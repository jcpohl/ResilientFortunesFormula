{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE-04D · TOP-20 RATIO SUMMARY PER METRIC\n",
    "v1.9 – 2025-06-20\n",
    "• Compatible with the v3.1 naming convention\n",
    "  (Stage4A_ / Stage4B_ / Stage4C_ files).\n",
    "• Still guards against locked files and missing score columns.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import logging, os, time, tempfile\n",
    "from pathlib import Path\n",
    "from typing  import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "# ── helper: atomic writer tolerant of locked files ──────────────\n",
    "def safe_to_csv(df: pd.DataFrame, path: Path, max_retry: int = 3) -> Path:\n",
    "    tmp = Path(tempfile.mkstemp(suffix=\".csv\", dir=path.parent)[1])\n",
    "    df.to_csv(tmp, index=False)\n",
    "\n",
    "    target = path\n",
    "    for i in range(max_retry):\n",
    "        try:\n",
    "            os.replace(tmp, target)\n",
    "            return target\n",
    "        except PermissionError:\n",
    "            time.sleep(0.5)\n",
    "            target = target.with_name(f\"{path.stem}_retry{i+1}{path.suffix}\")\n",
    "\n",
    "    logging.getLogger(__name__).warning(\n",
    "        \"Destination %s remained locked; using temp file %s instead.\",\n",
    "        path.name, tmp.name)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "# ── bootstrap & paths ───────────────────────────────────────────\n",
    "CFG    = load_cfg()\n",
    "EVENTS = {str(k): v for k, v in CFG[\"events\"].items()}\n",
    "YEAR   = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "\n",
    "RUN_DIR = resolve_run_dir(\n",
    "    swan_year = YEAR,\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"),\n",
    "    must_have = f\"stage04c/Stage4C_winsor_RatioRanking_{YEAR}.csv\",   # at least one exists\n",
    ")\n",
    "OUT_DIR = RUN_DIR / \"stage04d\"; OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(OUT_DIR / \"stage04d.log\", \"w\", \"utf-8\"),\n",
    "              logging.StreamHandler()],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE-04D  (SWAN %s) ==========\", YEAR)\n",
    "\n",
    "# ── locate available ranking tables ─────────────────────────────\n",
    "CANDIDATES: Dict[str, Path] = {\n",
    "    \"Temporal\": RUN_DIR / \"stage04\"  / f\"Stage4A_winsor_RatioRanking_{YEAR}.csv\",\n",
    "    \"Impact\"  : RUN_DIR / \"stage04b\" / f\"Stage4B_winsor_RatioRanking_{YEAR}.csv\",\n",
    "    \"Dynamic\" : RUN_DIR / \"stage04c\" / f\"Stage4C_winsor_RatioRanking_{YEAR}.csv\",\n",
    "}\n",
    "tables: Dict[str, pd.DataFrame] = {}\n",
    "for dim, fp in CANDIDATES.items():\n",
    "    if fp.is_file() and fp.stat().st_size:\n",
    "        tables[dim] = pd.read_csv(fp)\n",
    "        log.info(\"Loaded %s (%d rows)\", fp.name, len(tables[dim]))\n",
    "    else:\n",
    "        log.warning(\"⏭️  %s missing or empty – skipped\", fp.name)\n",
    "\n",
    "if not tables:\n",
    "    raise RuntimeError(\"No ranking tables found – nothing to summarise\")\n",
    "\n",
    "metrics = sorted({m for t in tables.values() for m in t[\"Metric\"]})\n",
    "preferred_scores = [\"AbsRho\", \"|rho|\", \"AUROC\", \"PseudoR2\"]\n",
    "all_rows: List[Dict] = []\n",
    "\n",
    "# ── per-metric aggregation ─────────────────────────────────────\n",
    "for met in metrics:\n",
    "    rows: List[Dict] = []\n",
    "    for dim, tbl in tables.items():\n",
    "        sub = tbl[tbl[\"Metric\"] == met]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        score = next((c for c in preferred_scores if c in sub.columns), None)\n",
    "        if not score:\n",
    "            continue\n",
    "        top = (sub.nlargest(20, score)\n",
    "                 .loc[:, [\"Ratio\"] + [c for c in preferred_scores if c in sub]]\n",
    "                 .round(3))\n",
    "        top.insert(0, \"Dimension\", dim)\n",
    "        rows.extend(top.to_dict(\"records\"))\n",
    "\n",
    "    if rows:\n",
    "        df_out = pd.DataFrame(rows)\n",
    "        final  = safe_to_csv(df_out, OUT_DIR / f\"Stage4D_{met}_{YEAR}.csv\")\n",
    "        log.info(\"→ %s (%d rows)\", final.name, len(df_out))\n",
    "        all_rows.extend(df_out.assign(Metric=met).to_dict(\"records\"))\n",
    "\n",
    "# ── stacked summary across all metrics ─────────────────────────\n",
    "if all_rows:\n",
    "    df_all = pd.DataFrame(all_rows)\n",
    "    keep   = [\"Metric\", \"Dimension\", \"Ratio\"] + \\\n",
    "             [c for c in preferred_scores if c in df_all.columns]\n",
    "    df_all = df_all[keep]\n",
    "    safe_to_csv(df_all, OUT_DIR / f\"Stage4D_AllMetrics_{YEAR}.csv\")\n",
    "    log.info(\"Stacked summary saved (%d rows, %d cols).\", *df_all.shape)\n",
    "\n",
    "log.info(\"✅  STAGE-04D complete — artefacts in %s\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
