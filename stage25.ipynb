{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# ===================================================================\n",
    "# STAGE-25 · Universal Ratio-vs-Resilience Ranker  (2025-06-17 + blend)\n",
    "# ===================================================================\n",
    "\"\"\"\n",
    "Adds “blend” family (ScoreBlend_*, FlagBlend_*) and stronger guard-rails:\n",
    "    • Fisher / Stouffer remain finite when any p==0/1\n",
    "    • Cross-event summary skipped gracefully when nothing converged\n",
    "Every artefact now carries the Flavour token (Speed / Depth / Blend).\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import contextlib, io, logging, math, os, sys, warnings\n",
    "from pathlib import Path\n",
    "from typing  import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2, norm, spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.linalg   import LinAlgError\n",
    "from statsmodels.tools.sm_exceptions import (\n",
    "    MissingDataError, PerfectSeparationError)\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "# ═════════════════════ GLOBALS ══════════════════════\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\")\n",
    "log = logging.getLogger(\"stage25\")\n",
    "\n",
    "CFG        = load_cfg()\n",
    "EVENT_LIST = list(CFG.get(\"events\", {}).keys())            # ['1998', '2008', …]\n",
    "\n",
    "MIN_COVER = float(os.getenv(\"MIN_COVERAGE\", 40))           # %\n",
    "MIN_OBS   = int  (os.getenv(\"MIN_OBS\",      30))\n",
    "EPS_VAR   = 1e-6\n",
    "\n",
    "ID_COL, YEAR_COL, DATE_COL = \"Symbol\", \"Year\", \"ReportDate\"\n",
    "_IN_NOTEBOOK = \"ipykernel\" in sys.modules\n",
    "\n",
    "# ═════════════════════ STATS HELPERS ═════════════════\n",
    "def _safe_spearman(x: pd.Series, y: pd.Series):\n",
    "    ok = x.notna() & y.notna()\n",
    "    if ok.sum() < MIN_OBS:\n",
    "        return np.nan, np.nan\n",
    "    r, p = spearmanr(x[ok], y[ok])\n",
    "    return abs(r), p\n",
    "\n",
    "def _logit_one(x: pd.Series, flag: pd.Series):\n",
    "    ok = x.notna() & flag.isin([0, 1])\n",
    "    n  = int(ok.sum())\n",
    "    out = dict(SampleSize=n,\n",
    "               PositivePct=float(flag[ok].mean()*100) if n else np.nan,\n",
    "               PseudoR2=np.nan, AUROC=np.nan, CoefP=np.nan,\n",
    "               ModelConv=False, Failure=\"\")\n",
    "    if n < MIN_OBS:\n",
    "        out[\"Failure\"] = \"too_few_obs\"; return out\n",
    "    if flag[ok].nunique() < 2:\n",
    "        out[\"Failure\"] = \"single_class\"; return out\n",
    "    if x[ok].var() < EPS_VAR:\n",
    "        out[\"Failure\"] = \"zero_variance\"; return out\n",
    "\n",
    "    try:\n",
    "        mdl = sm.Logit(flag[ok], sm.add_constant(x[ok])).fit(disp=False)\n",
    "        if not mdl.mle_retvals.get(\"converged\", True):\n",
    "            out[\"Failure\"] = \"no_convergence\"; return out\n",
    "        out.update(ModelConv=True,\n",
    "                   PseudoR2=float(mdl.prsquared),\n",
    "                   AUROC=float(roc_auc_score(flag[ok], mdl.predict())),\n",
    "                   CoefP=float(mdl.pvalues.iloc[1]))\n",
    "    except (ValueError, LinAlgError,\n",
    "            MissingDataError, PerfectSeparationError):\n",
    "        out[\"Failure\"] = \"model_error\"\n",
    "    return out\n",
    "\n",
    "def _fisher(p_list: List[float]) -> float:\n",
    "    good = [p for p in p_list if 0 < p < 1]\n",
    "    if not good:\n",
    "        return np.nan\n",
    "    stat = -2 * sum(math.log(max(p, 1e-300)) for p in good)  # clamp at 1e-300\n",
    "    return 1 - chi2.cdf(stat, 2*len(good))\n",
    "\n",
    "def _stouffer(p_list: List[float]) -> float:\n",
    "    good = [p for p in p_list if 0 < p < 1]\n",
    "    if not good:\n",
    "        return np.nan\n",
    "    z = [norm.isf(p/2) * math.copysign(1, .5-p) for p in good]  # safe\n",
    "    return sum(z) / math.sqrt(len(z))\n",
    "\n",
    "# ═════════════════════ RATIO DETECTOR ════════════════\n",
    "def _ratio_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return (raw_cols, wins_cols) with best-guess naming heuristics.\n",
    "    \"\"\"\n",
    "    if any(c.endswith(\"_raw\") for c in df.columns):\n",
    "        raw  = [c for c in df if c.endswith(\"_raw\") and c[:-4] in df.columns]\n",
    "        wins = [c[:-4] for c in raw]\n",
    "    elif any(c.endswith(\"_orig\") for c in df.columns):\n",
    "        raw  = [c for c in df if c.endswith(\"_orig\") and c[:-5] in df.columns]\n",
    "        wins = [c[:-5] for c in raw]\n",
    "    else:\n",
    "        raw  = []\n",
    "        wins = [c for c in df if \"_\" in c and not c.endswith((\"_raw\", \"_orig\"))]\n",
    "    return raw, wins\n",
    "\n",
    "# ═════════════════════ ONE-EVENT CORE ════════════════\n",
    "def run_event(ev: str) -> pd.DataFrame:\n",
    "    run_dir = resolve_run_dir(ev,\n",
    "                              must_have=f\"stage03/Stage3_Data_WithRatios_{ev}.csv\",\n",
    "                              run_tag=os.getenv(\"RUN_TAG\"))\n",
    "    out_dir = run_dir / \"stage25\"; out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(run_dir/\"stage03\"/f\"Stage3_Data_WithRatios_{ev}.csv\")\n",
    "    if YEAR_COL not in df and DATE_COL in df:\n",
    "        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "        df[YEAR_COL] = df[DATE_COL].dt.year\n",
    "    df = df[df[YEAR_COL] < int(ev)].copy()   # pre-event history only\n",
    "\n",
    "    raw_cols, win_cols = _ratio_columns(df)\n",
    "\n",
    "    # outcome columns ─────────────\n",
    "    OUT = {\n",
    "        \"Speed\": dict(score=\"Score_\",       flag=\"Flag_\"),\n",
    "        \"Depth\": dict(score=\"ScoreDepth_\",  flag=\"FlagDepth_\"),\n",
    "        \"Blend\": dict(score=\"ScoreBlend_\",  flag=\"FlagBlend_\"),\n",
    "    }\n",
    "\n",
    "    metric_map = {}\n",
    "    for flav, pre in OUT.items():\n",
    "        scols = [c for c in df if c.startswith(pre[\"score\"])]\n",
    "        fcols = [c for c in df if c.startswith(pre[\"flag\"])]\n",
    "        metrics = sorted(\n",
    "            set(c[len(pre[\"score\"]):] for c in scols)\n",
    "            & set(c[len(pre[\"flag\"]):]  for c in fcols)\n",
    "        )\n",
    "        metric_map[flav] = metrics\n",
    "\n",
    "    # ranking helper ──────────────\n",
    "    def _rank(cols: list[str], flavour: str):\n",
    "        pre = OUT[flavour]\n",
    "        metrics = metric_map[flavour]\n",
    "        rows = []\n",
    "        for rc in cols:\n",
    "            cov = df[rc].notna().mean()*100\n",
    "            if cov < MIN_COVER:\n",
    "                continue\n",
    "            for m in metrics:\n",
    "                rho, p_rho = _safe_spearman(df[rc], df[f\"{pre['score']}{m}\"])\n",
    "                rows.append(dict(\n",
    "                    SwanYear    = int(ev),\n",
    "                    Ratio       = rc.replace(\"_raw\",\"\").replace(\"_orig\",\"\"),\n",
    "                    Metric      = m,\n",
    "                    CoveragePct = round(cov,1),\n",
    "                    AbsRho      = rho,\n",
    "                    RhoP        = p_rho,\n",
    "                    **_logit_one(df[rc], df[f\"{pre['flag']}{m}\"]),\n",
    "                    Flavour     = flavour,\n",
    "                    Series      = \"winsor\" if rc in win_cols else \"raw\",\n",
    "                ))\n",
    "        out = pd.DataFrame(rows)\n",
    "        tag = \"winsor\" if cols is win_cols else \"raw\"\n",
    "        if not out.empty:\n",
    "            out.to_csv(out_dir/f\"Stage25_{tag}_{flavour}_RatioRanking_{ev}.csv\",\n",
    "                       index=False)\n",
    "        return out\n",
    "\n",
    "    frames = []\n",
    "    if win_cols:\n",
    "        frames += [_rank(win_cols, f) for f in OUT]\n",
    "    if raw_cols:\n",
    "        frames += [_rank(raw_cols, f) for f in OUT]\n",
    "\n",
    "    out_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    log.info(\"Stage-25 %s → %d rows\", ev, len(out_df))\n",
    "    return out_df\n",
    "\n",
    "# ═════════════════════ DRIVER ════════════════════════\n",
    "def main():\n",
    "    all_frames = []\n",
    "    for ev in EVENT_LIST:\n",
    "        try:\n",
    "            all_frames.append(run_event(ev))\n",
    "        except Exception as exc:\n",
    "            log.error(\"Event %s skipped: %s\", ev, exc)\n",
    "\n",
    "    if not all_frames:\n",
    "        log.warning(\"No events processed – nothing to summarise\"); return\n",
    "\n",
    "    big = pd.concat(all_frames, ignore_index=True)\n",
    "\n",
    "    # only converged winsor models\n",
    "    sel = big[(big.Series==\"winsor\") & (big.ModelConv)]\n",
    "    if sel.empty:\n",
    "        log.warning(\"No converged winsor models – meta summary skipped\"); return\n",
    "\n",
    "    meta = (sel.groupby([\"Ratio\",\"Metric\",\"Flavour\"])\n",
    "               .apply(lambda g: pd.Series(dict(\n",
    "                   meanAbsRho = g.AbsRho.mean(),\n",
    "                   meanAUROC = g.AUROC.mean(),\n",
    "                   FisherP   = _fisher(g.CoefP.dropna().tolist()),\n",
    "                   StoufferZ = _stouffer(g.CoefP.dropna().tolist()),\n",
    "                   nEventsSig= int((g.CoefP < 0.05).sum()),\n",
    "                   Events    = \",\".join(map(str, sorted(set(g.SwanYear))))\n",
    "               )))\n",
    "               .reset_index()\n",
    "               .sort_values([\"Flavour\",\"FisherP\",\"meanAUROC\"]))\n",
    "\n",
    "    # write to the **latest** run folder that exists\n",
    "    meta_dir: Path | None = None\n",
    "    for ev in reversed(EVENT_LIST):\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            meta_dir = resolve_run_dir(ev, run_tag=os.getenv(\"RUN_TAG\"))\n",
    "            break\n",
    "    if meta_dir is None:\n",
    "        log.warning(\"No run folders found – meta summary NOT written\"); return\n",
    "\n",
    "    (meta_dir/\"stage25\").mkdir(exist_ok=True)\n",
    "    meta_path = meta_dir/\"stage25\"/\"Stage25_CrossEvent_Summary.csv\"\n",
    "    meta.to_csv(meta_path, index=False)\n",
    "    log.info(\"Cross-event summary saved → %s\", meta_path)\n",
    "\n",
    "    if _IN_NOTEBOOK:\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML(\"<h3>Cross-event summary (top 50)</h3>\"))\n",
    "        display(meta.head(50).style.background_gradient(cmap=\"Purples\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
