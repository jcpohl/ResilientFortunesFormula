{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# ===================================================================\n",
    "# STAGE-25 · Universal Ratio-vs-Resilience Ranker  (2025-06-17)\n",
    "# ===================================================================\n",
    "\"\"\"\n",
    "Changes vs the 2025-06-15 release\n",
    "─────────────────────────────────\n",
    "• Guard‐rails: no math-domain error when p-value ∈ {0,1}; no TypeError when\n",
    "  the cross-event CSV is empty.\n",
    "• NEW: understands draw-down outcomes\n",
    "      ─ ScoreDepth_<metric>, FlagDepth_<metric>, DD_<metric> ─\n",
    "  and produces *parallel* rankings for “speed” and “depth”.\n",
    "• All output filenames now include the flavour (‘Speed’ / ‘Depth’) so nothing\n",
    "  is overwritten.\n",
    "Everything else is unchanged.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import contextlib, io, logging, math, os, sys, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.stats import chi2, norm, spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from statsmodels.tools.sm_exceptions import (\n",
    "    MissingDataError, PerfectSeparationError)\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "# ──────────────── GLOBAL CONFIG ────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s | %(levelname)-7s | %(message)s\")\n",
    "log = logging.getLogger(\"stage25\")\n",
    "\n",
    "CFG           = load_cfg()\n",
    "EVENT_LIST    = list(CFG.get(\"events\", {}).keys())         # ['1998','2008', …]\n",
    "MIN_COVER     = float(os.getenv(\"MIN_COVERAGE\", 40))       # %\n",
    "MIN_OBS       = int  (os.getenv(\"MIN_OBS\",      30))\n",
    "EPS_VAR       = 1e-6\n",
    "ID_COL, YEAR_COL, DATE_COL = \"Symbol\", \"Year\", \"ReportDate\"\n",
    "_IN_NOTEBOOK  = \"ipykernel\" in sys.modules\n",
    "\n",
    "# ──────────────── STATS HELPERS ───────────────────────────────────\n",
    "def _safe_spearman(x: pd.Series, y: pd.Series):\n",
    "    ok = x.notna() & y.notna()\n",
    "    if ok.sum() < MIN_OBS:\n",
    "        return np.nan, np.nan\n",
    "    r, p = spearmanr(x[ok], y[ok])\n",
    "    return abs(r), p\n",
    "\n",
    "def _logit_one(x: pd.Series, flag: pd.Series):\n",
    "    ok = x.notna() & flag.isin([0, 1])\n",
    "    n  = int(ok.sum())\n",
    "    out = dict(SampleSize=n,\n",
    "               PositivePct=float(flag[ok].mean() * 100) if n else np.nan,\n",
    "               PseudoR2=np.nan, AUROC=np.nan, CoefP=np.nan,\n",
    "               ModelConv=False, Failure=\"\")\n",
    "    if n < MIN_OBS:\n",
    "        out[\"Failure\"] = \"too_few_obs\"; return out\n",
    "    if flag[ok].nunique() < 2:\n",
    "        out[\"Failure\"] = \"single_class\"; return out\n",
    "    if x[ok].var() < EPS_VAR:\n",
    "        out[\"Failure\"] = \"zero_variance\"; return out\n",
    "    try:\n",
    "        mdl = sm.Logit(flag[ok], sm.add_constant(x[ok])).fit(disp=False)\n",
    "        if not mdl.mle_retvals.get(\"converged\", True):\n",
    "            out[\"Failure\"] = \"no_convergence\"; return out\n",
    "        out.update(ModelConv=True,\n",
    "                   PseudoR2=float(mdl.prsquared),\n",
    "                   AUROC=float(roc_auc_score(flag[ok], mdl.predict())),\n",
    "                   CoefP=float(mdl.pvalues.iloc[1]))\n",
    "        return out\n",
    "    except (ValueError, LinAlgError,\n",
    "            MissingDataError, PerfectSeparationError):\n",
    "        out[\"Failure\"] = \"model_error\"; return out\n",
    "\n",
    "def _fisher(p_list):\n",
    "    good = [p for p in p_list if 0 < p < 1]\n",
    "    if not good:\n",
    "        return np.nan\n",
    "    stat = -2 * sum(math.log(p) for p in good)\n",
    "    return 1 - chi2.cdf(stat, 2 * len(good))\n",
    "\n",
    "def _stouffer(p_list):\n",
    "    good = [p for p in p_list if 0 < p < 1]\n",
    "    if not good:\n",
    "        return np.nan\n",
    "    z = [norm.isf(p / 2) * math.copysign(1, .5 - p) for p in good]\n",
    "    return sum(z) / math.sqrt(len(z))\n",
    "\n",
    "# ──────────────── RATIO COLUMN DETECTOR ───────────────────────────\n",
    "def _ratio_columns(df: pd.DataFrame):\n",
    "    \"\"\"Return (raw_cols, winsorised_cols).\"\"\"\n",
    "    if any(c.endswith(\"_raw\") for c in df.columns):\n",
    "        raw  = [c for c in df if c.endswith(\"_raw\") and c[:-4] in df]\n",
    "        wins = [c[:-4] for c in raw]\n",
    "    elif any(c.endswith(\"_orig\") for c in df.columns):\n",
    "        raw  = [c for c in df if c.endswith(\"_orig\") and c[:-5] in df]\n",
    "        wins = [c[:-5] for c in raw]\n",
    "    else:\n",
    "        raw  = []\n",
    "        wins = [c for c in df if \"_\" in c and not c.endswith((\"_raw\", \"_orig\"))]\n",
    "    return raw, wins\n",
    "\n",
    "# ──────────────── ONE-EVENT ROUTINE ───────────────────────────────\n",
    "def run_event(ev: str) -> pd.DataFrame:\n",
    "    run_dir = resolve_run_dir(ev,\n",
    "                              must_have=f\"stage03/Stage3_Data_WithRatios_{ev}.csv\",\n",
    "                              run_tag  =os.getenv(\"RUN_TAG\"))\n",
    "    out_dir = run_dir / \"stage25\"; out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(run_dir / \"stage03\" / f\"Stage3_Data_WithRatios_{ev}.csv\")\n",
    "    if YEAR_COL not in df and DATE_COL in df:\n",
    "        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "        df[YEAR_COL] = df[DATE_COL].dt.year\n",
    "    df = df[df[YEAR_COL] < int(ev)].copy()\n",
    "\n",
    "    raw_cols, win_cols = _ratio_columns(df)\n",
    "\n",
    "    # outcome columns ------------------------------------------------\n",
    "    speed_score_cols = [c for c in df if c.startswith(\"Score_\")]\n",
    "    depth_score_cols = [c for c in df if c.startswith(\"ScoreDepth_\")]\n",
    "    speed_flag_cols  = [c for c in df if c.startswith(\"Flag_\")]\n",
    "    depth_flag_cols  = [c for c in df if c.startswith(\"FlagDepth_\")]\n",
    "\n",
    "    def _metric_name(col: str, prefix: str) -> str:\n",
    "        return col[len(prefix):]\n",
    "\n",
    "    speed_metrics = sorted(set(_metric_name(c, \"Score_\") for c in speed_score_cols)\n",
    "                           & set(_metric_name(c, \"Flag_\")  for c in speed_flag_cols))\n",
    "    depth_metrics = sorted(set(_metric_name(c, \"ScoreDepth_\") for c in depth_score_cols)\n",
    "                           & set(_metric_name(c, \"FlagDepth_\")  for c in depth_flag_cols))\n",
    "\n",
    "    # ---------- ranking helper -------------------------------------\n",
    "    def _rank(cols: list[str], flavour: str):\n",
    "        \"\"\"\n",
    "        flavour ∈ {\"Speed\", \"Depth\"}\n",
    "        \"\"\"\n",
    "        score_prefix = \"Score_\"      if flavour == \"Speed\" else \"ScoreDepth_\"\n",
    "        flag_prefix  = \"Flag_\"       if flavour == \"Speed\" else \"FlagDepth_\"\n",
    "        metrics      = speed_metrics if flavour == \"Speed\" else depth_metrics\n",
    "\n",
    "        rows = []\n",
    "        for rc in cols:\n",
    "            cov = df[rc].notna().mean() * 100\n",
    "            if cov < MIN_COVER:\n",
    "                continue\n",
    "            for m in metrics:\n",
    "                rho, p_rho = _safe_spearman(df[rc], df[f\"{score_prefix}{m}\"])\n",
    "                rows.append(dict(\n",
    "                    SwanYear   = int(ev),\n",
    "                    Ratio      = rc.replace(\"_raw\", \"\").replace(\"_orig\", \"\"),\n",
    "                    Metric     = m,\n",
    "                    CoveragePct= round(cov, 1),\n",
    "                    AbsRho     = rho,\n",
    "                    RhoP       = p_rho,\n",
    "                    **_logit_one(df[rc], df[f\"{flag_prefix}{m}\"]),\n",
    "                    Flavour    = flavour,\n",
    "                    Series     = \"winsor\" if rc in win_cols else \"raw\"\n",
    "                ))\n",
    "        out = pd.DataFrame(rows)\n",
    "        tag = \"winsor\" if cols is win_cols else \"raw\"\n",
    "        if not out.empty:\n",
    "            out.to_csv(out_dir / f\"Stage25_{tag}_{flavour}_RatioRanking_{ev}.csv\",\n",
    "                       index=False)\n",
    "        return out\n",
    "\n",
    "    frames = []\n",
    "    if win_cols:\n",
    "        frames.append(_rank(win_cols, \"Speed\"))\n",
    "        frames.append(_rank(win_cols, \"Depth\"))\n",
    "    if raw_cols:\n",
    "        frames.append(_rank(raw_cols, \"Speed\"))\n",
    "        frames.append(_rank(raw_cols, \"Depth\"))\n",
    "\n",
    "    out_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    log.info(\"Stage-25 %s → %d rows\", ev, len(out_df))\n",
    "    return out_df\n",
    "\n",
    "# ──────────────── DRIVER ──────────────────────────────────────────\n",
    "def main():\n",
    "    all_frames = []\n",
    "    for ev in EVENT_LIST:\n",
    "        try:\n",
    "            all_frames.append(run_event(ev))\n",
    "        except Exception as exc:\n",
    "            log.error(\"Event %s skipped: %s\", ev, exc)\n",
    "\n",
    "    if not all_frames:\n",
    "        log.warning(\"No events processed – nothing to summarise.\")\n",
    "        return\n",
    "\n",
    "    big = pd.concat(all_frames, ignore_index=True)\n",
    "\n",
    "    # focus on converged winsorised models only\n",
    "    sel = big[(big.Series == \"winsor\") & (big.ModelConv)]\n",
    "    if sel.empty:\n",
    "        log.warning(\"No converged winsor models – meta summary skipped.\")\n",
    "        return\n",
    "\n",
    "    meta = (sel.groupby([\"Ratio\", \"Metric\", \"Flavour\"])\n",
    "                .apply(lambda g: pd.Series(dict(\n",
    "                    meanAbsRho = g.AbsRho.mean(),\n",
    "                    meanAUROC = g.AUROC.mean(),\n",
    "                    FisherP   = _fisher(g.CoefP.dropna().tolist()),\n",
    "                    StoufferZ = _stouffer(g.CoefP.dropna().tolist()),\n",
    "                    nEventsSig= int((g.CoefP < 0.05).sum()),\n",
    "                    Events    = \",\".join(map(str, sorted(set(g.SwanYear))))\n",
    "                )))\n",
    "                .reset_index()\n",
    "                .sort_values([\"Flavour\", \"FisherP\", \"meanAUROC\"]))\n",
    "\n",
    "    # pick the newest run folder that exists — any event is fine\n",
    "    meta_dir: Path | None = None\n",
    "    for ev in reversed(EVENT_LIST):\n",
    "        try:\n",
    "            meta_dir = resolve_run_dir(ev, run_tag=os.getenv(\"RUN_TAG\"))\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    if meta_dir is None:\n",
    "        log.warning(\"No run folders found – meta summary NOT written.\")\n",
    "        return\n",
    "\n",
    "    (meta_dir / \"stage25\").mkdir(exist_ok=True)\n",
    "    meta_path = meta_dir / \"stage25\" / \"Stage25_CrossEvent_Summary.csv\"\n",
    "    meta.to_csv(meta_path, index=False)\n",
    "    log.info(\"Cross-event summary saved → %s\", meta_path)\n",
    "\n",
    "    if _IN_NOTEBOOK:\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML(\"<h3>Cross-event summary (top 50)</h3>\"))\n",
    "        display(meta.head(50).style.background_gradient(cmap=\"Purples\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
