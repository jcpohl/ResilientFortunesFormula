{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 22:24:35,878 | INFO    | ==========  STAGE 18 ==========\n",
      "2025-06-10 22:24:35,887 | INFO    | RUN_DIR ➜ C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\n",
      "2025-06-10 22:24:35,892 | INFO    | Probabilities  → C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\\11_RISE_Probabilities_All.csv\n",
      "2025-06-10 22:24:35,893 | INFO    | Stage-3 ratios → C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage03\\Stage3_Data_WithRatios.csv\n",
      "2025-06-10 22:24:41,485 | INFO    | Size variables detected: {'assets': 'totalassets', 'revenue': 'totalrevenue'}\n",
      "2025-06-10 22:24:41,557 | INFO    | Snapshot merged rows: 903\n",
      "2025-06-10 22:24:43,602 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,603 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,605 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,606 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,606 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,607 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,610 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,611 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,613 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:43,614 | INFO    | Flag column flag_rscoreprob missing – skip metric rscoreprob\n",
      "2025-06-10 22:24:44,076 | INFO    | ✓ Stage 18 outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage18\\snapshot2007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 worst calibration slopes (ideal = 1.00):\n",
      "                Metric SizeVar  Quintile  CalibSlope   n\n",
      "     operatingcashflow revenue         1      -1.400 181\n",
      "       operatingincome revenue         3      -0.999 181\n",
      "     operatingcashflow  assets         1      -0.844 181\n",
      "     operatingcashflow  assets         1      -0.828 181\n",
      "                  cash revenue         2      -0.769 180\n",
      "       operatingincome revenue         1      -0.725 181\n",
      "       operatingincome revenue         3      -0.667 181\n",
      "     operatingcashflow revenue         1      -0.534 181\n",
      "                  cash revenue         1      -0.492 181\n",
      "cashandcashequivalents  assets         1      -0.459 181\n",
      "\n",
      "✓ Stage 18 complete — outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage18\\snapshot2007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Stage-18 · Calibration by Size Quintile (Assets & Revenue)\n",
    "new-format · 2025-06-10 · filename-robust\n",
    "\n",
    "Fixes\n",
    "• looks for BOTH “stage11/Stage11_RISE_Probabilities_All.csv” and\n",
    "  “stage11/11_RISE_Probabilities_All.csv” (older run)  \n",
    "• latest_run_with() now accepts a list of alternative relative paths.  \n",
    "Everything else unchanged from the 2025-06-10 port.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, logging, warnings, yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s | %(levelname)-7s | %(message)s\")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 18 ==========\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 0 · YAML CONFIG & RUN-DIR\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "CFG_FILE = Path(os.getenv(\"PIPELINE_CFG\", \"pipeline_config.yaml\")).expanduser()\n",
    "if not CFG_FILE.is_file():\n",
    "    raise FileNotFoundError(f\"pipeline_config.yaml missing: {CFG_FILE}\")\n",
    "CFG       = yaml.safe_load(CFG_FILE.read_text()) or {}\n",
    "DEFAULTS  = CFG.get(\"defaults\", {})\n",
    "EVENTS    = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "\n",
    "SWAN_YEAR = int(os.getenv(\"SWAN_YEAR\", next(iter(EVENTS))))\n",
    "if str(SWAN_YEAR) not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR {SWAN_YEAR} missing in config\")\n",
    "SNAP_YEAR = SWAN_YEAR - 1\n",
    "\n",
    "OUTPUT_ROOT = Path(DEFAULTS[\"OUTPUT_ROOT\"]).expanduser()\n",
    "EVENT_DIR   = OUTPUT_ROOT / f\"event={SWAN_YEAR}\"\n",
    "\n",
    "def latest_run_with(rel_paths: Sequence[str]) -> Path:\n",
    "    \"\"\"Return RUN_DIR for newest run containing *any* of the rel_paths.\"\"\"\n",
    "    hits: List[Path] = []\n",
    "    for rel in rel_paths:\n",
    "        hits.extend(EVENT_DIR.glob(f\"*/{rel}\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"No run contains any of {rel_paths}\")\n",
    "    return max(hits, key=lambda p: p.stat().st_mtime).parents[1]\n",
    "\n",
    "if os.getenv(\"RUN_DIR\"):\n",
    "    RUN_DIR = Path(os.getenv(\"RUN_DIR\")).expanduser()\n",
    "elif os.getenv(\"RUN_DATE\"):\n",
    "    RUN_DIR = EVENT_DIR / os.getenv(\"RUN_DATE\")\n",
    "else:\n",
    "    RUN_DIR = latest_run_with([\n",
    "        \"stage11/Stage11_RISE_Probabilities_All.csv\",\n",
    "        \"stage11/11_RISE_Probabilities_All.csv\"\n",
    "    ])\n",
    "\n",
    "STAGE18_DIR = RUN_DIR / \"stage18\" / f\"snapshot{SNAP_YEAR}\"\n",
    "STAGE18_DIR.mkdir(parents=True, exist_ok=True)\n",
    "log.info(\"RUN_DIR ➜ %s\", RUN_DIR)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 1 · ENV OVERRIDES\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "DATE_COL = os.getenv(\"DATE_COL\", \"ReportDate\")\n",
    "ID_COL   = os.getenv(\"ID_COL\",   \"Symbol\")\n",
    "\n",
    "date_col = DATE_COL.lower()\n",
    "id_col   = ID_COL.lower()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 2 · LOCATE INPUT FILES\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "def find_first(rel_paths: Sequence[str]) -> Path:\n",
    "    for rel in rel_paths:\n",
    "        p = RUN_DIR / rel\n",
    "        if p.is_file():\n",
    "            return p\n",
    "    # else search event-wide\n",
    "    p_dir = latest_run_with(rel_paths)  # returns run dir\n",
    "    for rel in rel_paths:\n",
    "        cand = p_dir / rel\n",
    "        if cand.is_file():\n",
    "            return cand\n",
    "    raise FileNotFoundError(f\"No file found for any of {rel_paths}\")\n",
    "\n",
    "PROB_CSV = find_first([\n",
    "    \"stage11/Stage11_RISE_Probabilities_All.csv\",\n",
    "    \"stage11/11_RISE_Probabilities_All.csv\"\n",
    "])\n",
    "STAGE3_CSV = find_first([\"stage03/Stage3_Data_WithRatios.csv\"])\n",
    "\n",
    "log.info(\"Probabilities  → %s\", PROB_CSV)\n",
    "log.info(\"Stage-3 ratios → %s\", STAGE3_CSV)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 3 · LOAD DATA\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "prob = pd.read_csv(PROB_CSV, low_memory=False)\n",
    "prob.columns = prob.columns.str.lower().str.strip()\n",
    "prob[date_col] = pd.to_datetime(prob[date_col], errors=\"coerce\")\n",
    "\n",
    "stage3 = pd.read_csv(STAGE3_CSV, low_memory=False)\n",
    "stage3.columns = stage3.columns.str.lower().str.strip()\n",
    "stage3[date_col] = pd.to_datetime(stage3[date_col], errors=\"coerce\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 4 · DETECT SIZE VARIABLES\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "aliases = {\n",
    "    \"totalassets\":         \"assets\",\n",
    "    \"total_assets\":        \"assets\",\n",
    "    \"totalassetsreported\": \"assets\",\n",
    "    \"totalrevenue\":        \"revenue\",\n",
    "    \"total_revenue\":       \"revenue\",\n",
    "    \"revenue\":             \"revenue\"\n",
    "}\n",
    "size_cols: Dict[str,str] = {}\n",
    "for col in stage3.columns:\n",
    "    key = col.replace(\" \", \"\").lower()\n",
    "    if key in aliases:\n",
    "        size_cols[aliases[key]] = col\n",
    "if not size_cols:\n",
    "    raise RuntimeError(\"No TotalAssets / TotalRevenue columns detected\")\n",
    "log.info(\"Size variables detected: %s\", size_cols)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 5 · BUILD SNAPSHOT MERGED FRAME\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "snap_prob = prob[prob[date_col].dt.year == SNAP_YEAR].copy()\n",
    "prob_cols = [c for c in snap_prob.columns if\n",
    "             c.endswith(\"_rise_prob\") or c.endswith(\"_stagerise_prob\") or\n",
    "             c.startswith(\"rscoreprob_\")]\n",
    "if not prob_cols:\n",
    "    raise RuntimeError(\"No *_rise_prob columns in Stage-11 file\")\n",
    "\n",
    "snap_size = (stage3[stage3[date_col].dt.year == SNAP_YEAR]\n",
    "             .drop_duplicates(subset=id_col)\n",
    "             [[id_col] + list(size_cols.values())])\n",
    "\n",
    "df = (snap_prob[[id_col] + prob_cols]\n",
    "      .merge(snap_size, on=id_col, how=\"inner\")\n",
    "      .dropna(subset=prob_cols + list(size_cols.values())))\n",
    "log.info(\"Snapshot merged rows: %s\", f\"{len(df):,}\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 6 · CREATE SIZE QUINTILES\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "for var, raw in size_cols.items():\n",
    "    df[f\"{var}_quintile\"] = pd.qcut(df[raw], 5, labels=False, duplicates=\"drop\") + 1\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 7 · CALIBRATION UTILITIES\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "def calibration_table(data: pd.DataFrame, score_col: str,\n",
    "                      flag_col: str=\"flag\") -> pd.DataFrame:\n",
    "    cuts = pd.qcut(data[score_col], 10, duplicates=\"drop\")\n",
    "    pred = data.groupby(cuts)[score_col].mean()\n",
    "    obs  = data.groupby(cuts)[flag_col].mean()\n",
    "    return pd.DataFrame({\"bin_mean_pred\": pred.values,\n",
    "                         \"bin_mean_obs\":  obs.values},\n",
    "                        index=range(1, len(pred)+1))\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 8 · INITIALISE OVERALL PLOT\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot([0,1], [0,1], \"--\", color=\"gray\", label=\"perfect\")\n",
    "\n",
    "srows: List[Dict[str,object]] = []\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 9 · LOOP OVER PROBABILITY METRICS\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "for pcol in prob_cols:\n",
    "    metric   = pcol.split(\"_\")[0]\n",
    "    flag_col = f\"flag_{metric}\"\n",
    "    if flag_col not in stage3.columns:\n",
    "        log.info(\"Flag column %s missing – skip metric %s\", flag_col, metric)\n",
    "        continue\n",
    "\n",
    "    flags = (stage3[stage3[date_col].dt.year == SNAP_YEAR]\n",
    "             .drop_duplicates(subset=id_col)\n",
    "             [[id_col, flag_col]].rename(columns={flag_col: \"flag\"}))\n",
    "\n",
    "    base = df.merge(flags, on=id_col, how=\"inner\")\n",
    "    if base[\"flag\"].nunique() < 2:\n",
    "        log.info(\"Metric %s: only one class present – skipped\", metric)\n",
    "        continue\n",
    "\n",
    "    # overall curve\n",
    "    x_all, y_all = calibration_curve(\n",
    "        base[\"flag\"], base[pcol], n_bins=10, strategy=\"quantile\")\n",
    "    plt.plot(x_all, y_all, marker=\"o\", alpha=0.85, label=metric)\n",
    "\n",
    "    # by size quintile\n",
    "    for var in size_cols:\n",
    "        tag = f\"{var}_quintile\"\n",
    "        for q in range(1, 6):\n",
    "            seg = base[base[tag] == q]\n",
    "            if len(seg) < 120:\n",
    "                continue\n",
    "            tbl   = calibration_table(seg, pcol)\n",
    "            slope = np.polyfit(tbl[\"bin_mean_pred\"], tbl[\"bin_mean_obs\"], 1)[0]\n",
    "            tbl.to_csv(STAGE18_DIR / f\"{metric}_{var}_Q{q}.csv\", index=True)\n",
    "            srows.append({\n",
    "                \"Metric\":     metric,\n",
    "                \"SizeVar\":    var,\n",
    "                \"Quintile\":   q,\n",
    "                \"n\":          len(seg),\n",
    "                \"CalibSlope\": round(slope, 3)\n",
    "            })\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# 10 · FINALISE PLOT & SUMMARY\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "plt.title(f\"Calibration Curves (snapshot {SNAP_YEAR})\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.legend(fontsize=\"small\", ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(STAGE18_DIR / \"overall_calibration.png\", dpi=110)\n",
    "plt.close()\n",
    "\n",
    "slopes = pd.DataFrame(srows)\n",
    "slopes.to_csv(STAGE18_DIR / \"calibration_slope_summary.csv\", index=False)\n",
    "\n",
    "log.info(\"✓ Stage 18 outputs in %s\", STAGE18_DIR)\n",
    "if not slopes.empty:\n",
    "    worst = (slopes.assign(dev=lambda d: (d.CalibSlope - 1).abs())\n",
    "                   .sort_values(\"dev\", ascending=False)\n",
    "                   .head(10)[[\"Metric\",\"SizeVar\",\"Quintile\",\"CalibSlope\",\"n\"]])\n",
    "    print(\"\\n10 worst calibration slopes (ideal = 1.00):\")\n",
    "    print(worst.to_string(index=False))\n",
    "else:\n",
    "    print(\"No segment with ≥120 rows — nothing to report.\")\n",
    "\n",
    "print(f\"\\n✓ Stage 18 complete — outputs in {STAGE18_DIR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
