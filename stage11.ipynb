{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:49,357 | INFO    | ==========  STAGE 11: END-TO-END DASHBOARD ==========\n",
      "2025-06-11 10:37:49,360 | INFO    | RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609  SWAN_YEAR=2008  RUN_DATE=20250609\n",
      "2025-06-11 10:37:55,495 | INFO    | Loaded stage03\\Stage3_Data_WithRatios.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,497 | WARNING | None of ['05B_QuintilesAndScores.csv', 'Stage5B_QuintilesAndScores.csv'] found in stage05\n",
      "2025-06-11 10:37:55,654 | INFO    | Loaded stage06\\Stage6_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,794 | INFO    | Loaded stage06\\Stage6B_Stage_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,884 | INFO    | Loaded stage08\\08_pre2008_AllMetrics_RScores.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,900 | INFO    | Loaded stage08\\08_pre2008_CoefficientSummary.csv  (800 rows)\n",
      "2025-06-11 10:37:55,918 | INFO    | Loaded stage10\\10B_BestSubset_MasterTable.csv  (35 rows)\n",
      "2025-06-11 10:37:56,001 | INFO    | Backbone built: 34862 rows × 42 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AUROC snapshot FY-2007 =====\n",
      "                     Metric  AUROC_domain  AUROC_stage  AUROC_lasso\n",
      "                  NetIncome         0.656        0.729          1.0\n",
      "EarningBeforeInterestAndTax         0.657        0.681          1.0\n",
      "            OperatingIncome         0.678        0.678          1.0\n",
      "                     EBITDA         0.678        0.704          1.0\n",
      "          OperatingCashFlow         0.904        0.823          1.0\n",
      "               FreeCashFlow         0.585        0.601          1.0\n",
      "                       Cash         0.608        0.634          1.0\n",
      "     CashAndCashEquivalents         0.682        0.692          1.0\n",
      "               TotalRevenue         0.660        0.650          1.0\n",
      "                GrossProfit         0.729        0.682          1.0\n",
      "\n",
      "Ratios appearing in ≥3 best-subset models\n",
      "Ratio\n",
      "netdebt_to_ocf_q           9\n",
      "capex_to_depreciation_q    3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:56,864 | INFO    | Probability matrix written (30 columns)\n",
      "2025-06-11 10:37:56,871 | INFO    | ✅ STAGE 11 complete – artefacts saved in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run metadata\n",
      "Unique firms (Stage3)                   2,426\n",
      "Records in Stage3                      34,862\n",
      "Records in Stage5                         nan\n",
      "Rows with domain prob                     974\n",
      "Rows with stage prob                      974\n",
      "FY-2007 snapshot rows                     974\n",
      "\n",
      "✅ Stage 11 complete – outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Stage 11 · End-to-End Review Dashboard\n",
    "======================================\n",
    "\n",
    "Reads all earlier-stage artefacts, merges probabilities, evaluates\n",
    "snapshot AUROC, and saves run-wide metadata.\n",
    "\n",
    "Outputs  ( <run>/stage11/ )\n",
    "    11_ModelQuality.csv\n",
    "    11_BestSubset_RatioFrequency.csv\n",
    "    11_RISE_Probabilities_All.csv\n",
    "    11_RunMetadata.csv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── stdlib / 3-rd-party ────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import os, logging, warnings\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ── shared helpers ────────────────────────────────────────────────\n",
    "from pipeline_utils import load_cfg, resolve_run_dir         # NEW\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 0 · BOOTSTRAP  (cfg + run-folder + logger)                          #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "CFG: Dict      = load_cfg()\n",
    "EVENTS: Dict   = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "\n",
    "SWAN_YEAR_STR  = os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS))\n",
    "if SWAN_YEAR_STR not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR_STR} not listed in events block\")\n",
    "SWAN_YEAR      = int(SWAN_YEAR_STR)\n",
    "PRE_YEAR       = SWAN_YEAR - 1\n",
    "\n",
    "# pick the latest run that already contains Stage-10 outputs\n",
    "RUN_DIR  = resolve_run_dir(must_have=\"stage10/10B_BestSubset_MasterTable.csv\")\n",
    "RUN_DATE = RUN_DIR.name\n",
    "\n",
    "STAGE_DIR = RUN_DIR / \"stage11\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(STAGE_DIR / \"stage11.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"==========  STAGE 11: END-TO-END DASHBOARD ==========\")\n",
    "logger.info(\"RUN_DIR=%s  SWAN_YEAR=%s  RUN_DATE=%s\", RUN_DIR, SWAN_YEAR, RUN_DATE)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 1 · LOAD ARTEFACTS                                                 #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "\n",
    "def load_csv(stage_sub: str, names: list[str]) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Try each name inside <RUN_DIR>/<stage_sub>/ ; return the first match or None.\n",
    "    Lower-cases any column containing an underscore and ensures ReportDate dtype.\n",
    "    \"\"\"\n",
    "    for nm in names:\n",
    "        fp = RUN_DIR / stage_sub / nm\n",
    "        if fp.is_file():\n",
    "            df = pd.read_csv(fp, low_memory=False)\n",
    "            df.rename(columns={c: c.lower().strip()\n",
    "                               for c in df.columns if \"_\" in c}, inplace=True)\n",
    "            if DATE_COL.lower() in df.columns:\n",
    "                df[DATE_COL.lower()] = pd.to_datetime(df[DATE_COL.lower()],\n",
    "                                                      errors=\"coerce\")\n",
    "            logger.info(\"Loaded %s  (%d rows)\", fp.relative_to(RUN_DIR), len(df))\n",
    "            return df\n",
    "    logger.warning(\"None of %s found in %s\", names, stage_sub)\n",
    "    return None\n",
    "\n",
    "df3   = load_csv(\"stage03\", [\"Stage3_Data_WithRatios.csv\"])\n",
    "df5   = load_csv(\"stage05\", [\"05B_QuintilesAndScores.csv\",\n",
    "                             \"Stage5B_QuintilesAndScores.csv\"])\n",
    "df6   = load_csv(\"stage06\", [\"06_RISE_Predictions.csv\",\n",
    "                             \"Stage6_RISE_Predictions.csv\"])\n",
    "df6b  = load_csv(\"stage06\", [\"06B_Stage_RISE_Predictions.csv\",\n",
    "                             \"Stage6B_Stage_RISE_Predictions.csv\"])\n",
    "df8   = load_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_AllMetrics_RScores.csv\"])\n",
    "coef8 = load_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_CoefficientSummary.csv\"])\n",
    "df10  = load_csv(\"stage10\", [\"10B_BestSubset_MasterTable.csv\"])\n",
    "\n",
    "if df3 is None:\n",
    "    raise RuntimeError(\"Stage-03 artefacts missing – cannot proceed.\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 2 · MERGE INTO BACKBONE                                            #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "METRICS = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "           \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "           \"TotalRevenue\",\"GrossProfit\"]\n",
    "\n",
    "flag_cols = [f\"flag_{m.lower()}\" for m in METRICS if f\"flag_{m.lower()}\" in df3.columns]\n",
    "backbone  = df3[[ID_COL, DATE_COL] + flag_cols].copy()\n",
    "\n",
    "def merge_prob(src: pd.DataFrame | None, suffix: str) -> None:\n",
    "    \"\"\"Left-join onto *backbone* every column in *src* that ends with *suffix*.\"\"\"\n",
    "    global backbone\n",
    "    if src is None:\n",
    "        return\n",
    "    cols = [c for c in src.columns if c.endswith(suffix)]\n",
    "    if cols:\n",
    "        backbone = backbone.merge(\n",
    "            src[[ID_COL, DATE_COL] + cols],\n",
    "            on=[ID_COL, DATE_COL],\n",
    "            how=\"left\",\n",
    "            copy=False\n",
    "        )\n",
    "\n",
    "merge_prob(df6 , \"_rise_prob\")\n",
    "merge_prob(df6b, \"_stagerise_prob\")\n",
    "merge_prob(df8 , f\"_pre{SWAN_YEAR}\")\n",
    "\n",
    "logger.info(\"Backbone built: %d rows × %d columns\", len(backbone), backbone.shape[1])\n",
    "\n",
    "# ensure datetime dtype\n",
    "if not pd.api.types.is_datetime64_any_dtype(backbone[DATE_COL]):\n",
    "    backbone[DATE_COL] = pd.to_datetime(backbone[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 3 · MODEL-QUALITY TABLE (snapshot AUROC)                           #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "snap = backbone[backbone[DATE_COL].dt.year == PRE_YEAR]\n",
    "\n",
    "def safe_auc(y_series: pd.Series, col_name: str) -> float | np.nan:\n",
    "    if col_name not in snap.columns: return np.nan\n",
    "    y, p = y_series, snap[col_name]\n",
    "    msk = y.notna() & p.notna()\n",
    "    if msk.sum() < 2 or y[msk].nunique() < 2 or p[msk].nunique() < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return roc_auc_score(y[msk], p[msk])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "quality_rows = []\n",
    "for m in METRICS:\n",
    "    flag = f\"flag_{m.lower()}\"\n",
    "    if flag not in snap.columns: continue\n",
    "    y = snap[flag]\n",
    "    quality_rows.append({\n",
    "        \"Metric\": m,\n",
    "        \"AUROC_domain\": safe_auc(y, f\"{m.lower()}_rise_prob\"),\n",
    "        \"AUROC_stage\" : safe_auc(y, f\"{m.lower()}_stagerise_prob\"),\n",
    "        \"AUROC_lasso\" : safe_auc(y, f\"rscoreprob_{m.lower()}_pre{SWAN_YEAR}\")\n",
    "    })\n",
    "quality_df = pd.DataFrame(quality_rows).round(3)\n",
    "quality_df.to_csv(STAGE_DIR/\"11_ModelQuality.csv\", index=False)\n",
    "\n",
    "print(f\"\\n===== AUROC snapshot FY-{PRE_YEAR} =====\")\n",
    "print(quality_df.to_string(index=False))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 4 · BEST-SUBSET RATIO FREQUENCY                                    #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "if df10 is not None and \"ratio\" in (c.lower() for c in df10.columns):\n",
    "    ratio_col = next(c for c in df10.columns if c.lower() == \"ratio\")\n",
    "    freq = (df10[ratio_col].str.lower().str.strip()\n",
    "                      .value_counts()\n",
    "                      .rename(\"AppearsIn\"))\n",
    "    freq = freq[freq >= 3]\n",
    "    if not freq.empty:\n",
    "        freq.to_csv(STAGE_DIR/\"11_BestSubset_RatioFrequency.csv\")\n",
    "        print(\"\\nRatios appearing in ≥3 best-subset models\")\n",
    "        print(freq.to_string())\n",
    "else:\n",
    "    print(\"\\nStage10 coefficients missing – ratio frequency skipped\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 5 · FULL PROBABILITY MATRIX                                        #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "prob_cols = [c for c in backbone.columns\n",
    "             if c.endswith((\"_rise_prob\", \"_stagerise_prob\", f\"_pre{SWAN_YEAR}\"))]\n",
    "if prob_cols:\n",
    "    backbone[[ID_COL, DATE_COL] + prob_cols]\\\n",
    "        .to_csv(STAGE_DIR/\"11_RISE_Probabilities_All.csv\", index=False)\n",
    "    logger.info(\"Probability matrix written (%d columns)\", len(prob_cols))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 6 · RUN METADATA                                                   #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "meta = {\n",
    "    \"Unique firms (Stage3)\"       : df3[ID_COL].nunique(),\n",
    "    \"Records in Stage3\"           : len(df3),\n",
    "    \"Records in Stage5\"           : (len(df5)  if df5  is not None else np.nan),\n",
    "    \"Rows with domain prob\"       : (len(df6)  if df6  is not None else np.nan),\n",
    "    \"Rows with stage prob\"        : (len(df6b) if df6b is not None else np.nan),\n",
    "    f\"FY-{PRE_YEAR} snapshot rows\": len(snap),\n",
    "}\n",
    "pd.Series(meta).to_frame(\"Value\").to_csv(STAGE_DIR/\"11_RunMetadata.csv\")\n",
    "\n",
    "print(\"\\nRun metadata\")\n",
    "for k, v in meta.items():\n",
    "    print(f\"{k:<35s}{v:>10,.0f}\")\n",
    "\n",
    "logger.info(\"✅ STAGE 11 complete – artefacts saved in %s\", STAGE_DIR)\n",
    "print(f\"\\n✅ Stage 11 complete – outputs in {STAGE_DIR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
