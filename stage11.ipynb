{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:18:36,019 | INFO    | ==========  STAGE 11: END-TO-END DASHBOARD  ==========\n",
      "2025-06-10 14:18:36,022 | INFO    | SWAN_YEAR=2008  RUN_DATE=20250609  RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\n",
      "2025-06-10 14:18:41,373 | INFO    | Loaded stage03\\Stage3_Data_WithRatios.csv  (34862 rows)\n",
      "2025-06-10 14:18:41,394 | WARNING | None of ['05B_QuintilesAndScores.csv', 'Stage5B_QuintilesAndScores.csv'] found in stage05\n",
      "2025-06-10 14:18:41,545 | INFO    | Loaded stage06\\Stage6_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-10 14:18:41,654 | INFO    | Loaded stage06\\Stage6B_Stage_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-10 14:18:41,711 | INFO    | Loaded stage08\\08_pre2008_AllMetrics_RScores.csv  (34862 rows)\n",
      "2025-06-10 14:18:41,717 | INFO    | Loaded stage08\\08_pre2008_CoefficientSummary.csv  (800 rows)\n",
      "2025-06-10 14:18:41,723 | INFO    | Loaded stage10\\10B_BestSubset_MasterTable.csv  (35 rows)\n",
      "2025-06-10 14:18:41,783 | INFO    | Backbone built: 34862 rows × 42 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AUROC snapshot FY- 2007  =====\n",
      "                     Metric  AUROC_domain  AUROC_stage  AUROC_lasso\n",
      "                  NetIncome         0.656        0.729          1.0\n",
      "EarningBeforeInterestAndTax         0.657        0.681          1.0\n",
      "            OperatingIncome         0.678        0.678          1.0\n",
      "                     EBITDA         0.678        0.704          1.0\n",
      "          OperatingCashFlow         0.904        0.823          1.0\n",
      "               FreeCashFlow         0.585        0.601          1.0\n",
      "                       Cash         0.608        0.634          1.0\n",
      "     CashAndCashEquivalents         0.682        0.692          1.0\n",
      "               TotalRevenue         0.660        0.650          1.0\n",
      "                GrossProfit         0.729        0.682          1.0\n",
      "\n",
      "Ratios appearing in ≥3 best-subset models\n",
      "Ratio\n",
      "netdebt_to_ocf_q           9\n",
      "capex_to_depreciation_q    3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:18:42,499 | INFO    | Probability matrix written (30 columns)\n",
      "2025-06-10 14:18:42,507 | INFO    | ✅  STAGE 11 complete – artefacts saved in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run metadata\n",
      "Unique firms (Stage3)                   2,426\n",
      "Records in Stage3                      34,862\n",
      "Records in Stage5                         nan\n",
      "Rows with domain prob                     974\n",
      "Rows with stage prob                      974\n",
      "FY-2007 snapshot rows                     974\n",
      "\n",
      "✅ Stage 11 complete – outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Stage 11 · End-to-End Review Dashboard\n",
    "--------------------------------------\n",
    "\n",
    "Reads every earlier-stage artefact, merges probabilities, evaluates\n",
    "snapshot AUROC, and saves run-wide metadata.\n",
    "\n",
    "Outputs (…/stage11/)\n",
    "    11_ModelQuality.csv\n",
    "    11_BestSubset_RatioFrequency.csv\n",
    "    11_RISE_Probabilities_All.csv\n",
    "    11_RunMetadata.csv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── stdlib ──────────────────────────────────────────────────────────\n",
    "import os, logging, warnings\n",
    "from pathlib import Path\n",
    "# ── third-party ─────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml, seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 0 · CONFIG & PATHS                                                 #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "CFG_FILE = Path(os.getenv(\"PIPELINE_CFG\", \"pipeline_config.yaml\")).expanduser()\n",
    "if not CFG_FILE.is_file():\n",
    "    raise FileNotFoundError(f\"pipeline_config.yaml missing at {CFG_FILE}\")\n",
    "CFG = yaml.safe_load(CFG_FILE.read_text()) or {}\n",
    "\n",
    "DEFAULTS = CFG.get(\"defaults\", {})\n",
    "EVENTS   = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "\n",
    "SWAN_YEAR = int(os.getenv(\"SWAN_YEAR\",  next(iter(EVENTS))))\n",
    "if str(SWAN_YEAR) not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} not listed in config events.\")\n",
    "\n",
    "OUTPUT_ROOT = Path(DEFAULTS[\"OUTPUT_ROOT\"]).expanduser()\n",
    "EVENT_DIR   = OUTPUT_ROOT / f\"event={SWAN_YEAR}\"\n",
    "\n",
    "RUN_DIR: Path | None = None\n",
    "if os.getenv(\"RUN_DIR\"):\n",
    "    RUN_DIR = Path(os.getenv(\"RUN_DIR\")).expanduser()\n",
    "elif os.getenv(\"RUN_DATE\"):\n",
    "    RUN_DIR = EVENT_DIR / os.getenv(\"RUN_DATE\")\n",
    "\n",
    "if RUN_DIR is None:\n",
    "    # Pick newest run that has stage10 outputs\n",
    "    cand = list(EVENT_DIR.glob(\"*/stage10/10B_BestSubset_MasterTable.csv\"))\n",
    "    if not cand:\n",
    "        raise FileNotFoundError(\"No complete run found – make sure Stages 01-10 ran.\")\n",
    "    RUN_DIR = max(cand, key=lambda p: p.stat().st_mtime).parents[1]\n",
    "\n",
    "RUN_DATE  = RUN_DIR.name\n",
    "STAGE_DIR = RUN_DIR / \"stage11\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── logger ──────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(STAGE_DIR / \"stage11.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"==========  STAGE 11: END-TO-END DASHBOARD  ==========\")\n",
    "logger.info(\"SWAN_YEAR=%s  RUN_DATE=%s  RUN_DIR=%s\", SWAN_YEAR, RUN_DATE, RUN_DIR)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 1 · LOAD ARTEFACTS                                                 #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "PRE_YEAR         = SWAN_YEAR - 1\n",
    "\n",
    "def load_csv(stage_sub: str, names: list[str]) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Try a list of filenames inside RUN_DIR/<stage_sub>/ .  Return the\n",
    "    DataFrame of the first hit, or None if none exist.\n",
    "    \"\"\"\n",
    "    for nm in names:\n",
    "        fp = RUN_DIR / stage_sub / nm\n",
    "        if fp.is_file():\n",
    "            df = pd.read_csv(fp, low_memory=False)\n",
    "            # normalise column case (lower all w/ '_')\n",
    "            df.rename(columns={c: c.lower().strip()\n",
    "                               for c in df.columns if \"_\" in c}, inplace=True)\n",
    "            if DATE_COL.lower() in df.columns:\n",
    "                df[DATE_COL.lower()] = pd.to_datetime(df[DATE_COL.lower()],\n",
    "                                                      errors=\"coerce\")\n",
    "            logger.info(\"Loaded %s  (%d rows)\", fp.relative_to(RUN_DIR), len(df))\n",
    "            return df\n",
    "    logger.warning(\"None of %s found in %s\", names, stage_sub)\n",
    "    return None\n",
    "\n",
    "df3   = load_csv(\"stage03\", [\"Stage3_Data_WithRatios.csv\"])\n",
    "df5   = load_csv(\"stage05\", [\"05B_QuintilesAndScores.csv\",\n",
    "                             \"Stage5B_QuintilesAndScores.csv\"])\n",
    "df6   = load_csv(\"stage06\", [\"06_RISE_Predictions.csv\",\n",
    "                             \"Stage6_RISE_Predictions.csv\"])\n",
    "df6b  = load_csv(\"stage06\", [\"06B_Stage_RISE_Predictions.csv\",\n",
    "                             \"Stage6B_Stage_RISE_Predictions.csv\"])\n",
    "df8   = load_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_AllMetrics_RScores.csv\"])\n",
    "coef8 = load_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_CoefficientSummary.csv\"])\n",
    "df10  = load_csv(\"stage10\", [\"10B_BestSubset_MasterTable.csv\"])\n",
    "\n",
    "if df3 is None:\n",
    "    raise RuntimeError(\"Stage-03 artefacts missing – cannot proceed.\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 2 · MERGE INTO “BACKBONE”                                          #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "METRICS = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "           \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "           \"TotalRevenue\",\"GrossProfit\"]\n",
    "\n",
    "flag_cols = [f\"flag_{m.lower()}\" for m in METRICS if f\"flag_{m.lower()}\" in df3.columns]\n",
    "backbone  = df3[[ID_COL, DATE_COL] + flag_cols].copy()\n",
    "\n",
    "# helper ────────────────────────────────────────────────────────────\n",
    "def merge_prob(src: pd.DataFrame | None, suffix: str) -> None:\n",
    "    \"\"\"\n",
    "    Left-join onto *backbone* every column in *src* that ends with *suffix*.\n",
    "    The global 'backbone' DataFrame is reassigned (DataFrame.merge has\n",
    "    no 'inplace' argument).\n",
    "    \"\"\"\n",
    "    global backbone\n",
    "    if src is None:\n",
    "        return\n",
    "    cols = [c for c in src.columns if c.endswith(suffix)]\n",
    "    if cols:\n",
    "        backbone = backbone.merge(\n",
    "            src[[ID_COL, DATE_COL] + cols],\n",
    "            on=[ID_COL, DATE_COL],\n",
    "            how=\"left\",\n",
    "            copy=False\n",
    "        )\n",
    "merge_prob(df6 , \"_rise_prob\")\n",
    "merge_prob(df6b, \"_stagerise_prob\")\n",
    "merge_prob(df8 , f\"_pre{SWAN_YEAR}\")            # lasso probs\n",
    "\n",
    "logger.info(\"Backbone built: %d rows × %d columns\", len(backbone), backbone.shape[1])\n",
    "\n",
    "# ensure date dtype\n",
    "if not pd.api.types.is_datetime64_any_dtype(backbone[DATE_COL]):\n",
    "    backbone[DATE_COL] = pd.to_datetime(backbone[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 3 · MODEL-QUALITY TABLE (AUROC)                                    #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "def safe_auc(y_series: pd.Series, col_name: str) -> float | np.nan:\n",
    "    \"\"\"\n",
    "    AUROC for *col_name* against *y_series*.\n",
    "    • Ignores rows where either y or prob is NaN\n",
    "    • Requires at least 2 distinct classes *and* 2 distinct scores\n",
    "    \"\"\"\n",
    "    if col_name not in snap.columns:\n",
    "        return np.nan\n",
    "\n",
    "    y   = y_series\n",
    "    p   = snap[col_name]\n",
    "    msk = y.notna() & p.notna()\n",
    "    if msk.sum() < 2 or y[msk].nunique() < 2 or p[msk].nunique() < 2:\n",
    "        return np.nan                       # not enough information\n",
    "    try:\n",
    "        return roc_auc_score(y[msk], p[msk])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "snap = backbone[backbone[DATE_COL].dt.year == PRE_YEAR]\n",
    "quality_rows = []\n",
    "for m in METRICS:\n",
    "    flag = f\"flag_{m.lower()}\"\n",
    "    if flag not in snap.columns:\n",
    "        continue\n",
    "    y = snap[flag]\n",
    "    quality_rows.append({\n",
    "        \"Metric\": m,\n",
    "        \"AUROC_domain\": safe_auc(y, f\"{m.lower()}_rise_prob\"),\n",
    "        \"AUROC_stage\" : safe_auc(y, f\"{m.lower()}_stagerise_prob\"),\n",
    "        \"AUROC_lasso\" : safe_auc(y, f\"rscoreprob_{m.lower()}_pre{SWAN_YEAR}\")\n",
    "    })\n",
    "quality_df = pd.DataFrame(quality_rows).round(3)\n",
    "quality_df.to_csv(STAGE_DIR/\"11_ModelQuality.csv\", index=False)\n",
    "\n",
    "print(\"\\n===== AUROC snapshot FY-\", PRE_YEAR, \" =====\")\n",
    "print(quality_df.to_string(index=False))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 4 · BEST-SUBSET RATIO FREQUENCY                                    #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "if df10 is not None and \"ratio\" in (c.lower() for c in df10.columns):\n",
    "    ratio_col = next(c for c in df10.columns if c.lower() == \"ratio\")\n",
    "    freq = (df10[ratio_col].str.lower().str.strip()\n",
    "                      .value_counts()\n",
    "                      .rename(\"AppearsIn\"))\n",
    "    freq = freq[freq >= 3]\n",
    "    if not freq.empty:\n",
    "        freq.to_csv(STAGE_DIR/\"11_BestSubset_RatioFrequency.csv\")\n",
    "        print(\"\\nRatios appearing in ≥3 best-subset models\")\n",
    "        print(freq.to_string())\n",
    "else:\n",
    "    print(\"\\nStage10 coefficients missing – ratio frequency skipped\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 5 · WRITE FULL PROBABILITY MATRIX                                  #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "prob_cols = [c for c in backbone.columns\n",
    "             if c.endswith((\"_rise_prob\", \"_stagerise_prob\", f\"_pre{SWAN_YEAR}\"))]\n",
    "if prob_cols:\n",
    "    backbone[[ID_COL, DATE_COL] + prob_cols]\\\n",
    "        .to_csv(STAGE_DIR/\"11_RISE_Probabilities_All.csv\", index=False)\n",
    "    logger.info(\"Probability matrix written (%d columns)\", len(prob_cols))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 6 · RUN METADATA                                                   #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "meta = {\n",
    "    \"Unique firms (Stage3)\"       : df3[ID_COL].nunique(),\n",
    "    \"Records in Stage3\"           : len(df3),\n",
    "    \"Records in Stage5\"           : (len(df5)  if df5  is not None else np.nan),\n",
    "    \"Rows with domain prob\"       : (len(df6)  if df6  is not None else np.nan),\n",
    "    \"Rows with stage prob\"        : (len(df6b) if df6b is not None else np.nan),\n",
    "    f\"FY-{PRE_YEAR} snapshot rows\": len(snap),\n",
    "}\n",
    "pd.Series(meta).to_frame(\"Value\").to_csv(STAGE_DIR/\"11_RunMetadata.csv\")\n",
    "\n",
    "print(\"\\nRun metadata\")\n",
    "for k, v in meta.items():\n",
    "    print(f\"{k:<35s}{v:>10,.0f}\")\n",
    "\n",
    "logger.info(\"✅  STAGE 11 complete – artefacts saved in %s\", STAGE_DIR)\n",
    "print(f\"\\n✅ Stage 11 complete – outputs in {STAGE_DIR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
