{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:49,357 | INFO    | ==========  STAGE 11: END-TO-END DASHBOARD ==========\n",
      "2025-06-11 10:37:49,360 | INFO    | RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609  SWAN_YEAR=2008  RUN_DATE=20250609\n",
      "2025-06-11 10:37:55,495 | INFO    | Loaded stage03\\Stage3_Data_WithRatios.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,497 | WARNING | None of ['05B_QuintilesAndScores.csv', 'Stage5B_QuintilesAndScores.csv'] found in stage05\n",
      "2025-06-11 10:37:55,654 | INFO    | Loaded stage06\\Stage6_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,794 | INFO    | Loaded stage06\\Stage6B_Stage_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,884 | INFO    | Loaded stage08\\08_pre2008_AllMetrics_RScores.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,900 | INFO    | Loaded stage08\\08_pre2008_CoefficientSummary.csv  (800 rows)\n",
      "2025-06-11 10:37:55,918 | INFO    | Loaded stage10\\10B_BestSubset_MasterTable.csv  (35 rows)\n",
      "2025-06-11 10:37:56,001 | INFO    | Backbone built: 34862 rows Ã— 42 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AUROC snapshot FY-2007 =====\n",
      "                     Metric  AUROC_domain  AUROC_stage  AUROC_lasso\n",
      "                  NetIncome         0.656        0.729          1.0\n",
      "EarningBeforeInterestAndTax         0.657        0.681          1.0\n",
      "            OperatingIncome         0.678        0.678          1.0\n",
      "                     EBITDA         0.678        0.704          1.0\n",
      "          OperatingCashFlow         0.904        0.823          1.0\n",
      "               FreeCashFlow         0.585        0.601          1.0\n",
      "                       Cash         0.608        0.634          1.0\n",
      "     CashAndCashEquivalents         0.682        0.692          1.0\n",
      "               TotalRevenue         0.660        0.650          1.0\n",
      "                GrossProfit         0.729        0.682          1.0\n",
      "\n",
      "Ratios appearing in â‰¥3 best-subset models\n",
      "Ratio\n",
      "netdebt_to_ocf_q           9\n",
      "capex_to_depreciation_q    3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:56,864 | INFO    | Probability matrix written (30 columns)\n",
      "2025-06-11 10:37:56,871 | INFO    | âœ… STAGE 11 complete â€“ artefacts saved in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run metadata\n",
      "Unique firms (Stage3)                   2,426\n",
      "Records in Stage3                      34,862\n",
      "Records in Stage5                         nan\n",
      "Rows with domain prob                     974\n",
      "Rows with stage prob                      974\n",
      "FY-2007 snapshot rows                     974\n",
      "\n",
      "âœ… Stage 11 complete â€“ outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE-11 Â· END-TO-END REVIEW DASHBOARD\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Understands both the legacy â€œspeed-onlyâ€ artefacts and the new\n",
    "speed / depth / blend files (2025-06-16 refactor).\n",
    "\n",
    "Adds AUROC columns:\n",
    "    AUROC_speed Â· AUROC_stage Â· AUROC_depth Â· AUROC_blend\n",
    "    AUROC_lasso Â· AUROC_lassoDepth\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing  import Dict, List, Optional\n",
    "import os, logging, warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 0 Â· BOOTSTRAP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CFG        : Dict = load_cfg()\n",
    "EVENTS     : Dict = {str(k): v for k, v in CFG[\"events\"].items()}\n",
    "\n",
    "SWAN_YEAR  = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "SWAN_INT   = int(SWAN_YEAR)\n",
    "PRE_YEAR   = SWAN_INT - 1\n",
    "\n",
    "RUN_DIR = resolve_run_dir(\n",
    "    swan_year = SWAN_YEAR,\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"),\n",
    "    must_have = f\"stage10/Stage10_BestSubset_MasterTable_{SWAN_YEAR}.csv\",\n",
    ")\n",
    "STAGE_DIR = RUN_DIR / \"stage11\"; STAGE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(STAGE_DIR/\"stage11.log\", \"w\", \"utf-8\"),\n",
    "              logging.StreamHandler()],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"Stage-11 â€“ RUN=%s  SWAN=%s\", RUN_DIR.name, SWAN_YEAR)\n",
    "\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1 Â· SMART CSV LOADER â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _first_csv(stage: str, names: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Return first CSV (if any) from *names* inside RUN_DIR/<stage>/.\"\"\"\n",
    "    for nm in names:\n",
    "        fp = RUN_DIR / stage / nm\n",
    "        if fp.is_file():\n",
    "            df = pd.read_csv(fp, low_memory=False)\n",
    "\n",
    "            # lower-case every column that contains an underscore for consistency\n",
    "            df.rename(\n",
    "                columns={c: c.lower() for c in df.columns if \"_\" in c},\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "            # Parse date column (ReportDate / reportdate)\n",
    "            for cand in (DATE_COL, DATE_COL.lower()):\n",
    "                if cand in df.columns:\n",
    "                    df[cand] = pd.to_datetime(df[cand], errors=\"coerce\")\n",
    "                    break\n",
    "\n",
    "            log.info(\"Loaded %s  (%d rows, %d cols)\",\n",
    "                     fp.relative_to(RUN_DIR), *df.shape)\n",
    "            return df\n",
    "    log.warning(\"None of %s found in %s\", names, stage)\n",
    "    return None\n",
    "\n",
    "# Stage-level artefacts -------------------------------------------------------\n",
    "df3  = _first_csv(\"stage03\", [f\"Stage3_Data_WithRatios_{SWAN_YEAR}.csv\"])\n",
    "df5  = _first_csv(\"stage05a\", [f\"Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\"])\n",
    "\n",
    "# Stage-06 prediction files (all new + legacy fall-backs)\n",
    "df6_speed = _first_csv(\"stage06\", [\n",
    "    f\"Stage6Speed_RISE_Predictions_{SWAN_YEAR}.csv\",       # legacy\n",
    "    f\"Stage6_RISE_Predictions_{SWAN_YEAR}.csv\",            # new (family A)\n",
    "])\n",
    "df6_stage = _first_csv(\"stage06\", [\n",
    "    f\"Stage6B_Stage_RISE_Predictions_{SWAN_YEAR}.csv\",\n",
    "])\n",
    "df6_depth = _first_csv(\"stage06\", [\n",
    "    f\"Stage6Depth_RISE_Predictions_{SWAN_YEAR}.csv\",       # legacy\n",
    "    f\"Stage6C_Depth_RISE_Predictions_{SWAN_YEAR}.csv\",     # new (family C)\n",
    "])\n",
    "df6_blend = _first_csv(\"stage06\", [\n",
    "    f\"Stage6Blend_RISE_Predictions_{SWAN_YEAR}.csv\",       # legacy\n",
    "    f\"Stage6E_Blend_RISE_Predictions_{SWAN_YEAR}.csv\",     # new (family E)\n",
    "])\n",
    "\n",
    "# Stage-08 L1-scores\n",
    "df8_speed = _first_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_AllMetrics_RScores.csv\"])\n",
    "df8_depth = _first_csv(\"stage08\", [f\"08_pre{SWAN_YEAR}_Depth_AllMetrics_RScores.csv\"])\n",
    "\n",
    "# Stage-10 coefficients\n",
    "df10 = _first_csv(\"stage10\", [f\"Stage10_BestSubset_MasterTable_{SWAN_YEAR}.csv\"])\n",
    "\n",
    "if df3 is None:\n",
    "    raise RuntimeError(\"Stage-03 artefacts missing â€” cannot proceed.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2 Â· MASTER BACKBONE TABLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "METRICS = [\n",
    "    \"NetIncome\", \"EarningBeforeInterestAndTax\", \"OperatingIncome\", \"EBITDA\",\n",
    "    \"OperatingCashFlow\", \"FreeCashFlow\", \"Cash\", \"CashAndCashEquivalents\",\n",
    "    \"TotalRevenue\", \"GrossProfit\",\n",
    "]\n",
    "\n",
    "flag_cols = [f\"flag_{m.lower()}\" for m in METRICS if f\"flag_{m.lower()}\" in df3.columns]\n",
    "backbone  = df3[[ID_COL, DATE_COL] + flag_cols].copy()\n",
    "\n",
    "def _merge_prob(src: Optional[pd.DataFrame], suffix: str, base: pd.DataFrame) -> pd.DataFrame:\n",
    "    if src is None:\n",
    "        return base\n",
    "    cols = [c for c in src.columns if c.endswith(suffix)]\n",
    "    if not cols:\n",
    "        return base\n",
    "    return base.merge(src[[ID_COL, DATE_COL] + cols],\n",
    "                      on=[ID_COL, DATE_COL], how=\"left\", copy=False)\n",
    "\n",
    "# Stage-06 predictions\n",
    "backbone = _merge_prob(df6_speed, \"_rise_prob\",          backbone)\n",
    "backbone = _merge_prob(df6_stage, \"_stagerise_prob\",     backbone)\n",
    "backbone = _merge_prob(df6_depth, \"_depthrise_prob\",     backbone)\n",
    "backbone = _merge_prob(df6_blend, \"_blendrise_prob\",     backbone)\n",
    "\n",
    "# Stage-08 L1-scores\n",
    "backbone = _merge_prob(df8_speed, f\"_pre{SWAN_YEAR}\",    backbone)\n",
    "backbone = _merge_prob(df8_depth, f\"_pre{SWAN_YEAR}\",    backbone)  # depth uses same tail\n",
    "\n",
    "backbone[DATE_COL] = pd.to_datetime(backbone[DATE_COL], errors=\"coerce\")\n",
    "log.info(\"Backbone table: %d rows Ã— %d cols\", *backbone.shape)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3 Â· AUROC QUALITY TABLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "snap = backbone[backbone[DATE_COL].dt.year == PRE_YEAR]\n",
    "\n",
    "def _safe_auc(y: pd.Series, pcol: str) -> float | np.nan:\n",
    "    if pcol not in snap.columns:\n",
    "        return np.nan\n",
    "    mask = y.notna() & snap[pcol].notna()\n",
    "    if mask.sum() < 6 or y[mask].nunique() < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return roc_auc_score(y[mask], snap.loc[mask, pcol])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "rows = []\n",
    "for m in METRICS:\n",
    "    flag = f\"flag_{m.lower()}\"\n",
    "    if flag not in snap.columns:\n",
    "        continue\n",
    "    y = snap[flag]\n",
    "    rows.append({\n",
    "        \"Metric\"          : m,\n",
    "        \"AUROC_speed\"     : _safe_auc(y, f\"{m.lower()}_rise_prob\"),\n",
    "        \"AUROC_stage\"     : _safe_auc(y, f\"{m.lower()}_stagerise_prob\"),\n",
    "        \"AUROC_depth\"     : _safe_auc(y, f\"{m.lower()}_depthrise_prob\"),\n",
    "        \"AUROC_blend\"     : _safe_auc(y, f\"{m.lower()}_blendrise_prob\"),\n",
    "        \"AUROC_lasso\"     : _safe_auc(y, f\"rscoreprob_{m.lower()}_pre{SWAN_YEAR}\"),\n",
    "        \"AUROC_lassoDepth\": _safe_auc(y, f\"rscoredepthprob_{m.lower()}_pre{SWAN_YEAR}\"),\n",
    "    })\n",
    "quality = pd.DataFrame(rows).round(3)\n",
    "quality.to_csv(STAGE_DIR / f\"11_ModelQuality_{SWAN_YEAR}.csv\", index=False)\n",
    "\n",
    "print(f\"\\n=== AUROC snapshot FY-{PRE_YEAR} ===\")\n",
    "print(quality.to_string(index=False))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4 Â· RATIO / TERM FREQUENCY (Stage-10) â•â•â•â•â•â•\n",
    "if df10 is not None:\n",
    "    key_col = next((c for c in df10.columns if c.lower() in (\"ratio\", \"term\")), None)\n",
    "    if key_col:\n",
    "        freq = (df10[key_col]\n",
    "                   .astype(str)\n",
    "                   .str.lower()\n",
    "                   .replace(\"const\", np.nan)\n",
    "                   .dropna()\n",
    "                   .value_counts()\n",
    "                   .rename(\"AppearsIn\")\n",
    "                   .loc[lambda s: s >= 3])\n",
    "        if not freq.empty:\n",
    "            freq.to_csv(STAGE_DIR / f\"11_BestSubset_RatioFrequency_{SWAN_YEAR}.csv\")\n",
    "            print(\"\\nRatios / terms in â‰¥3 best-subset models:\")\n",
    "            print(freq.to_string())\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5 Â· DUMP PROBABILITY MATRIX â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "prob_cols = [c for c in backbone.columns if c.endswith((\n",
    "    \"_rise_prob\", \"_stagerise_prob\", \"_depthrise_prob\", \"_blendrise_prob\",\n",
    "    f\"_pre{SWAN_YEAR}\"))]\n",
    "if prob_cols:\n",
    "    backbone[[ID_COL, DATE_COL] + prob_cols]\\\n",
    "        .to_csv(STAGE_DIR / f\"11_RISE_Probabilities_All_{SWAN_YEAR}.csv\", index=False)\n",
    "    log.info(\"Probability matrix saved with %d probability columns\", len(prob_cols))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 6 Â· RUN-METADATA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "meta = {\n",
    "    \"Unique firms (Stage3)\"       : df3[ID_COL].nunique(),\n",
    "    \"Records in Stage3\"           : len(df3),\n",
    "    \"Records in Stage5A\"          : len(df5)        if df5   is not None else np.nan,\n",
    "    \"Rows with speed prob\"        : len(df6_speed)  if df6_speed  is not None else np.nan,\n",
    "    \"Rows with depth prob\"        : len(df6_depth)  if df6_depth  is not None else np.nan,\n",
    "    \"Rows with blend prob\"        : len(df6_blend)  if df6_blend  is not None else np.nan,\n",
    "    f\"FY-{PRE_YEAR} snapshot rows\": len(snap),\n",
    "}\n",
    "pd.Series(meta).to_frame(\"Value\").to_csv(STAGE_DIR / f\"11_RunMetadata_{SWAN_YEAR}.csv\")\n",
    "\n",
    "print(\"\\nRun-metadata:\")\n",
    "for k, v in meta.items():\n",
    "    print(f\"{k:<32}{v:>10,.0f}\" if pd.notna(v) else f\"{k:<32} â€”\")\n",
    "\n",
    "log.info(\"ğŸ‰  Stage-11 complete â€” artefacts in %s\", STAGE_DIR)\n",
    "print(f\"\\nâœ… Stage-11 complete â€” outputs in {STAGE_DIR}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
