{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:49,357 | INFO    | ==========  STAGE 11: END-TO-END DASHBOARD ==========\n",
      "2025-06-11 10:37:49,360 | INFO    | RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609  SWAN_YEAR=2008  RUN_DATE=20250609\n",
      "2025-06-11 10:37:55,495 | INFO    | Loaded stage03\\Stage3_Data_WithRatios.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,497 | WARNING | None of ['05B_QuintilesAndScores.csv', 'Stage5B_QuintilesAndScores.csv'] found in stage05\n",
      "2025-06-11 10:37:55,654 | INFO    | Loaded stage06\\Stage6_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,794 | INFO    | Loaded stage06\\Stage6B_Stage_RISE_Predictions.csv  (974 rows)\n",
      "2025-06-11 10:37:55,884 | INFO    | Loaded stage08\\08_pre2008_AllMetrics_RScores.csv  (34862 rows)\n",
      "2025-06-11 10:37:55,900 | INFO    | Loaded stage08\\08_pre2008_CoefficientSummary.csv  (800 rows)\n",
      "2025-06-11 10:37:55,918 | INFO    | Loaded stage10\\10B_BestSubset_MasterTable.csv  (35 rows)\n",
      "2025-06-11 10:37:56,001 | INFO    | Backbone built: 34862 rows Ã— 42 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== AUROC snapshot FY-2007 =====\n",
      "                     Metric  AUROC_domain  AUROC_stage  AUROC_lasso\n",
      "                  NetIncome         0.656        0.729          1.0\n",
      "EarningBeforeInterestAndTax         0.657        0.681          1.0\n",
      "            OperatingIncome         0.678        0.678          1.0\n",
      "                     EBITDA         0.678        0.704          1.0\n",
      "          OperatingCashFlow         0.904        0.823          1.0\n",
      "               FreeCashFlow         0.585        0.601          1.0\n",
      "                       Cash         0.608        0.634          1.0\n",
      "     CashAndCashEquivalents         0.682        0.692          1.0\n",
      "               TotalRevenue         0.660        0.650          1.0\n",
      "                GrossProfit         0.729        0.682          1.0\n",
      "\n",
      "Ratios appearing in â‰¥3 best-subset models\n",
      "Ratio\n",
      "netdebt_to_ocf_q           9\n",
      "capex_to_depreciation_q    3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:37:56,864 | INFO    | Probability matrix written (30 columns)\n",
      "2025-06-11 10:37:56,871 | INFO    | âœ… STAGE 11 complete â€“ artefacts saved in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run metadata\n",
      "Unique firms (Stage3)                   2,426\n",
      "Records in Stage3                      34,862\n",
      "Records in Stage5                         nan\n",
      "Rows with domain prob                     974\n",
      "Rows with stage prob                      974\n",
      "FY-2007 snapshot rows                     974\n",
      "\n",
      "âœ… Stage 11 complete â€“ outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage11\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE-11 Â· END-TO-END REVIEW DASHBOARD\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "*Understands both legacy â€œspeed-onlyâ€ outputs and the new speed / depth / blend\n",
    " prediction files introduced on 2025-06-16.*\n",
    "\n",
    "Outputs (unchanged) land in â€¦/stage11/, but new AUROC columns\n",
    "(`AUROC_speed`, `AUROC_depth`, `AUROC_blend`, `AUROC_lassoDepth`) are added\n",
    "when those flavours are available.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import os, logging, warnings\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 0 Â· BOOTSTRAP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CFG        : Dict = load_cfg()\n",
    "EVENTS     : Dict = {str(k): v for k, v in CFG[\"events\"].items()}\n",
    "\n",
    "SWAN_YEAR  = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "SWAN_INT   = int(SWAN_YEAR)\n",
    "PRE_YEAR   = SWAN_INT - 1\n",
    "\n",
    "RUN_DIR = resolve_run_dir(\n",
    "    swan_year = SWAN_YEAR,\n",
    "    must_have = f\"stage10/Stage10_BestSubset_MasterTable_{SWAN_YEAR}.csv\",\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"))\n",
    "STAGE_DIR = RUN_DIR / \"stage11\"; STAGE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "                    handlers=[logging.FileHandler(STAGE_DIR/\"stage11.log\",\"w\",\"utf-8\"),\n",
    "                              logging.StreamHandler()])\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"Stage-11 â€” RUN=%s  SWAN=%s\", RUN_DIR.name, SWAN_YEAR)\n",
    "\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1 Â· SMART CSV LOADER â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _first_csv(stage:str, names:List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Return first CSV (if any) from *names* inside RUN_DIR/<stage>/.\"\"\"\n",
    "    for nm in names:\n",
    "        fp = RUN_DIR / stage / nm\n",
    "        if fp.is_file():\n",
    "            df = pd.read_csv(fp, low_memory=False)\n",
    "            for c in df.columns:\n",
    "                if \"_\" in c:        # normalise underscores to lower\n",
    "                    df.rename(columns={c: c.lower().strip()}, inplace=True)\n",
    "            if DATE_COL.lower() in df.columns:\n",
    "                df[DATE_COL.lower()] = pd.to_datetime(\n",
    "                    df[DATE_COL.lower()], errors=\"coerce\")\n",
    "            log.info(\"Loaded %s  (%d rows)\", fp.relative_to(RUN_DIR), len(df))\n",
    "            return df\n",
    "    log.warning(\"None of %s found in %s\", names, stage)\n",
    "    return None\n",
    "\n",
    "# Stage-level artefacts -------------------------------------------------------\n",
    "df3 = _first_csv(\"stage03\",[f\"Stage3_Data_WithRatios_{SWAN_YEAR}.csv\"])\n",
    "df5 = _first_csv(\"stage05a\",[f\"Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\"])\n",
    "\n",
    "# speed / depth / blend prediction files (new names or legacy fallback)\n",
    "df6_speed = _first_csv(\"stage06\",[f\"Stage6Speed_RISE_Predictions_{SWAN_YEAR}.csv\",\n",
    "                                  f\"Stage6_RISE_Predictions_{SWAN_YEAR}.csv\"])  # legacy\n",
    "df6_depth = _first_csv(\"stage06\",[f\"Stage6Depth_RISE_Predictions_{SWAN_YEAR}.csv\"])\n",
    "df6_blend = _first_csv(\"stage06\",[f\"Stage6Blend_RISE_Predictions_{SWAN_YEAR}.csv\"])\n",
    "# legacy stage-weighted\n",
    "df6_stage = _first_csv(\"stage06\",[f\"Stage6B_Stage_RISE_Predictions_{SWAN_YEAR}.csv\"])\n",
    "\n",
    "# lasso (speed + depth)\n",
    "df8_speed = _first_csv(\"stage08\",[f\"08_pre{SWAN_YEAR}_AllMetrics_RScores.csv\"])\n",
    "df8_depth = _first_csv(\"stage08\",[f\"08_pre{SWAN_YEAR}_Depth_AllMetrics_RScores.csv\"])\n",
    "\n",
    "df10 = _first_csv(\"stage10\",[f\"Stage10_BestSubset_MasterTable_{SWAN_YEAR}.csv\"])\n",
    "\n",
    "if df3 is None:\n",
    "    raise RuntimeError(\"Stage-03 artefacts missing â€” cannot proceed.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2 Â· BACKBONE MASTER TABLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "METRICS = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "           \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "           \"TotalRevenue\",\"GrossProfit\"]\n",
    "\n",
    "flag_cols = [f\"flag_{m.lower()}\" for m in METRICS if f\"flag_{m.lower()}\" in df3.columns]\n",
    "backbone  = df3[[ID_COL, DATE_COL] + flag_cols].copy()\n",
    "\n",
    "def _merge_prob(src:pd.DataFrame|None, suffix:str, base:pd.DataFrame)->pd.DataFrame:\n",
    "    if src is None: return base\n",
    "    cols = [c for c in src.columns if c.endswith(suffix)]\n",
    "    if not cols:     return base\n",
    "    return base.merge(src[[ID_COL,DATE_COL]+cols], on=[ID_COL,DATE_COL], how=\"left\", copy=False)\n",
    "\n",
    "backbone = _merge_prob(df6_speed, \"_rise_prob\",          backbone)\n",
    "backbone = _merge_prob(df6_stage, \"_stagerise_prob\",     backbone)  # legacy\n",
    "backbone = _merge_prob(df6_depth, \"_depthrise_prob\",     backbone)\n",
    "backbone = _merge_prob(df6_blend, \"_blendrise_prob\",     backbone)\n",
    "backbone = _merge_prob(df8_speed, f\"_pre{SWAN_YEAR}\",    backbone)\n",
    "backbone = _merge_prob(df8_depth, f\"_depthpre{SWAN_YEAR}\", backbone)\n",
    "\n",
    "backbone[DATE_COL] = pd.to_datetime(backbone[DATE_COL], errors=\"coerce\")\n",
    "log.info(\"Backbone shape: %d rows Ã— %d cols\", *backbone.shape)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3 Â· AUROC QUALITY TABLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "snap = backbone[backbone[DATE_COL].dt.year == PRE_YEAR]\n",
    "\n",
    "def _safe_auc(y:pd.Series, pcol:str)->float|np.nan:\n",
    "    if pcol not in snap.columns:                  return np.nan\n",
    "    m = y.notna() & snap[pcol].notna()\n",
    "    if m.sum()<6 or y[m].nunique()<2:             return np.nan\n",
    "    try:  return roc_auc_score(y[m], snap.loc[m,pcol])\n",
    "    except ValueError: return np.nan\n",
    "\n",
    "rows=[]\n",
    "for m in METRICS:\n",
    "    flag = f\"flag_{m.lower()}\"\n",
    "    if flag not in snap.columns: continue\n",
    "    y = snap[flag]\n",
    "    rows.append({\n",
    "        \"Metric\":           m,\n",
    "        \"AUROC_speed\" : _safe_auc(y,f\"{m.lower()}_rise_prob\"),\n",
    "        \"AUROC_stage\" : _safe_auc(y,f\"{m.lower()}_stagerise_prob\"),\n",
    "        \"AUROC_depth\" : _safe_auc(y,f\"{m.lower()}_depthrise_prob\"),\n",
    "        \"AUROC_blend\" : _safe_auc(y,f\"{m.lower()}_blendrise_prob\"),\n",
    "        \"AUROC_lasso\" : _safe_auc(y,f\"rscoreprob_{m.lower()}_pre{SWAN_YEAR}\"),\n",
    "        \"AUROC_lassoDepth\":_safe_auc(y,f\"rscoredepthprob_{m.lower()}_pre{SWAN_YEAR}\")\n",
    "    })\n",
    "quality = pd.DataFrame(rows).round(3)\n",
    "quality.to_csv(STAGE_DIR/f\"11_ModelQuality_{SWAN_YEAR}.csv\", index=False)\n",
    "\n",
    "print(f\"\\n=== AUROC snapshot FY-{PRE_YEAR} ===\")\n",
    "print(quality.to_string(index=False))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4 Â· RATIO FREQUENCY (Stage-10) â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if df10 is not None and \"ratio\" in [c.lower() for c in df10.columns]:\n",
    "    rcol = next(c for c in df10.columns if c.lower()==\"ratio\")\n",
    "    freq =(df10[rcol].str.lower().value_counts().rename(\"AppearsIn\")\n",
    "                 .loc[lambda s:s>=3])\n",
    "    if not freq.empty:\n",
    "        freq.to_csv(STAGE_DIR/f\"11_BestSubset_RatioFrequency_{SWAN_YEAR}.csv\")\n",
    "        print(\"\\nRatios appearing in â‰¥3 best-subset models:\")\n",
    "        print(freq.to_string())\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5 Â· DUMP PROBABILITY MATRIX â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "prob_cols = [c for c in backbone.columns if c.endswith((\n",
    "                \"_rise_prob\",\"_stagerise_prob\",\"_depthrise_prob\",\"_blendrise_prob\",\n",
    "                f\"_pre{SWAN_YEAR}\",f\"_depthpre{SWAN_YEAR}\"))]\n",
    "if prob_cols:\n",
    "    backbone[[ID_COL,DATE_COL]+prob_cols]\\\n",
    "        .to_csv(STAGE_DIR/f\"11_RISE_Probabilities_All_{SWAN_YEAR}.csv\",index=False)\n",
    "    log.info(\"Probability matrix saved with %d columns\", len(prob_cols))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 6 Â· RUN-METADATA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "meta = {\n",
    "    \"Unique firms (Stage3)\"       : df3[ID_COL].nunique(),\n",
    "    \"Records in Stage3\"           : len(df3),\n",
    "    \"Records in Stage5A\"          : len(df5)   if df5   is not None else np.nan,\n",
    "    \"Rows with speed prob\"        : len(df6_speed) if df6_speed is not None else np.nan,\n",
    "    \"Rows with depth prob\"        : len(df6_depth) if df6_depth is not None else np.nan,\n",
    "    \"Rows with blend prob\"        : len(df6_blend) if df6_blend is not None else np.nan,\n",
    "    f\"FY-{PRE_YEAR} snapshot rows\": len(snap)\n",
    "}\n",
    "pd.Series(meta).to_frame(\"Value\").to_csv(STAGE_DIR/f\"11_RunMetadata_{SWAN_YEAR}.csv\")\n",
    "\n",
    "print(\"\\nRun-metadata:\")\n",
    "for k,v in meta.items():\n",
    "    print(f\"{k:<32}{v:>10,.0f}\" if pd.notna(v) else f\"{k:<32} â€”\")\n",
    "\n",
    "log.info(\"ğŸ‰ Stage-11 complete â€” artefacts in %s\", STAGE_DIR)\n",
    "print(f\"\\nâœ… Stage-11 complete â€” outputs in {STAGE_DIR}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
