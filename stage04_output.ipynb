{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a959f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:43:10.961571Z",
     "iopub.status.busy": "2025-06-11T04:43:10.961571Z",
     "iopub.status.idle": "2025-06-11T04:43:10.971783Z",
     "shell.execute_reply": "2025-06-11T04:43:10.971783Z"
    },
    "papermill": {
     "duration": 0.016953,
     "end_time": "2025-06-11T04:43:10.974253",
     "exception": false,
     "start_time": "2025-06-11T04:43:10.957300",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "INPUT_CSV = \"C:/Users/Jason Pohl/OneDrive - Bond University/PhD/rff/NEW_DATA.csv\"\n",
    "OUTPUT_ROOT = \"C:/Users/Jason Pohl/OneDrive - Bond University/PhD/rff/outputs_rff\"\n",
    "STAGE1_CFG = \"\"\n",
    "SWAN_YEAR = 2008\n",
    "WIN_START = 2004\n",
    "WIN_END = 2012\n",
    "RUN_TAG = \"myUniqueRunId\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84336a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T04:43:10.979255Z",
     "iopub.status.busy": "2025-06-11T04:43:10.979255Z",
     "iopub.status.idle": "2025-06-11T04:45:03.738193Z",
     "shell.execute_reply": "2025-06-11T04:45:03.736198Z"
    },
    "papermill": {
     "duration": 112.762939,
     "end_time": "2025-06-11T04:45:03.739193",
     "exception": false,
     "start_time": "2025-06-11T04:43:10.976254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:12,536 | INFO    | ==========  STAGE 04: DIAGNOSTICS & LEADERBOARDS ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:12,538 | INFO    | RUN_DIR        : outputs_rff\\daily\\2025-06-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:12,539 | INFO    | SWAN_YEAR=2008  RUN_DATE=2025-06-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:12,540 | INFO    | MC_THRESH=0.95  MIN_COVERAGE=40.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:16,962 | INFO    | Stage 03 CSV loaded: 34862 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:17,011 | INFO    | Pre-SWAN sample size: 11204 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:17,013 | INFO    | Detected 229 ratios (229 raw + 229 winsor)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason Pohl\\AppData\\Local\\Temp\\ipykernel_40992\\1151574771.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return s if lo == hi else s.clip(lo, hi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:33,360 | INFO    | MC filter: dropping 65 winsor columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:35,063 | INFO    | Diagnostic CSVs written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:43:35,066 | INFO    | Ranking raw (229 columns)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:44:28,191 | INFO    | Ranking winsor (164 columns)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jason pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:45:03,719 | INFO    | ✅  STAGE 04 complete — artefacts in outputs_rff\\daily\\2025-06-11\\stage04\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stage 04 · Ratio Diagnostics & Leaderboards\n",
    "===========================================\n",
    "\n",
    "– Correlation (|ρ|) and Logit pseudo-R² / AUROC ranking for every ratio created\n",
    "  in Stage 03, plus multicollinearity filtering and descriptive stats.\n",
    "\n",
    "Outputs\n",
    "  <OUTPUT_ROOT>/event=<SWAN_YEAR>/<RUN_DATE>/stage04/\n",
    "      ├─ Stage4_raw_RatioDiagnostics.csv\n",
    "      ├─ Stage4_winsor_RatioDiagnostics.csv\n",
    "      ├─ Stage4_DroppedCollinearWinsor.csv\n",
    "      ├─ Stage4_<raw|winsor>_RatioRanking.csv\n",
    "      ├─ Stage4_<raw|winsor>_{Bucket|Stage|Domain|Overall}Top3.csv\n",
    "      └─ stage04.log\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── core imports ─────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import os, sys, logging, warnings, io\n",
    "from typing import Dict, List, Tuple, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.linalg import LinAlgError\n",
    "from statsmodels.tools.sm_exceptions import MissingDataError\n",
    "\n",
    "# ── shared helper -----------------------------------------------------\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 0 · CONFIG & PARAMS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "CFG: Dict        = load_cfg()\n",
    "DEFAULTS: Dict   = CFG.get(\"defaults\", {})\n",
    "EVENTS: Dict     = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "ST4_OVR: Dict    = CFG.get(\"stage4\", {})           # per-stage overrides\n",
    "\n",
    "SWAN_YEAR: str   = os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS))\n",
    "if SWAN_YEAR not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} not present in YAML events:\")\n",
    "SWAN_YEAR_INT: int = int(SWAN_YEAR)               # numeric version\n",
    "\n",
    "DATE_COL      = ST4_OVR.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL        = ST4_OVR.get(\"id_col\",   \"Symbol\")\n",
    "MC_THRESH     = float(os.getenv(\"MC_THRESH\",    ST4_OVR.get(\"mc_thresh\",    0.95)))\n",
    "MIN_COVERAGE  = float(os.getenv(\"MIN_COVERAGE\", ST4_OVR.get(\"min_coverage\", 40)))\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 1 · RUN-FOLDER RESOLUTION\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "RUN_DIR  = resolve_run_dir(must_have=\"stage03/Stage3_Data_WithRatios.csv\")\n",
    "RUN_DATE = RUN_DIR.name\n",
    "\n",
    "STAGE3_FILE = RUN_DIR / \"stage03\" / \"Stage3_Data_WithRatios.csv\"\n",
    "OUT_DIR     = RUN_DIR / \"stage04\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 2 · LOGGER\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"stage04.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"==========  STAGE 04: DIAGNOSTICS & LEADERBOARDS ==========\")\n",
    "logger.info(\"RUN_DIR        : %s\", RUN_DIR)\n",
    "logger.info(\"SWAN_YEAR=%s  RUN_DATE=%s\", SWAN_YEAR, RUN_DATE)\n",
    "logger.info(\"MC_THRESH=%.2f  MIN_COVERAGE=%.1f%%\", MC_THRESH, MIN_COVERAGE)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 3 · LOAD DATA  (memory → disk fallback)\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "if \"data_stage_3\" in globals():\n",
    "    df_full = globals()[\"data_stage_3\"].copy()\n",
    "    logger.info(\"Stage 03 data reused from memory: %d rows\", len(df_full))\n",
    "else:\n",
    "    df_full = pd.read_csv(STAGE3_FILE, parse_dates=[DATE_COL], low_memory=False)\n",
    "    logger.info(\"Stage 03 CSV loaded: %d rows\", len(df_full))\n",
    "\n",
    "# keep observations *before* the crisis year\n",
    "pre_df = df_full[df_full[DATE_COL].dt.year < SWAN_YEAR_INT].copy()\n",
    "if pre_df.empty:\n",
    "    raise ValueError(f\"No observations before SWAN_YEAR={SWAN_YEAR}\")\n",
    "logger.info(\"Pre-SWAN sample size: %d rows\", len(pre_df))\n",
    "\n",
    "# ░░░░░░░░░░░░░░░░░░  RATIO COLUMNS  ░░░░░░░░░░░░░░░░░░\n",
    "ratio_names: List[str] = sorted({c[:-4] for c in pre_df.columns\n",
    "                                 if c.endswith(\"_raw\") and c[:-4] in pre_df.columns})\n",
    "raw_cols  = [f\"{r}_raw\" for r in ratio_names]\n",
    "win_cols  = ratio_names     # winsorised copies already exist\n",
    "logger.info(\"Detected %d ratios (%d raw + %d winsor)\",\n",
    "            len(ratio_names), len(raw_cols), len(win_cols))\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 4 · WINSORISATION & MULTICOLLINEARITY\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def winsorise(s: pd.Series, pct: float = 0.01) -> pd.Series:\n",
    "    if s.notna().sum() < 3:\n",
    "        return s\n",
    "    lo, hi = np.nanpercentile(s.dropna(), [pct*100, (1-pct)*100])\n",
    "    return s if lo == hi else s.clip(lo, hi)\n",
    "\n",
    "wins_df = pre_df.copy()\n",
    "for c in win_cols:\n",
    "    wins_df[c] = winsorise(wins_df[c])\n",
    "\n",
    "# Spearman |ρ| ≥ MC_THRESH → drop lower-coverage column\n",
    "corr = wins_df[win_cols].corr(method=\"spearman\").abs()\n",
    "mask = np.triu(np.ones(corr.shape), 1).astype(bool)\n",
    "high_pairs = corr.where(mask).stack().loc[lambda s: s >= MC_THRESH]\n",
    "\n",
    "drop_mc: Set[str] = set()\n",
    "for (c1, c2), _ in high_pairs.sort_values(ascending=False).items():\n",
    "    if c1 in drop_mc or c2 in drop_mc:\n",
    "        continue\n",
    "    keep, drop = (c1, c2) if wins_df[c1].notna().mean() >= wins_df[c2].notna().mean() else (c2, c1)\n",
    "    drop_mc.add(drop)\n",
    "\n",
    "if drop_mc:\n",
    "    logger.info(\"MC filter: dropping %d winsor columns\", len(drop_mc))\n",
    "    pd.Series(sorted(drop_mc), name=\"Dropped_Winsor_Columns\")\\\n",
    "        .to_csv(OUT_DIR / \"Stage4_DroppedCollinearWinsor.csv\", index=False)\n",
    "    win_cols = [c for c in win_cols if c not in drop_mc]\n",
    "    wins_df.drop(columns=list(drop_mc), inplace=True)\n",
    "else:\n",
    "    logger.info(\"MC filter: no columns dropped\")\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 5 · DIAGNOSTIC STATS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def _write_diag(base: pd.DataFrame, cols: List[str], tag: str):\n",
    "    diag = (\n",
    "        base.assign(Year=base[DATE_COL].dt.year)\n",
    "            .groupby(\"Year\")[cols]\n",
    "            .agg(['mean', 'std', 'median', 'min', 'max', 'count'])\n",
    "            .stack(level=1)\n",
    "            .reset_index()\n",
    "    )\n",
    "    diag.to_csv(OUT_DIR / f\"Stage4_{tag}_RatioDiagnostics.csv\", index=False)\n",
    "\n",
    "_write_diag(pre_df,  raw_cols,  \"raw\")\n",
    "_write_diag(wins_df, win_cols, \"winsor\")\n",
    "logger.info(\"Diagnostic CSVs written\")\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 6 · RANKING LOGIC\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "METRICS    = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\n",
    "              \"EBITDA\",\"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\n",
    "              \"CashAndCashEquivalents\",\"TotalRevenue\",\"GrossProfit\"]\n",
    "score_cols = [f\"Score_{m}\" for m in METRICS]\n",
    "flag_cols  = [f\"Flag_{m}\"  for m in METRICS]\n",
    "\n",
    "def _abs_spearman(x: pd.Series, y: pd.Series, min_obs=100):\n",
    "    ok = x.notna() & y.notna()\n",
    "    return np.nan if ok.sum() < min_obs else abs(spearmanr(x[ok], y[ok]).correlation)\n",
    "\n",
    "def _logit_stats(x: pd.Series, y_flag: pd.Series, min_obs=100) -> Tuple[float,float]:\n",
    "    ok = x.notna() & y_flag.isin([0,1])\n",
    "    if ok.sum() < min_obs or y_flag[ok].nunique() < 2 or x[ok].nunique() < 2:\n",
    "        return np.nan, np.nan\n",
    "    try:\n",
    "        mdl = sm.Logit(y_flag[ok], sm.add_constant(x[ok])).fit(disp=False)\n",
    "        return mdl.prsquared, roc_auc_score(y_flag[ok], mdl.predict())\n",
    "    except (ValueError, LinAlgError, MissingDataError):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# bucket / stage / domain maps (populated if Stage 03 ran in this session)\n",
    "ratio_to_buckets: Dict[str, List[str]] = {\n",
    "    r: (bs if isinstance(bs, (list, tuple)) else [bs])\n",
    "    for r, bs in globals().get(\"ratio_domain_stage_map\", {}).items()\n",
    "}\n",
    "domains = {\"Phys\", \"Info\", \"Cog\", \"Soc\"}\n",
    "stages  = {\"Prepare\", \"Absorb\", \"Recover\", \"Adapt\"}\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 7 · RANK LOOP\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def _rank(tag: str, cols: List[str], base: pd.DataFrame):\n",
    "    logger.info(\"Ranking %s (%d columns)…\", tag, len(cols))\n",
    "\n",
    "    rows = []\n",
    "    for col in cols:\n",
    "        cov_pct = base[col].notna().mean() * 100\n",
    "        if cov_pct < MIN_COVERAGE:\n",
    "            continue\n",
    "        x = base[col]\n",
    "        for m, sc, fc in zip(METRICS, score_cols, flag_cols):\n",
    "            rho  = _abs_spearman(x, base[sc])\n",
    "            pr2, auc = _logit_stats(x, base[fc])\n",
    "            rows.append({\"Ratio\": col.replace(\"_raw\",\"\"),\n",
    "                         \"Metric\": m,\n",
    "                         \"Coverage%\": round(cov_pct, 1),\n",
    "                         \"|rho|\":     round(rho,  3) if pd.notna(rho) else np.nan,\n",
    "                         \"PseudoR2\":  round(pr2,  3) if pd.notna(pr2) else np.nan,\n",
    "                         \"AUROC\":     round(auc,  3) if pd.notna(auc) else np.nan})\n",
    "    rk = pd.DataFrame(rows)\n",
    "    rk.to_csv(OUT_DIR / f\"Stage4_{tag}_RatioRanking.csv\", index=False)\n",
    "\n",
    "    # ---- selector maps ------------------------------------------------\n",
    "    bucket_map = ratio_to_buckets or {\"All\": [c.replace(\"_raw\",\"\") for c in cols]}\n",
    "    stage_map  = {stg: [r for r, bs in bucket_map.items()\n",
    "                        if any(str(b).endswith(f\"-{stg}\") for b in bs)]\n",
    "                  for stg in stages}\n",
    "    domain_map = {dom: [r for r, bs in bucket_map.items()\n",
    "                        if any(str(b).startswith(dom) for b in bs)]\n",
    "                  for dom in domains}\n",
    "\n",
    "    def _top3(df):  # pick top-3 by |rho|\n",
    "        return df.nlargest(3, \"|rho|\")\n",
    "\n",
    "    # (a) bucket leaderboard\n",
    "    bucket_rows = []\n",
    "    for bucket, members in bucket_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                bucket_rows.append({\"Bucket\": bucket, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(bucket_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_BucketTop3.csv\",\n",
    "                                     index=False)\n",
    "\n",
    "    # (b) stage leaderboard\n",
    "    stage_rows = []\n",
    "    for stg, members in stage_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                stage_rows.append({\"Stage\": stg, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(stage_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_StageTop3.csv\",\n",
    "                                    index=False)\n",
    "\n",
    "    # (c) domain leaderboard\n",
    "    domain_rows = []\n",
    "    for dom, members in domain_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                domain_rows.append({\"Domain\": dom, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(domain_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_DomainTop3.csv\",\n",
    "                                     index=False)\n",
    "\n",
    "    # (d) overall leaderboard\n",
    "    overall = []\n",
    "    for metric in METRICS:\n",
    "        for _, r in _top3(rk[rk[\"Metric\"] == metric]).iterrows():\n",
    "            overall.append(r.drop(\"Ratio\").to_dict())\n",
    "    pd.DataFrame(overall).to_csv(OUT_DIR / f\"Stage4_{tag}_OverallTop3.csv\",\n",
    "                                 index=False)\n",
    "\n",
    "# ── run rankings ─────────────────────────────────────────────────────\n",
    "_rank(\"raw\",    raw_cols,  pre_df)\n",
    "_rank(\"winsor\", win_cols, wins_df)\n",
    "\n",
    "logger.info(\"✅  STAGE 04 complete — artefacts in %s\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 114.874672,
   "end_time": "2025-06-11T04:45:04.192906",
   "environment_variables": {},
   "exception": null,
   "input_path": "stage04.ipynb",
   "output_path": "stage04_output.ipynb",
   "parameters": {
    "INPUT_CSV": "C:/Users/Jason Pohl/OneDrive - Bond University/PhD/rff/NEW_DATA.csv",
    "OUTPUT_ROOT": "C:/Users/Jason Pohl/OneDrive - Bond University/PhD/rff/outputs_rff",
    "RUN_TAG": "myUniqueRunId",
    "STAGE1_CFG": "",
    "SWAN_YEAR": 2008,
    "WIN_END": 2012,
    "WIN_START": 2004
   },
   "start_time": "2025-06-11T04:43:09.318234",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}