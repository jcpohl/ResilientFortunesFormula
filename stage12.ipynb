{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:40:13,389 | INFO    | ==========  STAGE 12 ==========\n",
      "2025-06-11 10:40:13,390 | INFO    | RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250610  SWAN_YEAR=2008  RUN_DATE=20250610\n",
      "2025-06-11 10:40:20,189 | INFO    | Snapshot rows: 974\n",
      "2025-06-11 10:40:20,229 | INFO    | Matrix for PCA: 941 firms × 204 ratios\n",
      "2025-06-11 10:40:20,433 | INFO    | k=1 PCs capture 12.2 % variance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 493, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 1311, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 10:40:22,442 | INFO    | Best k = 2  (silhouette = 0.718)\n",
      "2025-06-11 10:40:22,486 | INFO    | Sector × cluster table written\n",
      "2025-06-11 10:40:22,494 | INFO    | ✓ Stage 12 complete – artefacts in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250610\\stage12\n",
      "\n",
      "✓ Stage 12 complete – outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250610\\stage12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Stage-12 · FY-PRE PCA ➜ K-means clustering\n",
    "==========================================\n",
    "\n",
    "Part A  Snapshot (FY-PRE) ratio matrix ➜ PCA  \n",
    "Part B  PCA scores ➜ best-k K-means\n",
    "\n",
    "Artefacts written to  <run>/stage12/\n",
    "  Stage12A_PCA_Variance.csv\n",
    "  Stage12A_PCA_Loadings.csv\n",
    "  Stage12B_PCA_Scores.csv\n",
    "  Stage12B_ClusterLabels.csv\n",
    "  Stage12B_ClusterSummary.csv\n",
    "  Stage12B_SectorCluster_Table.csv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── stdlib / 3-rd-party ────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import os, sys, logging, warnings\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import yaml, matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ── shared helpers ─────────────────────────────────────────────────\n",
    "from pipeline_utils import load_cfg, resolve_run_dir     # NEW\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 0 · BOOTSTRAP  (config · run-folder · logger)                       #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "CFG: Dict      = load_cfg()\n",
    "EVENTS: Dict   = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "\n",
    "SWAN_YEAR_STR  = os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS))\n",
    "if SWAN_YEAR_STR not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR_STR} missing in events block\")\n",
    "SWAN_YEAR      = int(SWAN_YEAR_STR)\n",
    "PRE_YEAR       = SWAN_YEAR - 1\n",
    "\n",
    "RUN_DIR        = resolve_run_dir(must_have=\"stage03/Stage3_Data_WithRatios.csv\")\n",
    "RUN_DATE       = RUN_DIR.name\n",
    "STAGE3_FILE    = RUN_DIR / \"stage03\" / \"Stage3_Data_WithRatios.csv\"\n",
    "\n",
    "STAGE_DIR      = RUN_DIR / \"stage12\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(STAGE_DIR / \"stage12.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 12 ==========\")\n",
    "log.info(\"RUN_DIR=%s  SWAN_YEAR=%s  RUN_DATE=%s\", RUN_DIR, SWAN_YEAR, RUN_DATE)\n",
    "\n",
    "# ── env-overridable knobs ──────────────────────────────────────────\n",
    "MIN_ROW_CVR = float(os.getenv(\"MIN_ROW_CVR\", 0.60))\n",
    "MIN_COL_CVR = float(os.getenv(\"MIN_COL_CVR\", 0.60))\n",
    "MAX_PC      = int(os.getenv(\"MAX_PC\", 20))\n",
    "VAR_THRESH  = float(os.getenv(\"VAR_THRESH\", 90.0))\n",
    "K_RANGE     = range(*map(int, os.getenv(\"K_RANGE\", \"2,11\").split(\",\")))\n",
    "ID_COL      = os.getenv(\"ID_COL\", \"Symbol\")\n",
    "DATE_COL    = os.getenv(\"DATE_COL\", \"ReportDate\")\n",
    "SECTOR_COL  = os.getenv(\"SECTOR_COL\", \"SectorName\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 1 · LOAD FY-PRE SNAPSHOT                                           #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "df = pd.read_csv(STAGE3_FILE, low_memory=False)\n",
    "df.columns = [c.lower().strip() for c in df.columns]\n",
    "\n",
    "date_col = DATE_COL.lower()\n",
    "if date_col not in df.columns:\n",
    "    alt = [c for c in df.columns if \"reportdate\" in c]\n",
    "    if not alt:\n",
    "        raise KeyError(f\"'{DATE_COL}' column not found in Stage-03 file\")\n",
    "    date_col = alt[0]\n",
    "    log.warning(\"DATE_COL not found exactly; using '%s'\", date_col)\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "df_pre = df[df[date_col].dt.year == PRE_YEAR].copy()\n",
    "if df_pre.empty:\n",
    "    raise RuntimeError(f\"No FY-{PRE_YEAR} snapshot rows\")\n",
    "log.info(\"Snapshot rows: %s\", f\"{len(df_pre):,}\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 2 · RATIO MATRIX & ROW FILTER                                      #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "ignore = {ID_COL.lower(), date_col}\n",
    "ratio_cols = [c for c in df_pre.columns\n",
    "              if c not in ignore\n",
    "              and df_pre[c].dtype.kind in \"fi\"\n",
    "              and \"_\" in c\n",
    "              and not c.endswith(\"_raw\")]\n",
    "\n",
    "mat = df_pre[ratio_cols].replace([np.inf, -np.inf], np.nan)\n",
    "mat = mat.loc[:,  mat.notna().mean() >= MIN_COL_CVR]\n",
    "mat = mat.loc[   mat.notna().mean(axis=1) >= MIN_ROW_CVR]\n",
    "if mat.shape[1] < 2:\n",
    "    raise RuntimeError(\"Matrix too sparse after coverage filters\")\n",
    "log.info(\"Matrix for PCA: %d firms × %d ratios\", *mat.shape)\n",
    "\n",
    "# keep filtered rows going forward\n",
    "snap = df_pre.loc[mat.index].copy()\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 3 · PCA                                                            #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "Z   = StandardScaler().fit_transform(SimpleImputer(strategy=\"median\").fit_transform(mat))\n",
    "pca = PCA(n_components=min(MAX_PC, Z.shape[1]), random_state=42).fit(Z)\n",
    "cum = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "k_keep = np.argmax(cum >= VAR_THRESH) + 1\n",
    "log.info(\"k=%d PCs capture %.1f %% variance\", k_keep, cum[k_keep-1])\n",
    "\n",
    "(pd.DataFrame({\"PC\": [f\"PC{i+1}\" for i in range(len(cum))],\n",
    "               \"Eigen%\": (pca.explained_variance_ratio_*100).round(2),\n",
    "               \"Cum%\": cum.round(2)})\n",
    "   .set_index(\"PC\")\n",
    "   .to_csv(STAGE_DIR / \"Stage12A_PCA_Variance.csv\"))\n",
    "\n",
    "(pd.DataFrame(pca.components_.T,\n",
    "              index   = mat.columns,\n",
    "              columns = [f\"PC{i+1}\" for i in range(pca.n_components_)])\n",
    "   .reset_index()\n",
    "   .rename(columns={\"index\": \"ratio\"})\n",
    "   .to_csv(STAGE_DIR / \"Stage12A_PCA_Loadings.csv\", index=False))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 4 · PCA SCORES & K-MEANS                                           #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "loadings = pd.read_csv(STAGE_DIR / \"Stage12A_PCA_Loadings.csv\").set_index(\"ratio\")\n",
    "pc_cols  = [f\"PC{i+1}\" for i in range(k_keep)]\n",
    "scores   = Z @ loadings[pc_cols].values\n",
    "scores_df = (pd.DataFrame(scores, columns=pc_cols, index=snap.index)\n",
    "               .assign(**{ID_COL.lower(): snap[ID_COL.lower()].values}))\n",
    "scores_df.to_csv(STAGE_DIR / \"Stage12B_PCA_Scores.csv\", index=False)\n",
    "\n",
    "sil, models = [], {}\n",
    "X = scores_df[pc_cols].values\n",
    "for k in K_RANGE:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=42).fit(X)\n",
    "    sil.append(silhouette_score(X, km.labels_))\n",
    "    models[k] = km\n",
    "best_k = max(models, key=lambda k: sil[K_RANGE.index(k)])\n",
    "km     = models[best_k]\n",
    "snap[\"cluster\"] = km.labels_\n",
    "\n",
    "snap[[ID_COL.lower(), \"cluster\"]]\\\n",
    "    .to_csv(STAGE_DIR / \"Stage12B_ClusterLabels.csv\", index=False)\n",
    "pd.DataFrame({\"k\": list(K_RANGE), \"silhouette\": sil})\\\n",
    "    .to_csv(STAGE_DIR / \"Stage12B_ClusterSummary.csv\", index=False)\n",
    "log.info(\"Best k = %d  (silhouette = %.3f)\", best_k, sil[K_RANGE.index(best_k)])\n",
    "\n",
    "sec_col = SECTOR_COL.lower()\n",
    "if sec_col in snap.columns:\n",
    "    pd.crosstab(snap[\"cluster\"], snap[sec_col])\\\n",
    "      .to_csv(STAGE_DIR / \"Stage12B_SectorCluster_Table.csv\")\n",
    "    log.info(\"Sector × cluster table written\")\n",
    "else:\n",
    "    log.warning(\"Column '%s' absent – sector table skipped\", SECTOR_COL)\n",
    "\n",
    "log.info(\"✓ Stage 12 complete – artefacts in %s\", STAGE_DIR)\n",
    "print(f\"\\n✓ Stage 12 complete – outputs in {STAGE_DIR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
