{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:27:15,405 | INFO    | ==========  STAGE 12  ==========\n",
      "2025-06-10 14:27:15,406 | INFO    | SWAN_YEAR=2008  RUN_DATE=20250609  RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\n",
      "2025-06-10 14:27:20,706 | INFO    | Snapshot rows: 974\n",
      "2025-06-10 14:27:20,730 | INFO    | Matrix for PCA: 941 firms × 204 ratios\n",
      "2025-06-10 14:27:20,845 | INFO    | k=1 PCs capture 12.2 % variance\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 493, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\Jason Pohl\\miniconda3\\lib\\subprocess.py\", line 1311, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "2025-06-10 14:27:22,755 | INFO    | Best k = 2  (silhouette = 0.718)\n",
      "2025-06-10 14:27:22,791 | INFO    | Sector × cluster table written\n",
      "2025-06-10 14:27:22,793 | INFO    | ✓  Stage 12 complete – artefacts in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Stage 12 complete – outputs in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Stage-12 · FY-PRE PCA  ➜  K-means clustering\n",
    "============================================\n",
    "\n",
    "Part A  Snapshot (FY-PRE) ratio matrix  ➜  PCA  \n",
    "Part B  PCA scores                      ➜  best-k K-means\n",
    "\n",
    "Outputs (all written to <run>/stage12/)\n",
    "---------------------------------------\n",
    "Stage12A_PCA_Variance.csv\n",
    "Stage12A_PCA_Loadings.csv\n",
    "Stage12B_PCA_Scores.csv\n",
    "Stage12B_ClusterLabels.csv\n",
    "Stage12B_ClusterSummary.csv\n",
    "Stage12B_SectorCluster_Table.csv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import os, sys, logging, warnings\n",
    "from pathlib import Path\n",
    "import yaml                          # config loader\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s | %(levelname)-7s | %(message)s\")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 0 · CONFIG & RUN-DIR DISCOVERY                                     #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "CFG_FILE = Path(os.getenv(\"PIPELINE_CFG\", \"pipeline_config.yaml\")).expanduser()\n",
    "if not CFG_FILE.is_file():\n",
    "    raise FileNotFoundError(f\"pipeline_config.yaml not found at {CFG_FILE}\")\n",
    "CFG       = yaml.safe_load(CFG_FILE.read_text()) or {}\n",
    "DEFAULTS  = CFG.get(\"defaults\", {})\n",
    "EVENTS    = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "\n",
    "SWAN_YEAR = int(os.getenv(\"SWAN_YEAR\", next(iter(EVENTS))))\n",
    "if str(SWAN_YEAR) not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} missing in config events\")\n",
    "PRE_YEAR  = SWAN_YEAR - 1\n",
    "\n",
    "OUTPUT_ROOT = Path(DEFAULTS[\"OUTPUT_ROOT\"]).expanduser()\n",
    "EVENT_DIR   = OUTPUT_ROOT / f\"event={SWAN_YEAR}\"\n",
    "\n",
    "RUN_DIR: Path | None = None\n",
    "if os.getenv(\"RUN_DIR\"):\n",
    "    RUN_DIR = Path(os.getenv(\"RUN_DIR\")).expanduser()\n",
    "elif os.getenv(\"RUN_DATE\"):\n",
    "    RUN_DIR = EVENT_DIR / os.getenv(\"RUN_DATE\")\n",
    "\n",
    "if RUN_DIR is None:\n",
    "    cands = list(EVENT_DIR.glob(\"*/stage03/Stage3_Data_WithRatios.csv\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"Stage-03 outputs not found – run Stage 03 first\")\n",
    "    STAGE3_FILE = max(cands, key=lambda p: p.stat().st_mtime)\n",
    "    RUN_DIR     = STAGE3_FILE.parents[1]\n",
    "else:\n",
    "    STAGE3_FILE = RUN_DIR / \"stage03\" / \"Stage3_Data_WithRatios.csv\"\n",
    "    if not STAGE3_FILE.is_file():\n",
    "        raise FileNotFoundError(f\"{STAGE3_FILE} missing – run Stage 03\")\n",
    "\n",
    "RUN_DATE  = RUN_DIR.name\n",
    "STAGE_DIR = RUN_DIR / \"stage12\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log.info(\"==========  STAGE 12  ==========\")\n",
    "log.info(\"SWAN_YEAR=%s  RUN_DATE=%s  RUN_DIR=%s\", SWAN_YEAR, RUN_DATE, RUN_DIR)\n",
    "\n",
    "# ── env-overridable knobs ───────────────────────────────────────────\n",
    "MIN_ROW_CVR = float(os.getenv(\"MIN_ROW_CVR\", 0.60))\n",
    "MIN_COL_CVR = float(os.getenv(\"MIN_COL_CVR\", 0.60))\n",
    "MAX_PC      = int(os.getenv(\"MAX_PC\", 20))\n",
    "VAR_THRESH  = float(os.getenv(\"VAR_THRESH\", 90.0))\n",
    "K_RANGE     = range(*map(int, os.getenv(\"K_RANGE\", \"2,11\").split(\",\")))\n",
    "ID_COL      = os.getenv(\"ID_COL\", \"Symbol\")\n",
    "DATE_COL    = os.getenv(\"DATE_COL\", \"ReportDate\")\n",
    "SECTOR_COL  = os.getenv(\"SECTOR_COL\", \"SectorName\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 1 · LOAD FY-PRE SNAPSHOT                                           #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "df = pd.read_csv(STAGE3_FILE, low_memory=False)\n",
    "df.columns = [c.lower().strip() for c in df.columns]\n",
    "\n",
    "date_col = DATE_COL.lower()\n",
    "if date_col not in df.columns:\n",
    "    alt = [c for c in df.columns if \"reportdate\" in c]\n",
    "    if not alt:\n",
    "        raise KeyError(f\"'{DATE_COL}' column not found in Stage-3 file\")\n",
    "    date_col = alt[0]\n",
    "    log.warning(\"DATE_COL not found exactly; using '%s'\", date_col)\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "df_pre = df[df[date_col].dt.year == PRE_YEAR].copy()\n",
    "if df_pre.empty:\n",
    "    raise RuntimeError(f\"No FY-{PRE_YEAR} snapshot rows\")\n",
    "log.info(\"Snapshot rows: %s\", f\"{len(df_pre):,}\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 2 · RATIO MATRIX & ROW FILTER                                      #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "ignore = {ID_COL.lower(), date_col}\n",
    "ratio_cols = [c for c in df_pre.columns\n",
    "              if c not in ignore\n",
    "              and df_pre[c].dtype.kind in \"fi\"\n",
    "              and \"_\" in c\n",
    "              and not c.endswith(\"_raw\")]\n",
    "\n",
    "mat = df_pre[ratio_cols].replace([np.inf, -np.inf], np.nan)\n",
    "mat = mat.loc[:,  mat.notna().mean() >= MIN_COL_CVR]\n",
    "mat = mat.loc[   mat.notna().mean(axis=1) >= MIN_ROW_CVR]\n",
    "if mat.shape[1] < 2:\n",
    "    raise RuntimeError(\"Matrix too sparse after coverage filters\")\n",
    "log.info(\"Matrix for PCA: %d firms × %d ratios\", *mat.shape)\n",
    "\n",
    "# keep *only* filtered rows for the remainder\n",
    "snap = df_pre.loc[mat.index].copy()\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 3 · PCA                                                            #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "Z   = StandardScaler().fit_transform(SimpleImputer(strategy=\"median\").fit_transform(mat))\n",
    "pca = PCA(n_components=min(MAX_PC, Z.shape[1]), random_state=42).fit(Z)\n",
    "cum = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "k_keep = np.argmax(cum >= VAR_THRESH) + 1\n",
    "log.info(\"k=%d PCs capture %.1f %% variance\", k_keep, cum[k_keep-1])\n",
    "\n",
    "(pd.DataFrame({\"PC\": [f\"PC{i+1}\" for i in range(len(cum))],\n",
    "               \"Eigen%\": (pca.explained_variance_ratio_*100).round(2),\n",
    "               \"Cum%\": cum.round(2)})\n",
    "   .set_index(\"PC\")\n",
    "   .to_csv(STAGE_DIR / \"Stage12A_PCA_Variance.csv\"))\n",
    "\n",
    "(pd.DataFrame(pca.components_.T,\n",
    "              index   = mat.columns,\n",
    "              columns = [f\"PC{i+1}\" for i in range(pca.n_components_)])\n",
    "   .reset_index()\n",
    "   .rename(columns={\"index\": \"ratio\"})\n",
    "   .to_csv(STAGE_DIR / \"Stage12A_PCA_Loadings.csv\", index=False))\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# 4 · PCA SCORES & K-MEANS                                           #\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "loadings = pd.read_csv(STAGE_DIR / \"Stage12A_PCA_Loadings.csv\").set_index(\"ratio\")\n",
    "pc_cols  = [f\"PC{i+1}\" for i in range(k_keep)]\n",
    "scores   = Z @ loadings[pc_cols].values\n",
    "scores_df = (pd.DataFrame(scores, columns=pc_cols, index=snap.index)\n",
    "               .assign(**{ID_COL.lower(): snap[ID_COL.lower()].values}))\n",
    "scores_df.to_csv(STAGE_DIR / \"Stage12B_PCA_Scores.csv\", index=False)\n",
    "\n",
    "sil, models = [], {}\n",
    "X = scores_df[pc_cols].values\n",
    "for k in K_RANGE:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=42).fit(X)\n",
    "    sil.append(silhouette_score(X, km.labels_))\n",
    "    models[k] = km\n",
    "best_k = max(models, key=lambda k: sil[K_RANGE.index(k)])\n",
    "km     = models[best_k]\n",
    "snap[\"cluster\"] = km.labels_\n",
    "\n",
    "snap[[ID_COL.lower(), \"cluster\"]]\\\n",
    "    .to_csv(STAGE_DIR / \"Stage12B_ClusterLabels.csv\", index=False)\n",
    "pd.DataFrame({\"k\": list(K_RANGE), \"silhouette\": sil})\\\n",
    "    .to_csv(STAGE_DIR / \"Stage12B_ClusterSummary.csv\", index=False)\n",
    "log.info(\"Best k = %d  (silhouette = %.3f)\", best_k, sil[K_RANGE.index(best_k)])\n",
    "\n",
    "sec_col = SECTOR_COL.lower()\n",
    "if sec_col in snap.columns:\n",
    "    pd.crosstab(snap[\"cluster\"], snap[sec_col])\\\n",
    "      .to_csv(STAGE_DIR / \"Stage12B_SectorCluster_Table.csv\")\n",
    "    log.info(\"Sector × cluster table written\")\n",
    "else:\n",
    "    log.warning(\"Column '%s' absent – sector table skipped\", SECTOR_COL)\n",
    "\n",
    "log.info(\"✓  Stage 12 complete – artefacts in %s\", STAGE_DIR)\n",
    "print(f\"\\n✓ Stage 12 complete – outputs in {STAGE_DIR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
