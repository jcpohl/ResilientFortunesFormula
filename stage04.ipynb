{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:15,321 | INFO    | ==========  STAGE 04: DIAGNOSTICS & LEADERBOARDS ==========\n",
      "2025-06-10 12:53:15,324 | INFO    | Config        : pipeline_config.yaml\n",
      "2025-06-10 12:53:15,326 | INFO    | SWAN_YEAR=2008  RUN_DATE=20250609  RUN_DIR=C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\n",
      "2025-06-10 12:53:15,327 | INFO    | MC_THRESH=0.95  MIN_COVERAGE=40.0%\n",
      "2025-06-10 12:53:20,963 | INFO    | Stage 03 CSV loaded: 34862 rows\n",
      "2025-06-10 12:53:21,058 | INFO    | Pre-SWAN sample size: 11204 rows\n",
      "2025-06-10 12:53:21,060 | INFO    | Detected 229 ratios (229 raw + 229 winsor)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason Pohl\\AppData\\Local\\Temp\\ipykernel_35848\\230431602.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return s if lo == hi else s.clip(lo, hi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:37,202 | INFO    | MC filter: dropping 65 winsor columns\n",
      "2025-06-10 12:53:38,402 | INFO    | Diagnostic CSVs written\n",
      "2025-06-10 12:53:38,404 | INFO    | Ranking raw (229 columns)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:54:30,954 | INFO    | Ranking winsor (164 columns)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Jason Pohl\\miniconda3\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:55:17,290 | INFO    | ✅  STAGE 04 complete — artefacts in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage04\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stage 04 · Ratio Diagnostics & Leaderboards\n",
    "===========================================\n",
    "\n",
    "– Correlation (|ρ|) and Logit pseudo-R²/AUROC ranking for every ratio created\n",
    "  in Stage 03, plus multicollinearity filtering and descriptive stats.\n",
    "\n",
    "Dynamic file-finding logic\n",
    "--------------------------\n",
    "The script no longer assumes a *numeric* RUN_DATE folder.  If Stage 03 was run\n",
    "earlier in the same session we reuse the in-memory `data_stage_3` frame.\n",
    "Otherwise we locate the most-recent Stage 03 CSV by scanning every sub-folder\n",
    "under  rff/outputs_rff/event=<SWAN_YEAR>/.\n",
    "\n",
    "Outputs   (written to the same run folder discovered above)\n",
    "  stage04/\n",
    "      Stage4_raw_RatioDiagnostics.csv\n",
    "      Stage4_winsor_RatioDiagnostics.csv\n",
    "      Stage4_DroppedCollinearWinsor.csv\n",
    "      Stage4_<raw|winsor>_RatioRanking.csv\n",
    "      Stage4_<raw|winsor>_{Bucket|Stage|Domain|Overall}Top3.csv\n",
    "      stage04.log\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "# ── imports ──────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "import os, sys, logging, yaml, warnings, io, re\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.linalg import LinAlgError\n",
    "from statsmodels.tools.sm_exceptions import MissingDataError\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 0 · PIPELINE CONFIG\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "CFG_FILE = Path(os.getenv(\"PIPELINE_CFG\", \"pipeline_config.yaml\")).expanduser()\n",
    "if not CFG_FILE.is_file():\n",
    "    raise FileNotFoundError(f\"pipeline_config.yaml not found at {CFG_FILE}\")\n",
    "\n",
    "with CFG_FILE.open(encoding=\"utf-8\") as fh:\n",
    "    CFG: Dict = yaml.safe_load(fh) or {}\n",
    "\n",
    "DEFAULTS   = CFG.get(\"defaults\", {})\n",
    "EVENTS     = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "ST4_OVR    = CFG.get(\"stage4\", {})           # optional per-stage overrides\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 1 · PARAMETERS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "SWAN_YEAR = int(os.getenv(\"SWAN_YEAR\", next(iter(EVENTS))))\n",
    "if str(SWAN_YEAR) not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} missing in pipeline_config events:\")\n",
    "\n",
    "DATE_COL      = ST4_OVR.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL        = ST4_OVR.get(\"id_col\",   \"Symbol\")\n",
    "MC_THRESH     = float(os.getenv(\"MC_THRESH\",    ST4_OVR.get(\"mc_thresh\",    0.95)))\n",
    "MIN_COVERAGE  = float(os.getenv(\"MIN_COVERAGE\", ST4_OVR.get(\"min_coverage\", 40)))\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 2 · PATH RESOLUTION (robust, no numeric run-folder assumption)\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "OUTPUT_ROOT = Path(DEFAULTS[\"OUTPUT_ROOT\"]).expanduser()\n",
    "EVENT_DIR   = OUTPUT_ROOT / f\"event={SWAN_YEAR}\"\n",
    "\n",
    "# (a) user can override the run folder directly\n",
    "RUN_DIR: Path | None = None\n",
    "if os.getenv(\"RUN_DIR\"):\n",
    "    RUN_DIR = Path(os.getenv(\"RUN_DIR\")).expanduser()\n",
    "elif os.getenv(\"RUN_DATE\"):\n",
    "    RUN_DIR = EVENT_DIR / os.getenv(\"RUN_DATE\")\n",
    "\n",
    "# (b) auto-discover latest Stage-3 CSV if not provided\n",
    "if RUN_DIR is None:\n",
    "    if not EVENT_DIR.is_dir():\n",
    "        raise FileNotFoundError(f\"No outputs for event={SWAN_YEAR} at {EVENT_DIR}\")\n",
    "    # locate *any* Stage3 CSV inside event folder\n",
    "    candidates = list(EVENT_DIR.glob(\"*/stage03/Stage3_Data_WithRatios.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No Stage3_Data_WithRatios.csv found under {EVENT_DIR}.  Run Stage 03.\"\n",
    "        )\n",
    "    # pick the newest file by mtime; could also sort by folder name\n",
    "    STAGE3_FILE = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "    RUN_DIR     = STAGE3_FILE.parents[1]          # …/<run_tag>/\n",
    "else:\n",
    "    STAGE3_FILE = RUN_DIR / \"stage03\" / \"Stage3_Data_WithRatios.csv\"\n",
    "    if not STAGE3_FILE.is_file():\n",
    "        raise FileNotFoundError(f\"Stage-03 CSV not found at {STAGE3_FILE}\")\n",
    "\n",
    "RUN_DATE = RUN_DIR.name\n",
    "OUT_DIR  = RUN_DIR / \"stage04\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 3 · LOGGER\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"stage04.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"==========  STAGE 04: DIAGNOSTICS & LEADERBOARDS ==========\")\n",
    "logger.info(\"Config        : %s\", CFG_FILE)\n",
    "logger.info(\"SWAN_YEAR=%s  RUN_DATE=%s  RUN_DIR=%s\", SWAN_YEAR, RUN_DATE, RUN_DIR)\n",
    "logger.info(\"MC_THRESH=%.2f  MIN_COVERAGE=%.1f%%\", MC_THRESH, MIN_COVERAGE)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 4 · LOAD DATA  (memory → disk fallback)\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "if \"data_stage_3\" in globals():\n",
    "    df_full = globals()[\"data_stage_3\"].copy()\n",
    "    logger.info(\"Stage 03 data reused from memory: %d rows\", len(df_full))\n",
    "else:\n",
    "    df_full = pd.read_csv(STAGE3_FILE, parse_dates=[DATE_COL], low_memory=False)\n",
    "    logger.info(\"Stage 03 CSV loaded: %d rows\", len(df_full))\n",
    "\n",
    "# keep observations **before** the crisis\n",
    "pre_df = df_full[df_full[DATE_COL].dt.year < SWAN_YEAR].copy()\n",
    "if pre_df.empty:\n",
    "    raise ValueError(f\"No observations before SWAN_YEAR={SWAN_YEAR}\")\n",
    "logger.info(\"Pre-SWAN sample size: %d rows\", len(pre_df))\n",
    "\n",
    "# ░░░░░░░░░░░░░░░░░░  RATIO COLUMNS  ░░░░░░░░░░░░░░░░░░\n",
    "ratio_names: List[str] = sorted({c[:-4] for c in pre_df.columns\n",
    "                                 if c.endswith(\"_raw\") and c[:-4] in pre_df.columns})\n",
    "raw_cols  = [f\"{r}_raw\" for r in ratio_names]\n",
    "win_cols  = ratio_names    # winsorised copies exist from Stage 03\n",
    "logger.info(\"Detected %d ratios (%d raw + %d winsor)\",\n",
    "            len(ratio_names), len(raw_cols), len(win_cols))\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 5 · WINSORISATION & MULTICOLLINEARITY\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def winsorise(s: pd.Series, pct: float = 0.01) -> pd.Series:\n",
    "    if s.notna().sum() < 3:\n",
    "        return s\n",
    "    lo, hi = np.nanpercentile(s.dropna(), [pct*100, (1-pct)*100])\n",
    "    return s if lo == hi else s.clip(lo, hi)\n",
    "\n",
    "wins_df = pre_df.copy()\n",
    "for c in win_cols:\n",
    "    wins_df[c] = winsorise(wins_df[c])\n",
    "\n",
    "# Spearman |ρ| ≥ MC_THRESH → drop lower-coverage column\n",
    "corr = wins_df[win_cols].corr(method=\"spearman\").abs()\n",
    "mask = np.triu(np.ones(corr.shape), 1).astype(bool)\n",
    "high_pairs = corr.where(mask).stack().loc[lambda s: s >= MC_THRESH]\n",
    "\n",
    "drop_mc: Set[str] = set()\n",
    "for (c1, c2), _ in high_pairs.sort_values(ascending=False).items():\n",
    "    if c1 in drop_mc or c2 in drop_mc:\n",
    "        continue\n",
    "    keep, drop = (c1, c2) if wins_df[c1].notna().mean() >= wins_df[c2].notna().mean() else (c2, c1)\n",
    "    drop_mc.add(drop)\n",
    "\n",
    "if drop_mc:\n",
    "    logger.info(\"MC filter: dropping %d winsor columns\", len(drop_mc))\n",
    "    pd.Series(sorted(drop_mc), name=\"Dropped_Winsor_Columns\")\\\n",
    "        .to_csv(OUT_DIR / \"Stage4_DroppedCollinearWinsor.csv\", index=False)\n",
    "    win_cols = [c for c in win_cols if c not in drop_mc]\n",
    "    wins_df.drop(columns=list(drop_mc), inplace=True)\n",
    "else:\n",
    "    logger.info(\"MC filter: no columns dropped\")\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 6 · DIAGNOSTIC STATS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def _write_diag(base: pd.DataFrame, cols: List[str], tag: str):\n",
    "    diag = (\n",
    "        base.assign(Year=base[DATE_COL].dt.year)\n",
    "            .groupby(\"Year\")[cols]\n",
    "            .agg(['mean', 'std', 'median', 'min', 'max', 'count'])\n",
    "            .stack(level=1)\n",
    "            .reset_index()\n",
    "    )\n",
    "    diag.to_csv(OUT_DIR / f\"Stage4_{tag}_RatioDiagnostics.csv\", index=False)\n",
    "\n",
    "_write_diag(pre_df,  raw_cols,  \"raw\")\n",
    "_write_diag(wins_df, win_cols, \"winsor\")\n",
    "logger.info(\"Diagnostic CSVs written\")\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 7 · RANKING HELPERS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "METRICS    = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\n",
    "              \"EBITDA\",\"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\n",
    "              \"CashAndCashEquivalents\",\"TotalRevenue\",\"GrossProfit\"]\n",
    "score_cols = [f\"Score_{m}\" for m in METRICS]\n",
    "flag_cols  = [f\"Flag_{m}\"  for m in METRICS]\n",
    "\n",
    "def _abs_spearman(x: pd.Series, y: pd.Series, min_obs=100):\n",
    "    ok = x.notna() & y.notna()\n",
    "    return np.nan if ok.sum() < min_obs else abs(spearmanr(x[ok], y[ok]).correlation)\n",
    "\n",
    "def _logit_stats(x: pd.Series, y_flag: pd.Series, min_obs=100) -> Tuple[float,float]:\n",
    "    ok = x.notna() & y_flag.isin([0,1])\n",
    "    if ok.sum() < min_obs or y_flag[ok].nunique() < 2 or x[ok].nunique() < 2:\n",
    "        return np.nan, np.nan\n",
    "    try:\n",
    "        mdl = sm.Logit(y_flag[ok], sm.add_constant(x[ok])).fit(disp=False)\n",
    "        return mdl.prsquared, roc_auc_score(y_flag[ok], mdl.predict())\n",
    "    except (ValueError, LinAlgError, MissingDataError):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# bucket / stage / domain maps (if Stage 03 executed this session)\n",
    "ratio_to_buckets: Dict[str, List[str]] = {\n",
    "    r: (bs if isinstance(bs, (list, tuple)) else [bs])\n",
    "    for r, bs in globals().get(\"ratio_domain_stage_map\", {}).items()\n",
    "}\n",
    "domains = {\"Phys\", \"Info\", \"Cog\", \"Soc\"}\n",
    "stages  = {\"Prepare\", \"Absorb\", \"Recover\", \"Adapt\"}\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "# 8 · RANK LOOP\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "def _rank(tag: str, cols: List[str], base: pd.DataFrame):\n",
    "    logger.info(\"Ranking %s (%d columns)…\", tag, len(cols))\n",
    "\n",
    "    rows = []\n",
    "    for col in cols:\n",
    "        cov_pct = base[col].notna().mean()*100\n",
    "        if cov_pct < MIN_COVERAGE:\n",
    "            continue\n",
    "        x = base[col]\n",
    "        for m, sc, fc in zip(METRICS, score_cols, flag_cols):\n",
    "            rho  = _abs_spearman(x, base[sc])\n",
    "            pr2, auc = _logit_stats(x, base[fc])\n",
    "            rows.append({\"Ratio\": col.replace(\"_raw\",\"\"),\n",
    "                         \"Metric\": m,\n",
    "                         \"Coverage%\": round(cov_pct, 1),\n",
    "                         \"|rho|\": round(rho, 3) if pd.notna(rho) else np.nan,\n",
    "                         \"PseudoR2\": round(pr2, 3) if pd.notna(pr2) else np.nan,\n",
    "                         \"AUROC\":   round(auc, 3) if pd.notna(auc) else np.nan})\n",
    "    rk = pd.DataFrame(rows)\n",
    "    rk.to_csv(OUT_DIR / f\"Stage4_{tag}_RatioRanking.csv\", index=False)\n",
    "\n",
    "    # ---- selector maps ------------------------------------------------------\n",
    "    bucket_map = ratio_to_buckets or {\"All\": [c.replace(\"_raw\",\"\") for c in cols]}\n",
    "    stage_map  = {\n",
    "        stg: [r for r, bs in bucket_map.items()\n",
    "              if any(str(b).endswith(f\"-{stg}\") for b in bs)]\n",
    "        for stg in stages\n",
    "    }\n",
    "    domain_map = {\n",
    "        dom: [r for r, bs in bucket_map.items()\n",
    "              if any(str(b).startswith(dom) for b in bs)]\n",
    "        for dom in domains\n",
    "    }\n",
    "\n",
    "    def _top3(df):  # pick top-3 by |rho|\n",
    "        return df.nlargest(3, \"|rho|\")\n",
    "\n",
    "    # (a) bucket leaderboard\n",
    "    bucket_rows = []\n",
    "    for bucket, members in bucket_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                bucket_rows.append({\"Bucket\": bucket, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(bucket_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_BucketTop3.csv\",\n",
    "                                     index=False)\n",
    "\n",
    "    # (b) stage leaderboard\n",
    "    stage_rows = []\n",
    "    for stg, members in stage_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                stage_rows.append({\"Stage\": stg, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(stage_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_StageTop3.csv\",\n",
    "                                    index=False)\n",
    "\n",
    "    # (c) domain leaderboard\n",
    "    domain_rows = []\n",
    "    for dom, members in domain_map.items():\n",
    "        sub = rk[rk[\"Ratio\"].isin(members)]\n",
    "        for metric in METRICS:\n",
    "            for _, r in _top3(sub[sub[\"Metric\"] == metric]).iterrows():\n",
    "                domain_rows.append({\"Domain\": dom, **r.drop(\"Ratio\")})\n",
    "    pd.DataFrame(domain_rows).to_csv(OUT_DIR / f\"Stage4_{tag}_DomainTop3.csv\",\n",
    "                                     index=False)\n",
    "\n",
    "    # (d) overall leaderboard\n",
    "    overall = []\n",
    "    for metric in METRICS:\n",
    "        for _, r in _top3(rk[rk[\"Metric\"] == metric]).iterrows():\n",
    "            overall.append(r.drop(\"Ratio\").to_dict())\n",
    "    pd.DataFrame(overall).to_csv(OUT_DIR / f\"Stage4_{tag}_OverallTop3.csv\",\n",
    "                                 index=False)\n",
    "\n",
    "# run rankings\n",
    "_rank(\"raw\",    raw_cols, pre_df)\n",
    "_rank(\"winsor\", win_cols, wins_df)\n",
    "\n",
    "logger.info(\"✅  STAGE 04 complete — artefacts in %s\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
