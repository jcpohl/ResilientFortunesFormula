{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 15:10:03,019 | INFO    | Snapshot FY-2007 rows: 974\n",
      "2025-06-15 15:10:03,025 | WARNING | placeholder for Stage6_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,049 | WARNING | placeholder for Stage6B_Stage_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,056 | WARNING | placeholder for Stage6C_Depth_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,063 | WARNING | placeholder for Stage6D_DepthStage_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,069 | INFO    | ðŸŽ‰ Stage 06 complete â€” artefacts in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\2025-06-15\\stage06\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE 06 Â· COMBINED WEIGHTED RISE PREDICTIONS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Writes six prediction tables plus diagnostics.  Filenames are aligned with\n",
    "Stage-11 expectations (speed / depth, domain / stage, and two blends).\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import logging, os, warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ bootstrap / paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CFG    = load_cfg()\n",
    "EVENTS = {str(k): v for k, v in CFG[\"events\"].items()}\n",
    "\n",
    "SWAN_YEAR = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "SWAN_INT  = int(SWAN_YEAR)\n",
    "\n",
    "RUN_DIR  = resolve_run_dir(\n",
    "    swan_year = SWAN_YEAR,\n",
    "    must_have = f\"stage05a/Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\",\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"),\n",
    ")\n",
    "ST05A = RUN_DIR / \"stage05a\"\n",
    "ST05B = RUN_DIR / \"stage05b\"\n",
    "ST06  = RUN_DIR / \"stage06\"; ST06.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(ST06 / \"stage06.log\", \"w\", \"utf-8\"),\n",
    "              logging.StreamHandler()],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ snapshot data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "snap = pd.read_csv(ST05A / f\"Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\")\n",
    "if \"Year\" not in snap.columns:\n",
    "    snap[\"Year\"] = pd.to_datetime(snap[DATE_COL], errors=\"coerce\").dt.year\n",
    "SNAP_YR = SWAN_INT - 1\n",
    "snap    = snap[snap[\"Year\"] == SNAP_YR].copy()\n",
    "log.info(\"Snapshot FY-%d rows: %s\", SNAP_YR, f\"{len(snap):,}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "METRICS     = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "               \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "               \"TotalRevenue\",\"GrossProfit\"]\n",
    "DOMAIN_COLS = [\"Physical_Score\",\"Information_Score\",\"Cognitive_Score\",\"Social_Score\"]\n",
    "STAGE_COLS  = [\"Prepare_Score\",\"Absorb_Score\",\"Recover_Score\",\"Adapt_Score\"]\n",
    "\n",
    "# stem â†’ (coef prefixes,  csv stem,  col-suffix)\n",
    "SETTING = {\n",
    "    \"A\": ([\"Stage05B_Domain\"],      \"Stage6_RISE_Predictions_\",        \"_RISE_prob\"),\n",
    "    \"B\": ([\"Stage05B_Stage\"],       \"Stage6B_Stage_RISE_Predictions_\", \"_StageRISE_prob\"),\n",
    "    \"C\": ([\"Stage05B_DepthDomain\"], \"Stage6C_Depth_RISE_Predictions_\", \"_DepthRISE_prob\"),\n",
    "    \"D\": ([\"Stage05B_DepthStage\"],  \"Stage6D_DepthStage_RISE_Predictions_\",\n",
    "                                     \"_DepthStageRISE_prob\"),\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _coef_file(prefixes:list[str], metric:str)->Path|None:\n",
    "    for pre in prefixes:\n",
    "        p = ST05B / f\"{pre}_{metric}_Coefficients_{SWAN_YEAR}.csv\"\n",
    "        if p.exists(): return p\n",
    "        legacy = ST05B / f\"{pre}_{metric}_Coefficients.csv\"\n",
    "        if legacy.exists(): return legacy\n",
    "    return None\n",
    "\n",
    "def _diagnostics(df:pd.DataFrame, pcols:list[str], stem:str):\n",
    "    if not pcols: return\n",
    "    mean_col = f\"Mean{pcols[0].split('_',1)[1]}\"\n",
    "    df[mean_col] = df[pcols].mean(axis=1)\n",
    "\n",
    "    stem_tag = stem if stem else \"A\"\n",
    "    (df[pcols].describe(percentiles=[.25,.5,.75]).T.round(3)\n",
    "       .to_csv(ST06/f\"Stage6{stem_tag}_Summary_Probs_{SWAN_YEAR}.csv\"))\n",
    "\n",
    "    df.nlargest(10, mean_col)[[ID_COL,\"Year\",mean_col]]\\\n",
    "      .to_csv(ST06/f\"Stage6{stem_tag}_Top10_{SWAN_YEAR}.csv\", index=False)\n",
    "    df.nsmallest(10, mean_col)[[ID_COL,\"Year\",mean_col]]\\\n",
    "      .to_csv(ST06/f\"Stage6{stem_tag}_Bottom10_{SWAN_YEAR}.csv\", index=False)\n",
    "\n",
    "    r, c = (-(-len(pcols)//4)), 4\n",
    "    fig, axs = plt.subplots(r, c, figsize=(4*c, 3*r))\n",
    "    for ax, col in zip(axs.flatten(), pcols):\n",
    "        df[col].dropna().hist(bins=20, ax=ax, edgecolor=\"k\"); ax.set_xlim(0,1)\n",
    "        ax.set_title(col.replace(pcols[0].split('_')[-1],\"\"))\n",
    "    for ax in axs.flatten()[len(pcols):]: ax.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(ST06/f\"Stage6{stem_tag}_HistGrid_{SWAN_YEAR}.png\", dpi=110)\n",
    "    plt.close(fig)\n",
    "\n",
    "def build(stem:str)->pd.DataFrame|None:\n",
    "    prefixes, csv_stem, suffix = SETTING[stem]\n",
    "    df = snap.copy(); made=False\n",
    "    for m in METRICS:\n",
    "        fp=_coef_file(prefixes, m)\n",
    "        if not fp: continue\n",
    "        beta = pd.read_csv(fp).set_index(\"Term\")[\"Coefficient\"].to_dict()\n",
    "        cols = DOMAIN_COLS if \"Domain\" in fp.name else STAGE_COLS\n",
    "        lin  = np.full(len(df), beta.get(\"const\",0.0))\n",
    "        for c in cols: lin += beta.get(c,0.0)*df.get(c,0)\n",
    "        df[f\"{m}{suffix.replace('prob','linpred')}\"] = lin\n",
    "        df[f\"{m}{suffix}\"] = 1/(1+np.exp(-lin)); made=True\n",
    "    out = ST06 / f\"{csv_stem}{SWAN_YEAR}.csv\"\n",
    "    if made:\n",
    "        df.to_csv(out,index=False)\n",
    "        _diagnostics(df,[c for c in df if c.endswith(suffix)], stem)\n",
    "        log.info(\"âœ“ %s\", out.name); return df\n",
    "    pd.DataFrame(columns=[ID_COL,DATE_COL]).to_csv(out,index=False)\n",
    "    log.warning(\"placeholder for %s â€¦ no coefficients\", csv_stem.rstrip(\"_\")); return None\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main flavours â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "speed_dom  = build(\"A\")\n",
    "speed_stg  = build(\"B\")\n",
    "depth_dom  = build(\"C\")\n",
    "depth_stg  = build(\"D\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ blends â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_blend(df1, df2, suff1, suff2, csvname, diag_stem):\n",
    "    out = ST06/csvname\n",
    "    if df1 is None or df2 is None:\n",
    "        pd.DataFrame(columns=[ID_COL,DATE_COL]).to_csv(out,index=False); return\n",
    "    blend=snap.copy()\n",
    "    for m in METRICS:\n",
    "        c1,f1 = f\"{m}{suff1}\", m\n",
    "        c2,f2 = f\"{m}{suff2}\", m\n",
    "        if c1 in df1 and c2 in df2:\n",
    "            blend[f\"{m}_blend{suff1.split('_',1)[1]}\"]=(df1[c1]+df2[c2])/2\n",
    "    blend.to_csv(out,index=False)\n",
    "    _diagnostics(blend,[c for c in blend if \"blend\" in c.lower() and c.endswith('prob')],\n",
    "                 diag_stem)\n",
    "    log.info(\"âœ“ %s\", out.name)\n",
    "\n",
    "make_blend(speed_dom, depth_dom,\n",
    "           SETTING[\"A\"][2], SETTING[\"C\"][2],\n",
    "           f\"Stage6E_Blend_RISE_Predictions_{SWAN_YEAR}.csv\", \"E\")\n",
    "\n",
    "make_blend(speed_stg, depth_stg,\n",
    "           SETTING[\"B\"][2], SETTING[\"D\"][2],\n",
    "           f\"Stage6F_BlendStage_RISE_Predictions_{SWAN_YEAR}.csv\", \"F\")\n",
    "\n",
    "log.info(\"ðŸŽ‰ Stage 06 complete â€” artefacts in %s\", ST06)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
