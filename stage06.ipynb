{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84336a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 15:10:03,019 | INFO    | Snapshot FY-2007 rows: 974\n",
      "2025-06-15 15:10:03,025 | WARNING | placeholder for Stage6_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,049 | WARNING | placeholder for Stage6B_Stage_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,056 | WARNING | placeholder for Stage6C_Depth_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,063 | WARNING | placeholder for Stage6D_DepthStage_RISE_Predictions â€¦ no coefficients\n",
      "2025-06-15 15:10:03,069 | INFO    | ğŸ‰ Stage 06 complete â€” artefacts in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\2025-06-15\\stage06\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE 06 Â· COMBINED WEIGHTED RISE PREDICTIONS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Creates six prediction tables:\n",
    "\n",
    "   A  speed-Domain      (_RISE_prob)\n",
    "   B  speed-Stage       (_StageRISE_prob)\n",
    "   C  depth-Domain      (_DepthRISE_prob)\n",
    "   D  depth-Stage       (_DepthStageRISE_prob)\n",
    "   E  blend of A & C    (_blendRISE_prob)\n",
    "   F  blend of B & D    (_blendStageRISE_prob)\n",
    "\n",
    "For every family it\n",
    "   â€¢ saves a CSV with all snapshot rows\n",
    "   â€¢ saves summary/top/bottom/hist-grid PNG + CSV\n",
    "   â€¢ PRINTS a text summary & TOP/BOTTOM-10 tables\n",
    "   â€¢ DISPLAYS a bar-chart of mean probabilities and the histogram grid\n",
    "     (exactly what the legacy Stage-06 showed).\n",
    "\n",
    "All filenames remain unchanged so Stage-11+ continue to work.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import os, logging, warnings, textwrap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 0 Â· BOOTSTRAP â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CFG        = load_cfg()\n",
    "EVENTS     = {str(k): v for k, v in CFG[\"events\"].items()}\n",
    "\n",
    "SWAN_YEAR  = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "SWAN_INT   = int(SWAN_YEAR)\n",
    "SNAP_YR    = SWAN_INT - 1\n",
    "\n",
    "RUN_DIR = resolve_run_dir(\n",
    "    swan_year = SWAN_YEAR,\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"),\n",
    "    must_have = f\"stage05a/Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\",\n",
    ")\n",
    "ST05A = RUN_DIR / \"stage05a\"\n",
    "ST05B = RUN_DIR / \"stage05b\"\n",
    "ST06  = RUN_DIR / \"stage06\"; ST06.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level   = logging.INFO,\n",
    "    format  = \"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(ST06/\"stage06.log\", \"w\", \"utf-8\"),\n",
    "              logging.StreamHandler()],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 06 â€“ RISE PREDICTIONS  (SWAN=%s) ==========\", SWAN_YEAR)\n",
    "\n",
    "DATE_COL, ID_COL = \"ReportDate\", \"Symbol\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1 Â· SNAPSHOT DATA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "snap = pd.read_csv(ST05A/f\"Stage5A_QuintilesAndScores_{SWAN_YEAR}.csv\")\n",
    "if \"Year\" not in snap.columns:\n",
    "    snap[\"Year\"] = pd.to_datetime(snap[DATE_COL], errors=\"coerce\").dt.year\n",
    "snap = snap[snap[\"Year\"] == SNAP_YR].copy()\n",
    "log.info(\"Snapshot FY-%d rows: %s\", SNAP_YR, f\"{len(snap):,}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2 Â· CONSTANTS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "METRICS = [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "           \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "           \"TotalRevenue\",\"GrossProfit\"]\n",
    "\n",
    "# mapping: tag â†’ (05B stem start, flavour, out-stem, prob-suffix)\n",
    "FAMILIES = {\n",
    "    \"A\": (\"Domain_speed\",  \"speed\",  \"Stage6_RISE_Predictions_\",        \"_RISE_prob\"),\n",
    "    \"B\": (\"Stage_speed\",   \"speed\",  \"Stage6B_Stage_RISE_Predictions_\", \"_StageRISE_prob\"),\n",
    "    \"C\": (\"Domain_depth\",  \"depth\",  \"Stage6C_Depth_RISE_Predictions_\", \"_DepthRISE_prob\"),\n",
    "    \"D\": (\"Stage_depth\",   \"depth\",  \"Stage6D_DepthStage_RISE_Predictions_\",\n",
    "                                   \"_DepthStageRISE_prob\"),\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3 Â· HELPER FUNCTIONS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _coef_file(stem_start:str, metric:str) -> Path|None:\n",
    "    \"\"\"\n",
    "    Find coefficients file produced in Stage-05B.  Works for both new and legacy names.\n",
    "    \"\"\"\n",
    "    modern = ST05B/f\"Stage05B_{stem_start}_{metric}_{SWAN_YEAR}_Coefficients.csv\"\n",
    "    if modern.exists(): return modern\n",
    "    # legacy pre-depth naming (no flavour in stem, year at end)\n",
    "    legacy = ST05B/f\"Stage05B_{stem_start.split('_')[0]}_{metric}_Coefficients_{SWAN_YEAR}.csv\"\n",
    "    return legacy if legacy.exists() else None\n",
    "\n",
    "def _print_header(title:str):\n",
    "    bar = \"=\" * len(title)\n",
    "    print(f\"\\n{bar}\\n{title}\\n{bar}\")\n",
    "\n",
    "def _diagnostics(df:pd.DataFrame, pcols:list[str], tag:str):\n",
    "    \"\"\"\n",
    "    (a) Save CSVs & PNGs  (b) Print + display like the legacy Stage-06 notebook.\n",
    "    \"\"\"\n",
    "    if not pcols:\n",
    "        log.warning(\"No probability columns for family %s â€“ diagnostics skipped\", tag)\n",
    "        return\n",
    "\n",
    "    mean_col = f\"Mean{pcols[0].split('_',1)[1]}\"\n",
    "    df[mean_col] = df[pcols].mean(axis=1)\n",
    "\n",
    "    # --- CSV artefacts ------------------------------------------------------\n",
    "    (df[pcols]\n",
    "       .describe(percentiles=[.25,.5,.75])\n",
    "       .T.round(3)\n",
    "       .to_csv(ST06/f\"Stage6{tag}_Summary_Probs_{SWAN_YEAR}.csv\"))\n",
    "\n",
    "    df.nlargest(10, mean_col)[[ID_COL,DATE_COL,mean_col]]\\\n",
    "      .to_csv(ST06/f\"Stage6{tag}_Top10_{SWAN_YEAR}.csv\", index=False)\n",
    "    df.nsmallest(10, mean_col)[[ID_COL,DATE_COL,mean_col]]\\\n",
    "      .to_csv(ST06/f\"Stage6{tag}_Bottom10_{SWAN_YEAR}.csv\", index=False)\n",
    "\n",
    "    # --- PNG histogram grid -------------------------------------------------\n",
    "    rows, cols = (-(-len(pcols)//4)), 4\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
    "    for ax, col in zip(axs.flatten(), pcols):\n",
    "        df[col].dropna().hist(bins=20, ax=ax, edgecolor=\"k\")\n",
    "        ax.set_xlim(0,1); ax.set_title(col.replace(\"_prob\",\"\"))\n",
    "    for ax in axs.flatten()[len(pcols):]: ax.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(ST06/f\"Stage6{tag}_HistGrid_{SWAN_YEAR}.png\", dpi=110)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- NOTEBOOK DISPLAY (like old code) -----------------------------------\n",
    "    _print_header(f\"SUMMARY â€“ Family {tag}\")\n",
    "    summary = df[pcols].describe(percentiles=[.25,.5,.75]).T.round(3)\n",
    "    print(summary.to_string())\n",
    "\n",
    "    # bar of means\n",
    "    summary[\"mean\"].sort_values(ascending=False).plot(kind=\"bar\", figsize=(10,4))\n",
    "    plt.title(f\"Mean Predicted Resilience Probability â€“ Family {tag}\")\n",
    "    plt.ylim(0,1); plt.ylabel(\"Probability\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # show the histogram grid\n",
    "    plt.figure(figsize=(4*cols, 3*rows))\n",
    "    for idx, col in enumerate(pcols, 1):\n",
    "        plt.subplot(rows, cols, idx)\n",
    "        plt.hist(df[col].dropna(), bins=20, edgecolor=\"k\"); plt.xlim(0,1)\n",
    "        plt.title(col.replace(\"_prob\",\"\"), fontsize=8)\n",
    "    for idx in range(len(pcols)+1, rows*cols+1):\n",
    "        plt.subplot(rows, cols, idx); plt.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # top / bottom tables\n",
    "    print(\"\\nTOP-10 firms:\")\n",
    "    print(df.nlargest(10, mean_col)[[ID_COL,DATE_COL,mean_col]]\n",
    "            .to_string(index=False))\n",
    "    print(\"\\nBOTTOM-10 firms:\")\n",
    "    print(df.nsmallest(10, mean_col)[[ID_COL,DATE_COL,mean_col]]\n",
    "            .to_string(index=False))\n",
    "\n",
    "def _build_family(tag:str) -> pd.DataFrame|None:\n",
    "    \"\"\"\n",
    "    Build predictions for one family; save CSV; run diagnostics.\n",
    "    Returns dataframe (or None if no coefficients found).\n",
    "    \"\"\"\n",
    "    stem_start, flav, csv_stem, prob_suf = FAMILIES[tag]\n",
    "    out_df   = snap.copy()\n",
    "    got_any  = False\n",
    "\n",
    "    for m in METRICS:\n",
    "        fp = _coef_file(stem_start, m)\n",
    "        if fp is None:\n",
    "            log.debug(\"No coefficients for %s / %s\", tag, m); continue\n",
    "\n",
    "        beta = pd.read_csv(fp).set_index(\"Term\")[\"Coefficient\"].to_dict()\n",
    "        lin  = np.full(len(out_df), beta.get(\"const\", 0.0))\n",
    "        for term, b in beta.items():\n",
    "            if term != \"const\" and term in out_df.columns:\n",
    "                lin += b * out_df[term].astype(float)\n",
    "        out_df[f\"{m}{prob_suf.replace('prob','linpred')}\"] = lin\n",
    "        out_df[f\"{m}{prob_suf}\"] = 1 / (1 + np.exp(-lin))\n",
    "        got_any = True\n",
    "\n",
    "    out_fp = ST06/f\"{csv_stem}{SWAN_YEAR}.csv\"\n",
    "    if got_any:\n",
    "        out_df.to_csv(out_fp, index=False)\n",
    "        _diagnostics(out_df,\n",
    "                     [c for c in out_df.columns if c.endswith(prob_suf)],\n",
    "                     tag)\n",
    "        log.info(\"âœ“ %s\", out_fp.name)\n",
    "        return out_df\n",
    "\n",
    "    pd.DataFrame(columns=[ID_COL, DATE_COL]).to_csv(out_fp, index=False)\n",
    "    log.warning(\"Placeholder %s (no coefficients)\", out_fp.name)\n",
    "    return None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4 Â· RUN FAMILIES A-D â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "results = {}\n",
    "for fam in (\"A\",\"B\",\"C\",\"D\"):\n",
    "    results[fam] = _build_family(fam)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5 Â· BLEND BUILDERS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _blend(df1:pd.DataFrame|None, df2:pd.DataFrame|None,\n",
    "           suf1:str, suf2:str,\n",
    "           tag:str, csv_name:str):\n",
    "\n",
    "    out_fp = ST06/csv_name\n",
    "    if df1 is None or df2 is None:\n",
    "        pd.DataFrame(columns=[ID_COL, DATE_COL]).to_csv(out_fp, index=False)\n",
    "        log.warning(\"Blend %s skipped â€“ missing inputs\", tag); return None\n",
    "\n",
    "    blend_df = snap.copy()\n",
    "    for m in METRICS:\n",
    "        c1 = f\"{m}{suf1}\"\n",
    "        c2 = f\"{m}{suf2}\"\n",
    "        if c1 in df1.columns and c2 in df2.columns:\n",
    "            blend_df[f\"{m}_blend{suf1.split('_',1)[1]}\"] = (df1[c1]+df2[c2]) / 2\n",
    "\n",
    "    blend_df.to_csv(out_fp, index=False)\n",
    "    _diagnostics(blend_df,\n",
    "                 [c for c in blend_df.columns if \"blend\" in c and c.endswith(\"prob\")],\n",
    "                 tag)\n",
    "    log.info(\"âœ“ %s\", csv_name)\n",
    "    return blend_df\n",
    "\n",
    "results[\"E\"] = _blend(results[\"A\"], results[\"C\"],\n",
    "                      FAMILIES[\"A\"][3], FAMILIES[\"C\"][3],\n",
    "                      \"E\", f\"Stage6E_Blend_RISE_Predictions_{SWAN_YEAR}.csv\")\n",
    "\n",
    "results[\"F\"] = _blend(results[\"B\"], results[\"D\"],\n",
    "                      FAMILIES[\"B\"][3], FAMILIES[\"D\"][3],\n",
    "                      \"F\", f\"Stage6F_BlendStage_RISE_Predictions_{SWAN_YEAR}.csv\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 6 Â· EXPORT FOR DOWNSTREAM â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "data_stage_6 = results   # dict of dataframes (None where family absent)\n",
    "\n",
    "log.info(\"ğŸ‰  STAGE 06 complete â€“ artefacts in %s\", ST06)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
