{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafcc2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:45:03,694 | INFO    | ==========  STAGE 2: RESILIENCE METRICS ==========\n",
      "2025-06-10 12:45:03,695 | INFO    | Config file      : c:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\pipeline_config.yaml\n",
      "2025-06-10 12:45:03,696 | INFO    | SWAN_YEAR=2008  RUN_DATE=20250609  MAX_YEARS=4\n",
      "2025-06-10 12:45:03,697 | INFO    | DATE_COL / ID_COL = ReportDate / Symbol\n",
      "2025-06-10 12:45:04,693 | INFO    | Stage 1 CSV loaded: 34,862 rows\n",
      "2025-06-10 12:45:05,640 | INFO    | NetIncome                      baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:06,494 | INFO    | EarningBeforeInterestAndTax    baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:07,598 | INFO    | OperatingIncome                baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:08,824 | INFO    | EBITDA                         baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:09,819 | INFO    | OperatingCashFlow              baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:10,938 | INFO    | FreeCashFlow                   baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:12,034 | INFO    | Cash                           baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:13,157 | INFO    | CashAndCashEquivalents         baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:14,328 | INFO    | TotalRevenue                   baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:15,447 | INFO    | GrossProfit                    baseline 48.9% | recovery 100.0%\n",
      "2025-06-10 12:45:20,799 | INFO    | Final DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34862 entries, 0 to 34861\n",
      "Columns: 196 entries, Symbol to Flag_GrossProfit\n",
      "dtypes: Int16(1), datetime64[ns](1), float64(180), int64(4), object(10)\n",
      "memory usage: 52.0+ MB\n",
      "\n",
      "2025-06-10 12:45:20,801 | INFO    | Saved Stage 2 CSV → C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008\\20250609\\stage02\\Stage2_Data_WithMetrics.csv\n",
      "2025-06-10 12:45:20,897 | INFO    | ✅ STAGE 2 complete — `data_stage_2` ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 2 · RESILIENCE METRICS & BASELINE RATIOS\n",
    "────────────────────────────────────────────────────────────────────────\n",
    "Self-contained, works both as a stand-alone script and inside the same\n",
    "Python session right after Stage 1.\n",
    "\n",
    "Key features\n",
    "• No manual parameters – everything comes from pipeline_config.yaml.\n",
    "• Robust when __file__ is missing (e.g. Jupyter).\n",
    "• Accepts either int or str keys under events: in the YAML.\n",
    "• Re-uses `data_stage_1` if it exists in memory; otherwise loads the\n",
    "  latest Stage 1 CSV.\n",
    "• Produces  \n",
    "  <OUTPUT_ROOT>/event=<SWAN_YEAR>/<RUN_DATE>/stage02/Stage2_Data_WithMetrics.csv\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import os, sys, logging, yaml, io\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 0 · LOAD PIPELINE CONFIG  (handles missing __file__)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "if os.getenv(\"PIPELINE_CFG\"):\n",
    "    cfg_file = Path(os.getenv(\"PIPELINE_CFG\")).expanduser()\n",
    "else:\n",
    "    try:                        # script run\n",
    "        cfg_file = Path(__file__).resolve().parent / \"pipeline_config.yaml\"\n",
    "    except NameError:           # Jupyter / interactive\n",
    "        cfg_file = Path.cwd() / \"pipeline_config.yaml\"\n",
    "cfg_file = cfg_file.expanduser()\n",
    "\n",
    "if not cfg_file.is_file():\n",
    "    raise FileNotFoundError(f\"pipeline_config.yaml not found at {cfg_file}\")\n",
    "\n",
    "with cfg_file.open(encoding=\"utf-8\") as fh:\n",
    "    CFG: Dict = yaml.safe_load(fh) or {}\n",
    "\n",
    "defaults: Dict = CFG.get(\"defaults\", {})\n",
    "events:   Dict = CFG.get(\"events\",   {})\n",
    "st2_cfg:  Dict = CFG.get(\"stage2\",   {})\n",
    "\n",
    "# helper: treat YAML keys as both str and int\n",
    "event_keys_str = {str(k): v for k, v in events.items()}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 1 · CORE PARAMS\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "SWAN_YEAR = os.getenv(\"SWAN_YEAR\", next(iter(event_keys_str)))        # str\n",
    "if SWAN_YEAR not in event_keys_str:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} not present in YAML `events:` block\")\n",
    "\n",
    "MAX_YEARS = int(st2_cfg.get(\"max_years\", 4))\n",
    "DATE_COL  = st2_cfg.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL    = st2_cfg.get(\"id_col\",   \"Symbol\")\n",
    "\n",
    "METRICS: List[str] = st2_cfg.get(\n",
    "    \"metrics\",\n",
    "    [\n",
    "        \"NetIncome\", \"EarningBeforeInterestAndTax\", \"OperatingIncome\", \"EBITDA\",\n",
    "        \"OperatingCashFlow\", \"FreeCashFlow\", \"Cash\", \"CashAndCashEquivalents\",\n",
    "        \"TotalRevenue\", \"GrossProfit\",\n",
    "    ],\n",
    ")\n",
    "METRIC_SIGN: Dict[str, bool] = {m: True for m in METRICS}   # True ⇒ higher better\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 2 · PATHS & RUN_DATE\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "OUTPUT_ROOT = Path(defaults[\"OUTPUT_ROOT\"]).expanduser()\n",
    "EVENT_DIR   = OUTPUT_ROOT / f\"event={SWAN_YEAR}\"\n",
    "\n",
    "if os.getenv(\"RUN_DATE\"):\n",
    "    RUN_DATE = os.getenv(\"RUN_DATE\")\n",
    "elif \"RUN_DATE\" in globals():\n",
    "    RUN_DATE = globals()[\"RUN_DATE\"]\n",
    "else:\n",
    "    if not EVENT_DIR.is_dir():\n",
    "        raise FileNotFoundError(f\"No Stage 1 outputs at {EVENT_DIR}\")\n",
    "    candidates = sorted(p.name for p in EVENT_DIR.iterdir()\n",
    "                        if p.is_dir() and p.name.isdigit())\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No dated run folders in {EVENT_DIR}. Run Stage 1 first.\")\n",
    "    RUN_DATE = candidates[-1]\n",
    "\n",
    "STAGE1_FILE = EVENT_DIR / RUN_DATE / \"stage01\" / \"stage01_cleaned.csv\"\n",
    "OUT_DIR     = EVENT_DIR / RUN_DATE / \"stage02\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 3 · LOGGER\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "if \"logger\" in globals() and isinstance(globals()[\"logger\"], logging.Logger):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if not any(isinstance(h, logging.FileHandler) and h.baseFilename.endswith(\"stage02.log\")\n",
    "               for h in logger.handlers):\n",
    "        logger.addHandler(logging.FileHandler(OUT_DIR / \"stage02.log\", mode=\"w\", encoding=\"utf-8\"))\n",
    "else:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(OUT_DIR / \"stage02.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "            logging.StreamHandler(sys.stdout),\n",
    "        ],\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"==========  STAGE 2: RESILIENCE METRICS ==========\")\n",
    "logger.info(\"Config file      : %s\", cfg_file)\n",
    "logger.info(\"SWAN_YEAR=%s  RUN_DATE=%s  MAX_YEARS=%s\", SWAN_YEAR, RUN_DATE, MAX_YEARS)\n",
    "logger.info(\"DATE_COL / ID_COL = %s / %s\", DATE_COL, ID_COL)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 4 · LOAD STAGE 1 DATA  (memory → disk fallback)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "if \"data_stage_1\" in globals():\n",
    "    df = globals()[\"data_stage_1\"].copy()\n",
    "    logger.info(\"Stage 1 data reused from memory.\")\n",
    "else:\n",
    "    if not STAGE1_FILE.is_file():\n",
    "        raise FileNotFoundError(f\"Stage 1 CSV not found at {STAGE1_FILE}\")\n",
    "    df = pd.read_csv(STAGE1_FILE, parse_dates=[DATE_COL], low_memory=False)\n",
    "    logger.info(\"Stage 1 CSV loaded: %s rows\", f\"{len(df):,}\")\n",
    "\n",
    "df[\"Year\"] = df[DATE_COL].dt.year.astype(\"Int16\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 5 · DERIVED COLUMNS\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "if {\"PretaxIncome\", \"EffectiveTaxRateAsReported\"}.issubset(df.columns):\n",
    "    df[\"IncomeTaxExpense\"] = df[\"PretaxIncome\"] * df[\"EffectiveTaxRateAsReported\"]\n",
    "    med = df.groupby([\"SectorName\", \"Year\"])[\"IncomeTaxExpense\"].transform(\"median\")\n",
    "    df[\"IncomeTaxExpense\"].fillna(med, inplace=True)\n",
    "else:\n",
    "    df[\"IncomeTaxExpense\"] = np.nan\n",
    "    logger.warning(\"IncomeTaxExpense derivation skipped (missing inputs)\")\n",
    "\n",
    "if {\"TotalAssets\", \"TotalLiabilitiesAsReported\"}.issubset(df.columns):\n",
    "    df[\"NetAssets\"] = df[\"TotalAssets\"] - df[\"TotalLiabilitiesAsReported\"]\n",
    "elif {\"TotalAssets\", \"TotalLiabilities\"}.issubset(df.columns):\n",
    "    df[\"NetAssets\"] = df[\"TotalAssets\"] - df[\"TotalLiabilities\"]\n",
    "else:\n",
    "    df[\"NetAssets\"] = np.nan\n",
    "    logger.warning(\"NetAssets derivation skipped (missing inputs)\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 6 · HELPERS\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "SWAN_YEAR_INT = int(SWAN_YEAR)           # for numeric comparison\n",
    "\n",
    "def _last_pre_swan(series: pd.Series) -> float:\n",
    "    pre = series.dropna()\n",
    "    pre = pre[pre.index < SWAN_YEAR_INT]\n",
    "    return pre.iloc[-1] if not pre.empty else np.nan\n",
    "\n",
    "def _first_recovery(series: pd.Series, baseline: float, higher_ok: bool) -> float:\n",
    "    if pd.isna(baseline):\n",
    "        return np.nan\n",
    "    cond = series >= baseline if higher_ok else series <= baseline\n",
    "    cand = series[(series.index >= SWAN_YEAR_INT) & cond]\n",
    "    return cand.index.min() if not cand.empty else np.nan\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 7 · METRIC LOOP\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "for metric in METRICS:\n",
    "    if metric not in df.columns:\n",
    "        logger.warning(\"⏭️ %-30s missing — skipped\", metric)\n",
    "        continue\n",
    "\n",
    "    grp = df.set_index(\"Year\").groupby(ID_COL)[metric]\n",
    "\n",
    "    baseline = grp.apply(_last_pre_swan).rename(\"Baseline\")\n",
    "    rec_year = grp.apply(\n",
    "        lambda s: _first_recovery(s, baseline.get(s.name), METRIC_SIGN[metric])\n",
    "    ).rename(\"RecYear\")\n",
    "\n",
    "    rp = (rec_year - SWAN_YEAR_INT + 1).clip(lower=1, upper=MAX_YEARS) \\\n",
    "                                       .fillna(MAX_YEARS).astype(\"int16\")\n",
    "    score = ((rp - 1) / (MAX_YEARS - 1)).round(4)     # 0 best … 1 worst\n",
    "    flag  = (rp < rp.median()).astype(\"int8\")\n",
    "\n",
    "    df = (\n",
    "        df.merge(rp.rename(f\"RP_{metric}\"),       on=ID_COL, how=\"left\")\n",
    "          .merge(score.rename(f\"Score_{metric}\"), on=ID_COL, how=\"left\")\n",
    "          .merge(flag.rename(f\"Flag_{metric}\"),   on=ID_COL, how=\"left\")\n",
    "    )\n",
    "\n",
    "    logger.info(\"%-30s baseline %.1f%% | recovery %.1f%%\",\n",
    "                metric, baseline.notna().mean()*100, rp.notna().mean()*100)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# 8 · EXPORT\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "out_csv = OUT_DIR / \"Stage2_Data_WithMetrics.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "buf = io.StringIO(); df.info(buf=buf)\n",
    "logger.info(\"Final DataFrame info:\\n%s\", buf.getvalue())\n",
    "logger.info(\"Saved Stage 2 CSV → %s\", out_csv)\n",
    "\n",
    "data_stage_2 = df.copy()\n",
    "logger.info(\"✅ STAGE 2 complete — `data_stage_2` ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
