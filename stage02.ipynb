{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcc2dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No run contains stage01/stage01_cleaned.csv in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m\n\u001b[0;32m     59\u001b[0m METRIC_SIGN: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m {m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m METRICS}   \u001b[38;5;66;03m# True ⇒ higher better\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 2 · resolve run folder & paths ---------------------------------------\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#     • honour $RUN_DIR or $RUN_DATE if the user sets them\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#     • otherwise pick the latest run that already contains Stage-1 output\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m RUN_DIR   \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_run_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmust_have\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstage01/stage01_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m RUN_DATE  \u001b[38;5;241m=\u001b[39m RUN_DIR\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     67\u001b[0m STAGE1_FILE \u001b[38;5;241m=\u001b[39m RUN_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\pipeline_utils.py:33\u001b[0m, in \u001b[0;36mresolve_run_dir\u001b[1;34m(swan_year, must_have)\u001b[0m\n\u001b[0;32m     31\u001b[0m     hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(event_dir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmust_have\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hits:\n\u001b[1;32m---> 33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo run contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmust_have\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hits[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m1\u001b[39m]      \u001b[38;5;66;03m# …/<run-tag>/\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# fallback: newest dated folder\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No run contains stage01/stage01_cleaned.csv in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2000"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE 02 · RESILIENCE METRICS\n",
    "────────────────────────────\n",
    "Adds recovery‑speed and draw‑down resilience outcomes to the cleaned Stage‑01\n",
    "financials and saves a wide CSV for Stage‑03.\n",
    "\n",
    "Outputs\n",
    "=======\n",
    "<OUTPUT_ROOT>/event=<SWAN_YEAR>/<RUN_TAG>/stage02/\n",
    "    └─ Stage2_Data_WithMetrics_<SWAN_YEAR>.csv\n",
    "\n",
    "Outcome families created per *metric* (EBITDA, OpCF, …):\n",
    "    • RP_<metric>             – integer years to recovery (1 … MAX_YEARS)\n",
    "    • Score_<metric>          – scaled 0 (best) → 1 (worst) recovery‑speed\n",
    "    • Flag_<metric>           – 1 if faster than median, else 0\n",
    "    • DD_<metric>             – % draw‑down depth (0 best … 1 worst)\n",
    "    • ScoreDepth_<metric>     – scaled draw‑down (min‑max normalization) rounded\n",
    "    • FlagDepth_<metric>      – 1 if shallower than median, else 0\n",
    "\n",
    "Down‑stream notebooks treat any column starting with Score*/Flag* as a resilience\n",
    "outcome, so no further code changes outside this stage are required.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import os, sys, io, logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 1 · CONFIG & PATHS\n",
    "# ──────────────────────────────────────────────────────────\n",
    "CFG      = load_cfg()                                       # pipeline_config.yaml\n",
    "EVENTS   = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "ST2_CFG  = CFG.get(\"stage2\", {})                            # optional YAML block\n",
    "\n",
    "# – runtime parameters ––––––––––––––––––––––––––––––––––––\n",
    "SWAN_YEAR = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "if SWAN_YEAR not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} not in YAML `events:` block\")\n",
    "\n",
    "RUN_DIR = resolve_run_dir(                                  # …/event=<YEAR>/<RUN_TAG>/\n",
    "            swan_year=SWAN_YEAR,\n",
    "            must_have=f\"stage01/stage01_cleaned_{SWAN_YEAR}.csv\")\n",
    "\n",
    "STAGE_DIR = RUN_DIR / \"stage02\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STAGE1_CSV = RUN_DIR / \"stage01\" / f\"stage01_cleaned_{SWAN_YEAR}.csv\"\n",
    "OUT_CSV    = STAGE_DIR / f\"Stage2_Data_WithMetrics_{SWAN_YEAR}.csv\"\n",
    "\n",
    "DATE_COL  = ST2_CFG.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL    = ST2_CFG.get(\"id_col\",   \"Symbol\")\n",
    "MAX_YEARS = int(ST2_CFG.get(\"max_years\", 4))\n",
    "\n",
    "# – metrics to score ––––––––––––––––––––––––––––––––––––––\n",
    "METRICS: List[str] = ST2_CFG.get(\n",
    "    \"metrics\",\n",
    "    [\n",
    "        \"NetIncome\", \"EarningBeforeInterestAndTax\", \"OperatingIncome\",\n",
    "        \"EBITDA\", \"OperatingCashFlow\", \"FreeCashFlow\",\n",
    "        \"Cash\", \"CashAndCashEquivalents\", \"TotalRevenue\", \"GrossProfit\",\n",
    "    ],\n",
    ")\n",
    "# True ⇒ higher is better\n",
    "METRIC_SIGN: Dict[str, bool] = {m: True for m in METRICS}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 2 · LOGGER\n",
    "# ──────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(STAGE_DIR / \"stage02.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 02  ==========\")\n",
    "log.info(\"RUN_DIR   : %s\", RUN_DIR)\n",
    "log.info(\"SWAN_YEAR : %s\", SWAN_YEAR)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 3 · LOAD STAGE‑01 DATA\n",
    "# ──────────────────────────────────────────────────────────\n",
    "if \"data_stage_1\" in globals():\n",
    "    df = globals()[\"data_stage_1\"].copy()\n",
    "    log.info(\"Re‑used Stage‑01 DataFrame from memory.\")\n",
    "else:\n",
    "    df = pd.read_csv(STAGE1_CSV, parse_dates=[DATE_COL], low_memory=False)\n",
    "    log.info(\"Loaded Stage‑01 CSV: %s rows\", f\"{len(df):,}\")\n",
    "\n",
    "df[\"Year\"] = df[DATE_COL].dt.year.astype(\"Int16\")\n",
    "SWAN_YEAR_INT = int(SWAN_YEAR)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 4 · HELPERS\n",
    "# ──────────────────────────────────────────────────────────\n",
    "\n",
    "def last_pre_swan(series: pd.Series) -> float:\n",
    "    \"\"\"Last non‑NA value before the crisis year.\"\"\"\n",
    "    pre = series[series.index < SWAN_YEAR_INT].dropna()\n",
    "    return pre.iloc[-1] if not pre.empty else np.nan\n",
    "\n",
    "\n",
    "def first_recovery(series: pd.Series, baseline: float, higher_ok: bool) -> float:\n",
    "    \"\"\"Earliest year ≥ swan where metric reaches the baseline again.\"\"\"\n",
    "    if pd.isna(baseline):\n",
    "        return np.nan  # no baseline ⇒ no recovery\n",
    "    cond = series >= baseline if higher_ok else series <= baseline\n",
    "    candidates = series[(series.index >= SWAN_YEAR_INT) & cond]\n",
    "    return candidates.index.min() if not candidates.empty else np.nan\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 5 · CORE LOOP – one metric at a time\n",
    "# ──────────────────────────────────────────────────────────\n",
    "for metric in METRICS:\n",
    "\n",
    "    if metric not in df.columns:\n",
    "        log.warning(\"⏭️  %-28s not found – skipped\", metric)\n",
    "        continue\n",
    "\n",
    "    # group as Series indexed by fiscal Year\n",
    "    g = df.set_index(\"Year\").groupby(ID_COL)[metric]\n",
    "\n",
    "    # ── speed / recovery period ───────────────────────────\n",
    "    baseline  = g.apply(last_pre_swan)\n",
    "    rec_year  = g.apply(lambda s: first_recovery(s, baseline.get(s.name), METRIC_SIGN[metric]))\n",
    "\n",
    "    rp = (rec_year - SWAN_YEAR_INT + 1) \\\n",
    "           .clip(lower=1, upper=MAX_YEARS) \\\n",
    "           .fillna(MAX_YEARS).astype(\"int16\")\n",
    "\n",
    "    score_speed = ((rp - 1) / (MAX_YEARS - 1)).round(4)  # 0 best … 1 worst\n",
    "    flag_speed  = (rp < rp.median()).astype(\"int8\")\n",
    "\n",
    "    # ── depth / draw‑down ─────────────────────────────────\n",
    "    trough = g.apply(lambda s: s[(s.index >= SWAN_YEAR_INT) &\n",
    "                                 (s.index <  SWAN_YEAR_INT + MAX_YEARS)].min())\n",
    "\n",
    "    dd_raw = (baseline - trough) / baseline\n",
    "    dd_raw = dd_raw.replace([np.inf, -np.inf], np.nan).clip(lower=0)\n",
    "\n",
    "    # New ScoreDepth calculation with min‑max normalization\n",
    "    if dd_raw.max() == dd_raw.min():\n",
    "        score_depth = dd_raw.round(4)\n",
    "    else:\n",
    "        score_depth = ((dd_raw - dd_raw.min()) / (dd_raw.max() - dd_raw.min())).round(4)\n",
    "    \n",
    "    flag_depth  = (dd_raw <= dd_raw.median()).astype(\"int8\")\n",
    "\n",
    "    # ── merge into df ────────────────────────────────────\n",
    "    df = (df.merge(rp.rename(f\"RP_{metric}\"),                 on=ID_COL, how=\"left\")\n",
    "            .merge(score_speed.rename(f\"Score_{metric}\"),       on=ID_COL, how=\"left\")\n",
    "            .merge(flag_speed.rename(f\"Flag_{metric}\"),         on=ID_COL, how=\"left\")\n",
    "            .merge(dd_raw.rename(f\"DD_{metric}\"),               on=ID_COL, how=\"left\")\n",
    "            .merge(score_depth.rename(f\"ScoreDepth_{metric}\"),  on=ID_COL, how=\"left\")\n",
    "            .merge(flag_depth.rename(f\"FlagDepth_{metric}\"),    on=ID_COL, how=\"left\"))\n",
    "\n",
    "    log.info(\"%-28s  baseline %.1f%% | recovery %.1f%% | depth %.1f%%\",\n",
    "             metric,\n",
    "             baseline.notna().mean()*100,\n",
    "             rp.notna().mean()*100,\n",
    "             dd_raw.notna().mean()*100)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 6 · SAVE & FINISH\n",
    "# ──────────────────────────────────────────────────────────\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "buf = io.StringIO(); df.info(buf=buf)\n",
    "log.info(\"Final DataFrame info:\\n%s\", buf.getvalue())\n",
    "log.info(\"Saved → %s\", OUT_CSV)\n",
    "\n",
    "# keep a shallow copy in memory for Stage‑03 if run within same Python session\n",
    "data_stage_2 = df.copy()\n",
    "log.info(\"✅  STAGE 02 complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
