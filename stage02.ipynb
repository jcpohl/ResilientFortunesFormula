{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafcc2dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No run directories under C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m SWAN_INT  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(SWAN_YEAR)\n\u001b[0;32m     30\u001b[0m SAVE_FMT : Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAVE_FORMAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefaults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAVE_FORMAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m )\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m---> 34\u001b[0m RUN_DIR \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_run_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswan_year\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSWAN_YEAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmust_have\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstage01/stage01_cleaned_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSWAN_YEAR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSAVE_FMT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_tag\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRUN_TAG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m OUT_DIR   \u001b[38;5;241m=\u001b[39m RUN_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage02\u001b[39m\u001b[38;5;124m\"\u001b[39m;  OUT_DIR\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m STAGE1_F  \u001b[38;5;241m=\u001b[39m RUN_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01_cleaned_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSWAN_YEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAVE_FMT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\pipeline_utils.py:100\u001b[0m, in \u001b[0;36mresolve_run_dir\u001b[1;34m(swan_year, run_tag, must_have, create)\u001b[0m\n\u001b[0;32m     93\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m     94\u001b[0m     (p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m event_dir\u001b[38;5;241m.\u001b[39miterdir()\n\u001b[0;32m     95\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir() \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfullmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, p\u001b[38;5;241m.\u001b[39mname)),\n\u001b[0;32m     96\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mstat()\u001b[38;5;241m.\u001b[39mst_mtime,\n\u001b[0;32m     97\u001b[0m     reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo run directories under \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m candidates[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    102\u001b[0m ulog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto-selected latest run directory: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, run_dir\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No run directories under C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2008"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE 02 · RESILIENCE METRICS   v3.0 – 2025-06-20\n",
    "──────────────────────────────────────────────────\n",
    "Adds three resilience dimensions to the cleaned Stage-01 data and\n",
    "writes a wide file for Stage-03.\n",
    "\n",
    "Temporal  → ScoreTemporal_<M>, FlagTemporal_<M>\n",
    "Impact    → ScoreImpact_<M>,   FlagImpact_<M>\n",
    "Dynamic   → RateDown/Up_, Asymmetry_, Convexity_,\n",
    "            + ScoreDynamic_<M>, FlagDynamic_<M>\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import io, logging, math, os, sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "from sklearn.preprocessing import StandardScaler   # ← new\n",
    "\n",
    "# ─── 1 · CONFIG ─────────────────────────────────────────────────\n",
    "CFG       = load_cfg()\n",
    "EVENTS    = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "C2        = CFG.get(\"stage2\", {})\n",
    "\n",
    "SWAN_YEAR = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "SWAN_INT  = int(SWAN_YEAR)\n",
    "SAVE_FMT : Literal[\"csv\", \"parquet\"] = os.getenv(\n",
    "    \"SAVE_FORMAT\", CFG[\"defaults\"].get(\"SAVE_FORMAT\", \"csv\")\n",
    ").lower()\n",
    "\n",
    "RUN_DIR = resolve_run_dir(\n",
    "    swan_year = SWAN_YEAR,\n",
    "    must_have = f\"stage01/stage01_cleaned_{SWAN_YEAR}.{SAVE_FMT}\",\n",
    "    run_tag   = os.getenv(\"RUN_TAG\"),\n",
    ")\n",
    "OUT_DIR   = RUN_DIR / \"stage02\";  OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STAGE1_F  = RUN_DIR / \"stage01\" / f\"stage01_cleaned_{SWAN_YEAR}.{SAVE_FMT}\"\n",
    "OUT_F     = OUT_DIR  / f\"Stage2_Data_WithMetrics_{SWAN_YEAR}.{SAVE_FMT}\"\n",
    "\n",
    "DATE_COL  = C2.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL    = C2.get(\"id_col\",   \"Symbol\")\n",
    "MAX_YEARS = int(C2.get(\"max_years\", 4))          # t₀ … t₀+3\n",
    "\n",
    "METRICS: List[str] = C2.get(\n",
    "    \"metrics\",\n",
    "    [\"NetIncome\",\"EarningBeforeInterestAndTax\",\"OperatingIncome\",\"EBITDA\",\n",
    "     \"OperatingCashFlow\",\"FreeCashFlow\",\"Cash\",\"CashAndCashEquivalents\",\n",
    "     \"TotalRevenue\",\"GrossProfit\"],\n",
    ")\n",
    "METRIC_SIGN: Dict[str, bool] = {m: True for m in METRICS}\n",
    "\n",
    "# ─── 2 · LOGGER ─────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(OUT_DIR/\"stage02.log\", \"w\", \"utf-8\"),\n",
    "              logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 02  (SWAN %s) ==========\", SWAN_YEAR)\n",
    "log.info(\"Load  : %s\", STAGE1_F.name)\n",
    "log.info(\"Save  : %s\", OUT_F.name)\n",
    "\n",
    "# ─── 3 · LOAD DATA ─────────────────────────────────────────────\n",
    "if SAVE_FMT == \"parquet\":\n",
    "    df = pd.read_parquet(STAGE1_F)\n",
    "else:\n",
    "    df = pd.read_csv(STAGE1_F, parse_dates=[DATE_COL], low_memory=False)\n",
    "\n",
    "df = df[df[ID_COL].astype(str).str.fullmatch(r\"[A-Z]{3}\")]\n",
    "df[\"Year\"] = pd.to_datetime(df[DATE_COL]).dt.year.astype(\"Int16\")\n",
    "log.info(\"Rows after primary-listing filter: %s\", f\"{len(df):,}\")\n",
    "\n",
    "# ─── 4 · HELPERS ───────────────────────────────────────────────\n",
    "def _last_pre_swan(s: pd.Series) -> Tuple[float, int | None]:\n",
    "    pre = s[s.index < SWAN_INT].dropna()\n",
    "    return (pre.iloc[-1], pre.index[-1]) if len(pre) else (np.nan, None)\n",
    "\n",
    "def _first_recovery(s: pd.Series, baseline: float, higher_ok: bool):\n",
    "    if math.isnan(baseline): return np.nan\n",
    "    cond = s >= baseline if higher_ok else s <= baseline\n",
    "    cand = s[(s.index >= SWAN_INT) & cond]\n",
    "    return cand.index.min() if len(cand) else np.nan\n",
    "\n",
    "def _safe_idxmin(s: pd.Series):\n",
    "    w = s.loc[SWAN_INT:SWAN_INT+MAX_YEARS-1].dropna()\n",
    "    return w.idxmin() if len(w) else np.nan\n",
    "\n",
    "def _rate(a, b, yrs):\n",
    "    try:   return (a / b) ** (1 / yrs) - 1\n",
    "    except Exception: return np.nan\n",
    "\n",
    "def _as_df(series: pd.Series, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Series → 2-col DF [Symbol | name] for safe merge.\"\"\"\n",
    "    return series.rename(name).reset_index().rename(columns={\"index\": ID_COL})\n",
    "\n",
    "# ─── 5 · PER-METRIC LOOP ───────────────────────────────────────\n",
    "for metric in METRICS:\n",
    "    if metric not in df:\n",
    "        log.warning(\"⏭️  %-28s missing – skipped\", metric)\n",
    "        continue\n",
    "\n",
    "    grp = df.set_index(\"Year\").groupby(ID_COL)[metric]\n",
    "\n",
    "    baseline, b_year = zip(*grp.apply(_last_pre_swan))\n",
    "    baseline = pd.Series(baseline, index=grp.groups.keys())\n",
    "    b_year   = pd.Series(b_year,   index=grp.groups.keys())\n",
    "\n",
    "    rec_year = grp.apply(\n",
    "        lambda s: _first_recovery(s, baseline.get(s.name), METRIC_SIGN[metric])\n",
    "    )\n",
    "\n",
    "    # ── Temporal (recovery time) ──────────────────────────────\n",
    "    rp  = (rec_year - SWAN_INT + 1).clip(lower=1, upper=MAX_YEARS)\\\n",
    "                                   .fillna(MAX_YEARS).astype(\"int16\")\n",
    "    score_temporal = ((rp - 1)/(MAX_YEARS-1)).round(4)\n",
    "    flag_temporal  = (rp < rp.median()).astype(\"int8\")\n",
    "\n",
    "    # ── Impact (draw-down depth) ──────────────────────────────\n",
    "    trough_val = grp.apply(lambda s: s[(s.index>=SWAN_INT) &\n",
    "                                       (s.index<SWAN_INT+MAX_YEARS)].min())\n",
    "    dd_raw = ((baseline - trough_val) / baseline)\\\n",
    "              .replace([np.inf,-np.inf], np.nan).clip(lower=0)\n",
    "    score_impact = ((dd_raw - dd_raw.min()) / (dd_raw.max()-dd_raw.min())\n",
    "                    if dd_raw.max()!=dd_raw.min() else dd_raw).round(4)\n",
    "    flag_impact  = (dd_raw <= dd_raw.median()).astype(\"int8\")\n",
    "\n",
    "    # ── Dynamic (speed & shape) ───────────────────────────────\n",
    "    trough_year = grp.apply(_safe_idxmin)\n",
    "\n",
    "    yrs_down = (trough_year - b_year).where(trough_year > b_year, np.nan)\n",
    "    yrs_up   = (rec_year    - trough_year).where(rec_year    > trough_year, np.nan)\n",
    "\n",
    "    rate_down = pd.Series({i: _rate(trough_val[i], baseline[i], yrs_down[i])\n",
    "                           for i in grp.groups})\n",
    "    rate_up   = pd.Series({i: _rate(baseline[i],  trough_val[i], yrs_up[i])\n",
    "                           for i in grp.groups})\n",
    "    asymmetry = (rate_up - rate_down).abs()\n",
    "\n",
    "    def _convex(s: pd.Series):\n",
    "        r_y = rec_year.get(s.name, np.nan)\n",
    "        seg = s.loc[SWAN_INT:r_y].dropna()\n",
    "        if len(seg) < 6:   # need ≥6 points for a half-decent curve\n",
    "            return np.nan\n",
    "        try: a, *_ = np.polyfit(range(len(seg)), seg.values, 2); return a\n",
    "        except Exception: return np.nan\n",
    "    convexity = grp.apply(_convex)\n",
    "\n",
    "    # ── Composite + flag (Stability removed) ──────────────────\n",
    "    z = lambda v: (v - v.mean()) / v.std(ddof=0)\n",
    "    comp = (\n",
    "        + z(rate_up)                         # faster rise good\n",
    "        - z(rate_down.abs())                 # steeper fall bad\n",
    "        - z(asymmetry)                       # bigger gap bad\n",
    "        - z(convexity.abs())                 # more curve bad\n",
    "    )\n",
    "    score_dyn  = comp.round(4)\n",
    "    flag_dyn   = (comp >= comp.median()).astype(\"int8\")\n",
    "\n",
    "    # ── MERGE ALL NEW COLUMNS ─────────────────────────────────\n",
    "    df = (df\n",
    "        .merge(_as_df(rp,            f\"RP_{metric}\"),              on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(score_temporal,f\"ScoreTemporal_{metric}\"),   on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(flag_temporal, f\"FlagTemporal_{metric}\"),    on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(dd_raw,        f\"DD_{metric}\"),              on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(score_impact,  f\"ScoreImpact_{metric}\"),     on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(flag_impact,   f\"FlagImpact_{metric}\"),      on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(rate_down,     f\"RateDown_{metric}\"),        on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(rate_up,       f\"RateUp_{metric}\"),          on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(asymmetry,     f\"Asymmetry_{metric}\"),       on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(convexity,     f\"Convexity_{metric}\"),       on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(score_dyn,     f\"ScoreDynamic_{metric}\"),    on=ID_COL, how=\"left\")\n",
    "        .merge(_as_df(flag_dyn,      f\"FlagDynamic_{metric}\"),     on=ID_COL, how=\"left\")\n",
    "    )\n",
    "\n",
    "    log.info(\"%-28s  temporal ✓  impact ✓  dynamic ✓\", metric)\n",
    "\n",
    "# ─── 6 · SAVE ───────────────────────────────────────────────────\n",
    "if SAVE_FMT == \"parquet\":\n",
    "    df.to_parquet(OUT_F, index=False)\n",
    "else:\n",
    "    df.to_csv(OUT_F, index=False)\n",
    "\n",
    "buf = io.StringIO(); df.info(buf=buf)\n",
    "log.info(\"Final DataFrame info:\\n%s\", buf.getvalue())\n",
    "log.info(\"Saved → %s\", OUT_F.name)\n",
    "\n",
    "data_stage_2 = df.copy()          # keep in-memory cache\n",
    "log.info(\"✅  STAGE 02 complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
