{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcc2dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No run contains stage01/stage01_cleaned.csv in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m\n\u001b[0;32m     59\u001b[0m METRIC_SIGN: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m {m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m METRICS}   \u001b[38;5;66;03m# True ⇒ higher better\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 2 · resolve run folder & paths ---------------------------------------\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#     • honour $RUN_DIR or $RUN_DATE if the user sets them\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#     • otherwise pick the latest run that already contains Stage-1 output\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m RUN_DIR   \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_run_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmust_have\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstage01/stage01_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m RUN_DATE  \u001b[38;5;241m=\u001b[39m RUN_DIR\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     67\u001b[0m STAGE1_FILE \u001b[38;5;241m=\u001b[39m RUN_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage01_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\pipeline_utils.py:33\u001b[0m, in \u001b[0;36mresolve_run_dir\u001b[1;34m(swan_year, must_have)\u001b[0m\n\u001b[0;32m     31\u001b[0m     hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(event_dir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmust_have\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hits:\n\u001b[1;32m---> 33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo run contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmust_have\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hits[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m1\u001b[39m]      \u001b[38;5;66;03m# …/<run-tag>/\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# fallback: newest dated folder\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No run contains stage01/stage01_cleaned.csv in C:\\Users\\Jason Pohl\\OneDrive - Bond University\\PhD\\rff\\outputs_rff\\event=2000"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "STAGE 02 · RESILIENCE METRICS\n",
    "────────────────────────────\n",
    "Adds Score_*  and Flag_* columns to the Stage-01 data and saves\n",
    "\n",
    "  <OUTPUT_ROOT>/event=<SWAN_YEAR>/<RUN_TAG>/stage02/Stage2_Data_WithMetrics.csv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import os, sys, io, logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pipeline_utils import load_cfg, resolve_run_dir\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 1 · CONFIG & PATHS\n",
    "# ──────────────────────────────────────────────────────────\n",
    "CFG      = load_cfg()                                       # pipeline_config.yaml\n",
    "EVENTS   = {str(k): v for k, v in CFG.get(\"events\", {}).items()}\n",
    "ST2_CFG  = CFG.get(\"stage2\", {})                            # optional YAML block\n",
    "\n",
    "# – runtime parameters ––––––––––––––––––––––––––––––––––––\n",
    "SWAN_YEAR = str(os.getenv(\"SWAN_YEAR\") or next(iter(EVENTS)))\n",
    "if SWAN_YEAR not in EVENTS:\n",
    "    raise KeyError(f\"SWAN_YEAR={SWAN_YEAR} not in YAML `events:` block\")\n",
    "\n",
    "RUN_DIR = resolve_run_dir(                                  # …/event=<YEAR>/<RUN_TAG>/\n",
    "            swan_year=SWAN_YEAR,\n",
    "            must_have=\"stage01/stage01_cleaned.csv\")\n",
    "\n",
    "STAGE_DIR = RUN_DIR / \"stage02\"\n",
    "STAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STAGE1_CSV = RUN_DIR / \"stage01\" / \"stage01_cleaned.csv\"\n",
    "OUT_CSV    = STAGE_DIR / \"Stage2_Data_WithMetrics.csv\"\n",
    "\n",
    "DATE_COL  = ST2_CFG.get(\"date_col\", \"ReportDate\")\n",
    "ID_COL    = ST2_CFG.get(\"id_col\",   \"Symbol\")\n",
    "MAX_YEARS = int(ST2_CFG.get(\"max_years\", 4))\n",
    "\n",
    "# – metrics to score ––––––––––––––––––––––––––––––––––––––\n",
    "METRICS: List[str] = ST2_CFG.get(\n",
    "    \"metrics\",\n",
    "    [\n",
    "        \"NetIncome\", \"EarningBeforeInterestAndTax\", \"OperatingIncome\",\n",
    "        \"EBITDA\", \"OperatingCashFlow\", \"FreeCashFlow\",\n",
    "        \"Cash\", \"CashAndCashEquivalents\", \"TotalRevenue\", \"GrossProfit\",\n",
    "    ],\n",
    ")\n",
    "# True ⇒ higher is better\n",
    "METRIC_SIGN: Dict[str, bool] = {m: True for m in METRICS}\n",
    "\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 2. LOGGER\n",
    "# ──────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(STAGE_DIR / \"stage02.log\", mode=\"w\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "log.info(\"==========  STAGE 02  ==========\")\n",
    "log.info(\"RUN_DIR   : %s\", RUN_DIR)\n",
    "log.info(\"SWAN_YEAR : %s\", SWAN_YEAR)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 3. LOAD STAGE-01 DATA\n",
    "# ──────────────────────────────────────────────────────────\n",
    "if \"data_stage_1\" in globals():\n",
    "    df = globals()[\"data_stage_1\"].copy()\n",
    "    log.info(\"Re-used Stage-01 DataFrame from memory.\")\n",
    "else:\n",
    "    df = pd.read_csv(STAGE1_CSV, parse_dates=[DATE_COL], low_memory=False)\n",
    "    log.info(\"Loaded Stage-01 CSV: %s rows\", f\"{len(df):,}\")\n",
    "\n",
    "df[\"Year\"] = df[DATE_COL].dt.year.astype(\"Int16\")\n",
    "SWAN_YEAR_INT = int(SWAN_YEAR)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 4. HELPERS\n",
    "# ──────────────────────────────────────────────────────────\n",
    "def last_pre_swan(series: pd.Series) -> float:\n",
    "    \"\"\"Last non-NA value before the crisis year.\"\"\"\n",
    "    pre = series[series.index < SWAN_YEAR_INT].dropna()\n",
    "    return pre.iloc[-1] if not pre.empty else np.nan\n",
    "\n",
    "def first_recovery(series: pd.Series, baseline: float, higher_ok: bool) -> float:\n",
    "    \"\"\"Earliest year >= swan where metric reaches the baseline again.\"\"\"\n",
    "    if pd.isna(baseline):                   # no baseline ⇒ no recovery\n",
    "        return np.nan\n",
    "    cond = series >= baseline if higher_ok else series <= baseline\n",
    "    candidates = series[(series.index >= SWAN_YEAR_INT) & cond]\n",
    "    return candidates.index.min() if not candidates.empty else np.nan\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 5. CORE LOOP – one metric at a time\n",
    "# ──────────────────────────────────────────────────────────\n",
    "for metric in METRICS:\n",
    "\n",
    "    if metric not in df.columns:\n",
    "        log.warning(\"⏭️  %-28s not found – skipped\", metric)\n",
    "        continue\n",
    "\n",
    "    g = df.set_index(\"Year\").groupby(ID_COL)[metric]\n",
    "\n",
    "    baseline  = g.apply(last_pre_swan)\n",
    "    rec_year  = g.apply(lambda s: first_recovery(\n",
    "                            s, baseline.get(s.name), METRIC_SIGN[metric]))\n",
    "\n",
    "    # Recovery period in years (1 = immediate, MAX_YEARS = never)\n",
    "    rp = (rec_year - SWAN_YEAR_INT + 1) \\\n",
    "           .clip(lower=1, upper=MAX_YEARS) \\\n",
    "           .fillna(MAX_YEARS).astype(\"int16\")\n",
    "\n",
    "    score = ((rp - 1) / (MAX_YEARS - 1)).round(4)            # 0 best … 1 worst\n",
    "    flag  = (rp < rp.median()).astype(\"int8\")                 # simple binary flag\n",
    "\n",
    "    df = (df.merge(rp.rename(f\"RP_{metric}\"),       on=ID_COL, how=\"left\")\n",
    "            .merge(score.rename(f\"Score_{metric}\"), on=ID_COL, how=\"left\")\n",
    "            .merge(flag.rename(f\"Flag_{metric}\"),   on=ID_COL, how=\"left\"))\n",
    "\n",
    "    log.info(\"%-28s  baseline %.1f%% | recovery %.1f%%\",\n",
    "             metric, baseline.notna().mean()*100, rp.notna().mean()*100)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────\n",
    "# 6. SAVE & FINISH\n",
    "# ──────────────────────────────────────────────────────────\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "buf = io.StringIO(); df.info(buf=buf)\n",
    "log.info(\"Final DataFrame info:\\n%s\", buf.getvalue())\n",
    "log.info(\"Saved → %s\", OUT_CSV)\n",
    "\n",
    "# keep a copy in memory for Stage-03 if run in same Python session\n",
    "data_stage_2 = df.copy()\n",
    "log.info(\"✅  STAGE 02 complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
